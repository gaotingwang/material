[TOC]

##序列模型和注意力机制（Sequence models & Attention mechanism）

### 1. 基础模型（Basic Models）

seq2seq（sequence to sequence）模型，从机器翻译到语音识别，它们都能起到很大的作用。

假设想输入一个法语句子，把它翻译成英文句子。用$x^{<1>}$ 一直到$x^{< 5>}$来表示输入的句子的单词，然后用$y^{<1>}$到$y^{<6>}$来表示翻译输出的句子的单词，如何训练出一个新的网络来输入序列$x$和输出序列$y$呢？

![](http://www.ai-start.com/dl2017/images/2d41c0090fd3d71e6f28eade62b7c97b.png)

首先，建立一个上图编号1所示的网络，这个网络叫做编码网络（encoder network），它是一个RNN的结构， RNN的单元可以是GRU 也可以是LSTM。每次向该网络的单元中输入一个法语单词$x^{<1>}$一直到$x^{<T_x>}$，将输入序列接收完毕后，这个RNN网络会输出一个向量来代表这个输入序列。

之后可以建立一个上图编号2所示的解码网络，它以编码网络的输出作为输入。之后可以被训练为，每个单元输出一个翻译后的单词$y^{<1>}$一直到$y^{<T_y>}$，一直到它输出序列的结尾或者句子结尾标记，这个解码网络的工作就结束了。和往常一样把每次生成的标记都传递到下一个单元中来进行预测，就像之前用语言模型合成文本时一样。

深度学习在近期最卓越的成果之一就是这个模型确实有效，在给出足够的法语和英语文本的情况下，如果训练这个模型，通过输入一个法语句子来输出对应的英语翻译，这个模型将会非常有效。这个模型简单地用一个编码网络来对输入的法语句子进行编码，然后用一个解码网络来生成对应的英语翻译。

还有一个与此类似的结构被用来做图像描述，给出一张图片，它能自动地输出该图片的描述，一只猫坐在椅子上，那么如何训练出这样的网络？通过输入图像来输出描述，像下图中的句子一样。

![](http://www.ai-start.com/dl2017/images/b9492d18803ebe3853e936098f08661c.png)

方法如下，将图片输入到卷积神经网络中，比如一个预训练的AlexNet结构，然后让其学习图片的编码（学习图片的一系列特征）。去掉最后的softmax单元（上图编号3所示），这个预训练的AlexNet结构会输出一个4096维的特征向量，这个特征向量表示的就是这只猫的图片。

这个预训练网络就是图像的编码网络，接着可以把这个向量输入到RNN中（上图编号4方框所示），RNN要做的就是生成图像的描述，每次生成一个单词，这和之前将法语译为英语的机器翻译中看到的结构很像。现在输入一个描述的特征向量，然后让网络生成一个输出序列。

现在知道了基本的seq2seq模型是怎样运作的，以及image to sequence模型或者说图像描述模型是怎样运作的。不过这两个模型运作方式有一些不同，主要体现在如何用语言模型合成新的文本，并生成对应序列的方面。

### 2. 选择最可能的句子（Picking the most likely sentence）

在seq2seq机器翻译模型和之前所用的语言模型之间有很多相似的地方，但是它们之间也有许多重要的区别。

关于之前所讲的语言模型，可以估计句子的可能性，这就是语言模型所做的事情。也可以将它用于生成一个新的句子，如果在下图编号1所示位置，有$x^{<1>}$和$x^{<2>}$，那么在该例中$x^{<2>} = \hat y^{<1>}$ 。但是$x^{<1>}$、$x^{<2>}$等在这里并不重要。为了让图片看起来更简洁，把它们先抹去，可以理解为$x^{<1>}$是一个全为0的向量，然后$x^{<2>}$、$x^{<3>}$等都等于之前所生成的输出，这就是所说的语言模型。

![](http://www.ai-start.com/dl2017/images/a8b8c64483ee84d57135829ab025da53.png)

而机器翻译模型是下面这样的，绿色（上图编号2所示）表示encoder网络，紫色（上图编号3所示）表示decoder网络。可以发现decoder网络看起来和刚才所画的语言模型几乎一模一样，机器翻译模型其实和语言模型非常相似。**不同在于语言模型总是以零向量（上图编号4所示）开始，而encoder网络会计算出一系列向量（上图编号2所示）来表示输入的句子**。有了输入语句，decoder网络就可以以这个句子的编码输出为开始，而不是以零向量开始，所以把它叫做条件语言模型（conditional language model）。

相比语言模型，输出任意句子的概率，翻译模型会输出句子的英文翻译（上图编号5所示），取决于输入的法语句子（上图编号6所示），所以它是一个条件语言模型。

当使用这个模型来进行机器翻译时，并不是从得到的分布中进行随机取样，而是要找到一个英语句子$y$，使得条件概率最大化。所以在开发机器翻译系统时，需要做的一件事就是想出一个算法，用来找出合适的$y$值，使得$P(y^{<1>} \ldots y^{<T_y>}|x^{<1>} \ldots x^{<T_x>})$最大化，而解决这种问题最通用的算法就是束搜索(Beam Search)。

有一个问题为什么不用贪心搜索(Greedy Search)呢？贪心搜索是一种来自计算机科学的算法，生成第一个词的分布以后，根据条件语言模型挑选出最有可能的第一个词进入机器翻译模型中。在挑选出第一个词之后继续挑选出最有可能的第二个词，然后继续挑选第三个最有可能的词，这种算法就叫做贪心搜索。所以这种贪心算法先挑出最好的第一个词，在这之后再挑最好的第二词，然后再挑第三个，这种方法其实并不管用。

如果贪心算法挑选出了"Jane is"作为前两个词，因为在英语中going更加常见，所以来说"Jane is going"相比"Jane is visiting"会有更高的概率作为法语的翻译。所以如果仅仅根据前两个词来估计第三个词的可能性，得到的就是going，最终会得到一个欠佳的句子，在$P(y|x)$模型中这不是一个最好的选择。

如果字典中有10,000个单词，并且翻译可能有10个词长，那么可能的组合就有10,000的10次方这么多，这仅仅是10个单词的句子，从这样大一个字典中来挑选单词，所以可能的句子数量非常巨大，不可能去计算每一种组合的可能性。所以这时最常用的办法就是用一个近似的搜索算法，这个近似的搜索算法做的就是它会尽力地，尽管不一定总会成功，但它将挑选出句子$y$使得条件概率最大化，尽管它不能保证找到的$y$值一定可以使概率最大化，但这已经足够了。

机器翻译模型和之前的语言模型一个主要的区别就是，相比之前的模型随机地生成句子，在该模型中要找到最有可能的句子，但是可能的句子组合数量过于巨大，无法一一列举，所以需要一种合适的搜索算法。

### 3. 定向搜索（Beam Search）

要想找到一个最接近原意的翻译结果，定向搜索就是解决这个最常用的算法。

对于机器翻译，定向搜索算法首先做的就是挑选要输出的英语翻译中的第一个单词。这里列出10,000个词的词汇表，忽略大小写。在定向搜索的第一步，下图绿色是编码部分，紫色是解码部分，来评估第一个单词的概率值。即法语作为输入序列$x$，第一个输出$\hat y^{<1>}$的概率值是多少。

![](http://www.ai-start.com/dl2017/images/8a22dfb5d3c0a4b5d2fdfa716dc3f3b2.png)

贪婪算法只会挑出最可能的那一个单词，然后继续挑选后面每个最可能的单词，而定向搜索则会考虑多个选择。定向搜索算法会有一个参数B，叫做定向宽（beam width）。

这个例子中把定向宽设成3，这样就意味着定向搜索不会只考虑一个可能结果，而是一次会考虑3个。

1. 比如对第一个单词有不同选择的可能性，最后找到in、jane、september，是英语输出的第一个单词的最可能的三个选项，然后定向搜索算法会把结果存到计算机内存里以便后面尝试用这三个词。如果定向宽设的不一样，设为10的话，那么跟踪的不仅仅3个，而是10个第一个单词的最可能的选择。

   所以为了执行定向搜索的第一步，需要输入法语句子到编码网络，然后网络会解码到softmax层，会输出10,000个概率值，取前三个存起来。

2. 定向搜索算法的第二步，在已经选出了in、jane、september作为第一个单词的三个最可能的选择，定向算法接下来会针对每个第一个单词考虑第二个单词是什么。单词in后面的第二个单词可能是词汇表里某个位置的词。

   ![](http://www.ai-start.com/dl2017/images/14a940ae2ea7932b7b7190eceb79f79e.png)

   为了评估第二个词的概率值，用神经网络的编码部分，而对于解码部分，当决定单词in后面是什么，别忘了解码器的第一个输出$y^{<1>}$，把$y^{<1>}$设为单词in（上图编号3所示），然后把它喂给解码的下一个单元。因为它的目的是努力找出第一个单词是in的情况下，第二个单词是什么，第二个单元输出就是$y^{<2>}$ 。上图编号6所示的连接，就是第一个单词in作为输入，这样这个网络就可以，在给定法语句子和翻译结果的第一个单词是in的情况下，评估第二个单词的概率了。

   注意，在第二步里更关心的是找到最可能的第一个和第二个单词对，所以**==这里得出的不是第二个单词概率最大的，而是第一个、第二个单词对有最大的概率==**，$P(y^{<1>},y^{<2>}|x) = P(y^{<1>}|x)\cdot P(y^{<2>}|x,y^{<1>})$。

3. 现在已经知道在第一个单词是in的情况下如何评估第二个单词的概率。现在第一个单词是jane，道理一样，$y^{< 1 >}$连接jane。那么这个网络部分就可以告诉，在给定输入$x$和第一个词是jane下，第二个单词的概率了，和上面一样，$P(y^{<2>}|x,y^{<1>})$可以乘以$P(y^{<1>}|x)$得到$P(y^{<1>},y^{<2>}|x)$。针对第二个单词所有10,000个不同的选择，最后对于单词september也一样。

   对于定向搜索的第二步，由于一直用的定向宽为3，并且词汇表里有10,000个单词，那么最终会有$3 \times  10000 = 30000$个可能的结果，要做的就是评估这30,000个选择。按照第一个词和第二个词的概率，然后选出前三个，这样减少了这30,000个可能性，又变成了3个，减少到定向宽的大小。

   ![](http://www.ai-start.com/dl2017/images/507c9081ee77c686bb96a009248087fd.png)

   假如这30,000个选择里最可能的是“in September”和“jane is”，以及“jane visits”，这就是这30,000个选择里最可能的三个结果，定向搜索算法会保存这些结果，然后用于下一次定向搜索。

   注意一件事情，如果定向搜索找到了第一个和第二个单词对最可能的三个选择是“in September”或者“jane is”或者“jane visits”，这就意味着作为英语翻译结果去掉了september是第一个单词的选择，所以第一个单词现在减少到了两个可能结果。但是由于定向宽是3，所以还是有$y^{<1>}$，$y^{<2>}$对的三个选择，如下图。

   ![](http://www.ai-start.com/dl2017/images/6a0b785dd54fcbc439bd82794eeefcf8.png)

   提醒一下因为定向宽等于3，每一步都复制3个。同样用这种网络来评估部分句子和最后的结果，由于定向宽等于3，所以有上图所示的三个网络副本，每个网络的第一个单词不同，而这三个网络可以高效地评估第二个单词所有的30,000个选择。所以不需要初始化30,000个网络副本，只需要使用3个网络的副本就可以快速的评估softmax的输出。

4. 在给定输入的法语句子$x$和给定的英语输出的前两个单词“in September”情况下，然后定向搜索还是会挑选出针对前三个词的三个最可能的选择，可能是“in september jane”，“Jane is visiting”也很有可能，也很可能是“Jane visits Africa”。

   然后继续，接着进行定向搜索的第四步，再加一个单词继续，最终这个过程的输出一次增加一个单词，定向搜索最终会找到“Jane visits africa in september”这个句子，终止在上图编号8所示的句尾符号。

注意如果定向宽等于1，只考虑1种可能结果，这实际上就变成了贪婪搜索算法。但是如果同时考虑多个，定向搜索通常会找到比贪婪搜索更好的输出结果。

### 4. 改进定向搜索（Refinements to Beam Search）

这节会学到一些技巧, 能够使定向搜索算法(beam search algorithm)运行的更好。

前面讲到定向搜索就是最大化$P(y^{< 1 >}\ldots y^{< T_{y}}|X)$，可以表示成:$P(y^{<1>}|X) \cdot P(y^{< 2 >}|X,y^{< 1 >}) \cdot P(y^{< 3 >}|X,y^{< 1 >},y^{< 2>}) \ldots P(y^{< T_{y} >}|X,y^{<1 >},y^{<2 >}\ldots y^{< T_{y} - 1 >})$ 。这些概率值都是小于1的，通常远小于1。如果计算这些，很多小于1的数乘起来，会得到很小很小的数字，会造成数值下溢（numerical underflow），数值下溢导致电脑的浮点表示不能精确地储存。
$$
argmax\ \prod_{t=1}^{T_y}P(y^{< t>}|X,y^{<1 >},y^{<2 >}\ldots y^{< t - 1 >})
$$
因此在实践中，不会最大化这个乘积，而是取$\log$值如果给$P(y|X)$加上一个$\log$，最大化这个$\log$求和的概率值，在选择最可能的句子$y$时，会得到同样的结果。所以通过取$\log$，会得到一个数值上更稳定的算法，不容易出现四舍五入的误差。因为$\log$函数它是严格单调递增的函数，所以最大化$\log P(y|x)$和最大化$P(y|x)$结果一样。所以实际工作中，总是记录概率的对数和（the sum of logs of the probabilities），而不是概率的乘积（the production of probabilities）。
$$
argmax\ \sum_{t=1}^{T_y}\log P(y^{< t>}|X,y^{<1 >},y^{<2 >}\ldots y^{< t - 1 >})
$$
对于目标函数（this objective function），还可以做一些改变，可以使得机器翻译表现的更好。如果参照原来的目标函数，假设有一个很长的句子，因为乘了很多项小于1的数字来估计句子的概率，那么这个句子的概率会很低。所以这个目标函数有一个缺点，它更偏向短的输出，因为短句子的乘积不会那么小。

顺便说一下，这里也有同样的问题，概率的$\log$值通常小于等于1，实际上在0~1的范围内，加起来的项越多，得到的结果越负。所以对这个算法另一个改变也可以使它表现的更好，也就是不再最大化概率的对数和，可以通过除以翻译结果的单词数量，把它归一化。这样就是取每个单词的概率对数值的平均了，很明显地减少了对输出长的结果的惩罚。
$$
\frac{1}{T_y^{\alpha}}\sum_{t=1}^{T_y}\log P(y^{< t>}|X,y^{<1 >},y^{<2 >}\ldots y^{< t - 1 >})
$$
在实践中，有个探索性的方法，相比于直接除$T_{y}$，有时会用一个更柔和的方法（a softer approach），在$T_{y}$上加上指数$\alpha$，$\alpha$可以等于0.7。如果$\alpha$等于1，就相当于完全用长度来归一化，如果$\alpha$等于0，$T_{y}$的0次幂就是1，就相当于完全没有归一化，这就是在完全归一化和没有归一化之间。

$\alpha$就是算法另一个超参数（hyper parameter），需要调整大小来得到最好的结果。不得不承认，这样用$\alpha$实际上是试探性的，它并没有理论验证。但是大家都发现效果很好，所以很多人都会这么做。可以尝试不同的$\alpha$值，看看哪一个能够得到最好的结果。

**Beam with B:**

最后还有一些实现的细节，如何选择束宽B。

- B越大，需要考虑的选择越多，找到的句子可能越好，但是B越大，算法的计算代价也就越大，算法会运行的慢一些，内存占用也会增大，计算起来会慢一点。
- 用小的束宽，结果会没那么好，因为在算法运行中，保存的选择更少，但是算法运行的更快，内存占用也小。

在产品中，经常可以看到把束宽设到10，束宽设为100对于产品系统来说有点大了，但这也取决于不同应用。但是对科研而言，人们想压榨出全部性能，这样有个最好的结果用来发论文，也经常看到大家用束宽为1000或者3000，这也是取决于特定的应用和特定的领域。

### 5. 定向搜索的误差分析（Error analysis in beam search）

事实上在定向搜索上做误差分析是最有用的工具之一。有时想知道是否应该增大束宽，可以通过计算一些简单的东西来指导你需要做什么，来改进搜索算法。

定向搜索算法是一种近似搜索算法（approximate search algorithm），也被称作启发式搜索算法（heuristic search algorithm），它不总是输出可能性最大的句子，它仅记录着B为前3或者是10种可能。那么如果定向搜索算法出现错误会怎样呢?

假如说，在机器翻译的dev集中，人工翻译标记为$y^*$。模型输出什么糟糕的翻译结果，标记为$\hat y$。模型有两个主要部分，是序列到序列模型（sequence to sequence model），实际上是个编码器和解码器两部分。解码器部分是束搜索算法，以某个定向宽度B运行。如果能够找出造成这个错误，是两个部分中的哪一个，不是很好吗? 大家很容易想到去收集更多的训练数据，这总归没什么坏处。同样的，大家也会觉得不行就增大束宽，这么做很大可能是没有危害的。但是就像单纯获取更多训练数据一样，可能并不能得到预期的表现结果，同样单纯增大束宽也可能得不到想要的结果。

RNN实际上是个编码器和解码器，它会计算$P(y|x)$。$P(y|x)$结果表明，此时能做的最有效的事就是用这个模型来计算$P(y^*|x)$，同时也用RNN模型来计算$P(\hat y|x)$，然后比较一下这两个值哪个更大。有可能是$P(y^*)$大于$P(\hat y)$，也有可能是$P(y^*)$小于$P(\hat y)$。根据实际是哪种情况，就能够更清楚地将这个特定的错误归咎于RNN或是束搜索算法。

- 第一种情况，RNN模型的输出结果：$P(y^*|x) > P(\hat y|x)$  

  得到$\hat y$的方式是用一个RNN模型来计算$P(y|x)$，然后束搜索算法做的就是尝试寻找使$P(y|x)$最大的$y$。不过此时，$y^*$的$P(y|x)$更大，因此能够得出：束搜索算法实际上不能给出一个能使$P(y|x)$最大化的$y$值。因为束搜索算法的任务就是寻找一个$y$的值来使这项更大，但是它却选择了$\hat y$。因此这种情况下能够得出：束搜索算法出错了。

- 第二种情况是$P(y^*|x) < P(\hat y|x)$  

  $y^*$ 是比 $\hat y$更好的翻译结果，不过根据RNN模型的结果，$y^*$成为输出的可能更小。因此在这种情况下，RNN模型却赋予它更低的可能性，是RNN模型出现了问题。这时值得在RNN模型上花更多时间。

所以误差分析过程看起来就像下面这样：

![](http://www.ai-start.com/dl2017/images/2689876529562b7d9a79bf868e7cbad7.png)

先遍历开发集，然后在其中找出算法产生的错误。假如说$P(y^*|x)$的值为$2 \times 10^{-10}$，而$P(\hat y|x)$的值为 $1 \times 10^{-10}$，这种情况下可以得知束搜索算法出错了，将它缩写为B。

接着继续遍历第二个错误，也许对于第二个例子来说，认为是RNN模型出现了问题，用缩写R来代表RNN。再接着你遍历了更多的例子，有时是束搜索算法出现了问题，有时是模型出现了问题，等等。

通过这个过程，就能够执行误差分析，得出束搜索算法和RNN模型出错的比例是多少。有了这样的误差分析过程，能够发现这两个部分中哪个是产生更多错误的原因，并且**==只有当发现是束搜索算法造成了大部分错误时，才值得花费努力增大定向宽度==**。相反地，如果发现是RNN模型出了更多错，可以进行更深层次的分析，来决定是需要增加正则化还是获取更多的训练数据，抑或是尝试一个不同的网络结构，或是其他方案。第三门课中，了解到各种技巧都能够应用在这里。

### 6. Bleu 得分（Bleu Score）

机器翻译的一大难题是一个法语句子可以有多种英文翻译而且都同样好，当有多个同样好的答案时，怎样评估一个机器翻译系统呢？常见的解决办法是，通过一个叫做BLEU得分（the BLEU score）的东西来解决。

BLEU得分做的就是，给定一个机器生成的翻译，它能够自动地计算一个分数来衡量机器翻译的好坏。直觉告诉我们，只要这个机器生成的翻译与任何一个人工翻译的结果足够接近，那么它就会得到一个高的BLEU分数。BLEU得分背后的理念是观察机器生成的翻译，然后看生成的词是否出现在少一个人工翻译参考之中。因此这些人工翻译的参考会包含在开发集或是测试集中。

![](http://www.ai-start.com/dl2017/images/5e854a803e36991a6e0dd4e33ecab930.png)

假设机器翻译系统缩写为MT。机器翻译 (MT)的输出是：the the the the the the the。这显然是一个十分糟糕的翻译。衡量机器翻译输出质量的方法之一是观察输出结果的每一个词看其是否出现在参考中，这被称做是机器翻译的精确度。这个情况下，机器翻译输出了七个单词并且这七个词中的每一个都出现在了参考1或是参考2。MT翻译的单词the在两个参考中都出现了，因此MT这个输出的精确度就是7/7看起来是一个极好的精确度。

因此取而代之的是用改良后的精确度评估方法：把每一个单词的记分上限定为它在参考句子中出现的最多次数。在参考1中，单词the出现了两次，在参考2中，单词the只出现了一次。2比1大，所以单词the的得分上限为2。有了这个改良后的精确度，MT输出句子的得分为2/7，因为在7个词中，最多只能给它2分。

![](http://www.ai-start.com/dl2017/images/0bc25316900ccd1d4dd25a35ec7c45c4.png)

目前为止，只是关注了单独的单词，在BLEU得分中，不仅仅考虑单个的单词，也要考虑成对的单词。定义一下二元词组（bigrams）的BLEU得分，bigram的意思就是**相邻的两个单词**。我们会考虑一元词组（unigrams）也就是单个单词以及二元词组（bigrams），即成对的词，同时也许会有更长的单词序列，比如说三元词组（trigrams）。现在来看看用二元词组来定义BLEU得分：

MT翻译的这里可能的二元词组有the cat ，接着是cat the，然后又是the cat。已经有了，就跳过它，然后下一个是cat on，然后是on the，最后是the mat。这些就是机器翻译中的二元词组，最后每个二元词组出现的次数如上图。

最后 ，定义一下截取计数Countclip。以Count列的值为基础，但是给算法设置得分上限，**上限值为二元词组出现在参考1或2中的最大次数**。the cat在两个参考中最多出现一次，截取它的计数为1。cat the它并没有出现在参考1和参考2中，将它截取为0，cat on 出现了一次记1分 and so on。把所有的这些计数都截取了一遍，实际上就是将它们降低，使之不大于二元词组出现在参考中的次数。最后修改后的二元词组的精确度就是count_clip之和。所以就是4除以二元词组的总个数6，因此2/3为二元词组改良后的精确度。

**公式化：**

将改良后的一元词组精确度定义为$P_1$，$P$代表的是精确度，下标1的意思是一元词组。MT 输出就是$\hat y$，$P_1$定义为Countclip(unigram)除以机器翻译输出中的一元词组出现次数之和：
$$
P_1 = \frac{\sum_{unigrams \ \hat y} Countclip(unigram)}{\sum_{unigrams \ \hat y} Count(unigram)}
$$
也可以定义$P_n$为$n$元词组精确度，用n-gram替代掉一元词组，所以就是机器翻译输出中的$n$元词组的countclip之和除以$n$元词组的出现次数之和。
$$
P_n = \frac{\sum_{n-grams \ \hat y} Countclip(n-gram)}{\sum_{n-grams \ \hat y} Count(n-gram)}
$$
这个方法都能够衡量机器翻译输出中与参考相似重复的程度。另外如果能够确信如果机器翻译输出与参考1或参考2完全一致的话，那么所有的这些$P_1$、$P_2$等等的值，都会等于1.0。为了得到改良后的1.0的精确度，只要输出与参考之一完全相同就能满足，不过有时即使输出结果并不完全与参考相同，也是有可能实现的。可以将它们以另一种方式组合，但愿仍能得到不错的翻译结果。

**总结：**

$P_n$就是$n$元词组这一项的BLEU得分，也是计算出的$n$元词组改良后的精确度。最后为了用一个值来表示需要计算的$P_1$，$P_2$， $P_3$，$P_4$，将它们用公式组合在一起，即取平均值，按照惯例BLEU得分被定义为：
$$
BP \cdot exp (\frac{1}{4}\sum\limits_{n=1}^{4}{{{P}_{n}}})
$$
事实表明，如果输出了一个非常短的翻译，那么它会更容易得到一个高精确度，因为输出的大部分词可能都出现在参考之中。比如极端例子，MT翻译只输出了一个单词the，但是实际的翻译是很长一句话。因此简短惩罚(BP)就是一个调整因子，它能够惩罚输出了太短翻译结果的翻译系统。

![](http://www.ai-start.com/dl2017/images/0f9646d825a0c254376e094b48523ed3.png)

BP的公式如上图所示。如果机器翻译系统实际上输出了比人工翻译结果更长的翻译，那么它就等于1，其他情况下就像图中公式，惩罚所有更短的翻译。

BLEU得分对于机器翻译来说，具有革命性的原因是因为它有一个相当不错的，虽然不是完美但是非常好的单一实数评估指标，因此它加快了整个机器翻译领域的进程。实践中，很少人会从零实现一个BLEU得分，有很多开源的实现结果，可以下载下来然后直接用来评估系统。

不过BLEU得分并没有用于语音识别，因为在语音识别当中，通常只有一个答案，可以用其他评估方法。不过在图像描述应用中，对于同一图片的不同描述，是同样好的。或者对于机器翻译来说，有多个一样好的翻译结果，BLEU得分就给了你一个能够自动评估的方法，帮助加快算法开发进程。

### 7. 注意力模型直观理解（Attention Model Intuition）

对编码解码的构架做一些改变，称为注意力模型（the Attention Model），这会使它工作得更好，这已经是深度学习中最重要的思想之一。

![](http://www.ai-start.com/dl2017/images/59279ff91bb69a94280e6735eba8ab99.png)

给定一个很长的法语句子，在神经网络中，绿色的编码器要做的就是读整个句子，然后记忆整个句子，再在感知机中传递。对于这个紫色的解码网络，将生成英文翻译。

人工翻译并不会通过读整个法语句子，再记忆里面的东西，然后从零开始，机械式地翻译成一个英语句子。人工翻译实际首先做的是先翻译出句子的部分，再看下一部分，看一部分，翻译一部分，一直这样下去。人工翻译会通过句子，一点一点地翻译，因为记忆整个的像这样的的句子是非常困难的。

上图中关于Blue Score的曲线，使用编码解码的结构，Blue Score的曲线如蓝线所示。它对于短句子效果非常好，会有一个相对高的得分。但是对于长句子而言，比如说大于30词的句子，它的表现就会变差。随着单词数量变化，短的句子会难以翻译，因为很难得到所有词。因为在神经网络中，记忆非常长句子是非常困难的，所以对于长的句子，效果也不好。

注意力模型，它翻译得很像人类，一次翻译句子的一部分。而且有了注意力模型，机器翻译系统的表现会像绿色曲线，因为翻译只会翻译句子的一部分，不会看到有一个巨大的下倾。这个下倾实际上衡量了神经网络记忆一个长句子的能力，这是我们不希望神经网络去做的事情。

![](http://www.ai-start.com/dl2017/images/3dcdd58eaa544a09e67eb892f8c732bf.png)

举例说明一下注意力模型，这里编码部分将使用一个双向的RNN，对于句子里的每五个单词，计算一个句子中单词的特征集，也有可能是周围的词。这里用$S$来表示解码RNN的隐藏状态。

- 如果希望在解码模型里第一个生成的单词将会是Jane。当尝试生成第一个词，应该先看第一个输入单词，或者它附近的词，但是别看太远。所以注意力模型就会计算注意力权重，用$\alpha^{<1,1>}$来表示生成第一个词时，应该放多少注意力在输入的第一块信息处。然后计算第二个，$\alpha^{<1,2>}$告诉计算第一个词Jane时，应该花多少注意力在输入的第二个词上面。接下去$\alpha^{<1,3>}$也同理。

  这些告诉我们，应该花多少注意力在$S^{<1>}$的输入内容$C$上，这就是RNN的一个单元。

- 对于RNN的第二步，将有一个新的隐藏状态$S^{<2>}$，也会用一个新的注意力权值集。将用$\alpha^{<2,1>}$来告诉应该花多少注意力在输入的第一个法语词上。然后同理$\alpha^{<2,2>}$，接下去也同理，应该花多少注意在词l'Afique上面。第一个生成的词Jane也会输入到这里，于是就有了需要花注意力的上下文。

- 根据第二步生成的词，来到第三步$S^{<3>}$，这是的输入，会再有上下文$C$，它取决于在不同的时间集上面的$\alpha^{<3>}$。

注意力模型告诉了要花注意力在不同的法语的输入词上面，当尝试翻译出第$t$个英文词，$\alpha^{<t,t'>}$告诉第$t$个英语单词应该花多少注意力在第$t'$个法语词上面。当生成一个特定的英文词时，允许它在每个时间步去看周围词距内的法语词要花多少注意力。

### 8. 注意力模型（Attention Model）

在上个视频中你已经见到了,注意力模型如何让一个神经网络只注意到一部分的输入句子。当它在生成句子的时候，更像人类翻译。让我们把这些想法转化成确切的式子，来实现注意力模型。

![](http://www.ai-start.com/dl2017/images/1e6b86a4e3690b4a0c6b8146ffa2f791.png)

假定有一个输入句子，并使用双向的RNN，去计算每个词的特征，实际上GRU和LSTM经常应用于这个。对于前向传播，第一个时间步的有前向传播的激活值${\overrightarrow{a}}^{<1>}$，有一个后向传播的激活值${\overleftarrow{a}}^{<1>}$，以此类推。一共向前了五个时间步，也向后了五个时间步，技术上把$a^{<0>}$设置为0。为了简化每个时间步的记号，$\alpha^{<t>}$就是时间步$t$上的特征向量：
$$
a^{<t>} = ({\overrightarrow{a}}^{<t>}, {\overleftarrow{a}}^{<t>})
$$
接下来对解码部分只进行前向计算，这是个单向的RNN，用状态$S$表示生成翻译。在第一个时间步，当输入上下文$C$的时候就会生成$y^{<1>}$，$C$取决于注意力参数，即$\alpha^{<1,1>}$，$\alpha^{<1,2>}$以此类推。同样的，参数$\alpha$告诉我们上下文有多少取决于得到的特征。所以定义上下文的方式实际上来源于被注意力权重加权的不同时间步中的特征值，用$t'$来索引法语句子里面的词：
$$
C^{<1>} = \sum_{t'}^{T_x}\alpha^{<1, t'>}a^{<t'>}
$$
注意力权重将会满足非负的条件，所以这是个0或正数，它们加起来等于1：
$$
\sum_{t'}^{T_x}\alpha^{<1,t'>} =1
$$
于是$\alpha^{<t,t'>}$就是$y^{<t>}$在$t'$时，应该花费在$a^{<t'>}$上注意力的数量。换句话说，当在$t$处生成输出词，应该花多少注意力在第$t'$个输入词上面，这是生成输出的其中一步。然后下一个时间步，会生成第二个输出，相似的，有了一个新的注意力权重集，再找到一个新的方式将$\alpha^{<2, t'>}a^{<t'>}$相加，就产生了一个新的上下文$C$，这个也是解码部分该单元的输入，且允许生成第二个词。解码部分的神经网络看起来是相当标准的RNN序列，这里有着上下文向量作为输出，可以一次一个词地生成翻译。也定义了如何通过这些注意力权重和输入句子的特征值来计算上下文向量。

![](http://www.ai-start.com/dl2017/images/b22dff4a3b1a4ea8c1ab201446e98889.png)

回忆一下$\alpha^{<t,t'>}$，是$y^{<t>}$花费在$a^{<t'>}$上的注意力数量。当尝试去生成第$t$个输出的翻译词：
$$
\alpha^{<t,t'>}=\frac{exp(e^{<t,t'>})}{\sum_{t'=1}^{T_x}exp(e^{<t,t'>})}
$$
在此之前要先计算$e^{<t,t'>}$，关键要用softmax确保权重$\alpha^{<t,t'>}$加起来等于1。对每一个固定的$t$值，这些$\alpha^{<t,t'>}$加起来等于1。关于如何计算这些$e$项，一种可以用的方式是上图所示的小的神经网络。$s^{<t-1>}$就是编码网络在上个时间步的状态，如果想要生成$y^{<t>}$，那么$s^{<t-1>}$就是上一时间步的隐藏状态。$s^{<t-1>}$是给小神经网络的其中一个输入，然后$a^{<t'>}$。

直观来想就是，如果想要决定花多少注意力在$t'$的激活值$a^{<t'>}$上。似乎它会很大程度上取决于上一个时间步的的隐藏状态的激活值$s^{<t-1>}$。因为上下文输入到这里，还没有计算出来当前状态的激活值，但是可以看看上一个生成翻译的RNN的隐藏状态。然后对于每一个位置$t'$的词都看向它们自己的特征值$a^{<t'>}$，所以$\alpha^{<t,t'>}$和$e^{<t,t'>}$应该取决于$s^{<t-1>}$和$a^{<t'>}$这两个量。

我们不知道具体函数是什么，但是可以做的事情就是训练一个很小的神经网络，去学习这个函数到底是什么。然后反向传播算法，相信梯度下降算法学到一个正确的函数。这个小型的神经网络做了一件相当棒的事情，告诉$y^{<t>}$应该花多少注意力在$a^{<t'>}$上面。然后$\frac{exp(e^{<t,t'>})}{\sum_{t'=1}^{T_x}exp(e^{<t,t'>})}$确保注意力权重加起来等于1，一次生成一个词。这个神经网络实际上会花注意力在右边的输入句子上，它会完全自动的通过梯度下降来学习。

这个算法的一个缺点就是算法的复杂度是$O(n^3)$的。如果有$T_x$个输入单词和$T_y$个输出单词，于是注意力参数的总数就会是$T_x\times T_y$，所以这个算法有着三次方的消耗。但是在机器翻译的应用上，输入和输出的句子一般不会太长，三次方的消耗是可以接受。

这个想法也被应用到了其他的很多问题中去了，比如图片加标题。当在写图片标题的时候，一次只花注意力在一部分的图片上面。

### 9. 语音识别（Speech recognition）

什么是语音视频问题？比如现在有一个音频片段$x$，任务是自动地生成文本$y$。

![](http://www.ai-start.com/dl2017/images/8da3e9cf049139a8e4a78503bd72e7fd.png)

考虑到人的耳朵并不会处理声音的原始波形，而是通过一种特殊的物理结构来测量这些不同频率和强度的声波。音频数据的常见预处理步骤，就是运行原始的音频片段，然后生成一个声谱图。同样地，横轴是时间，纵轴是声音的频率，而图中不同的颜色，显示了声波能量的大小，也就是在不同的时间和频率上这些声音有多大。通过这样的声谱图，可能还听过人们谈到过伪空白输出，也经常应用于预处理步骤。而人耳所做的计算和这个预处理过程非常相似。

语音识别方面，最令人振奋的趋势之一就是曾经有一段时间，语音识别系统是用音位（phonemes）来构建的，也就是人工设计的基本单元，语音学家过去把这些音作为声音的基本单元写下来，然后把这些语音分解成这些基本的声音单元。

不过在end-to-end模型中，发现这种音位表示法已经不再必要了，而是可以构建一个系统，通过向系统中输入音频片段（audio clip），然后直接输出音频的文本（a transcript），而不需要使用这种人工设计的表示方法。使这种方法成为可能的一件事就是用一个很大的数据集，所以语音识别的研究数据集可能长达300个小时，在学术界，甚至3000小时的文本音频数据集，都被认为是合理的大小。在文本音频数据集中同时包含$x$和$y$，通过深度学习算法大大推进了语音识别的进程。那么，如何建立一个语音识别系统呢？

![](http://www.ai-start.com/dl2017/images/4130b85a0694549f02bdf60f7c47a3d7.png)

比如用注意力模型，一件能做的事就是在输入音频的不同时间帧上，可以用一个注意力模型，来输出文本描述。

![](http://www.ai-start.com/dl2017/images/8f409fc3980b0be00dca49bf4fac2659.png)

还有一种效果也不错的方法，就是用CTC损失函数（CTC cost）来做语音识别。在实际中，可能是双向的LSTM结构，或者双向的GIU结构，并且通常是很深的模型。这里时间步的数量，它非常地大。在语音识别中，通常输入的时间步数量要比输出的时间步的数量多出很多。

举个例子，比如有一段10秒的音频，并且特征（features）是100赫兹的，即每秒有100个样本，于是这段10秒的音频片段就会有1000个输入，就是简单地用100赫兹乘上10秒。所以如果有1000个输入，但可能输出就没有1000个字母。这时要怎么办呢？

CTC损失函数允许RNN生成如上图的输出：ttt，这是一个特殊的字符，叫做空白符，这里用下划线表示，这句话开头的音可表示为h_eee\_ \_ \_，然后这里可能有个空格，用这个来表示空格，之后是\_ \_ \_qqq\_\_，这样的输出也被看做是正确的输出。下面这段输出对应的是"the q"。

CTC损失函数的一个基本规则是将空白符之间的重复的字符折叠起来，再说清楚一些，这里用下划线来表示这个特殊的空白符，它和空格是不一样的。the和quick之间有一个空格符，所以还要输出一个空格，通过把用空白符所分割的重复的字符折叠起来，然后就可以把这段序列折叠成"the q"。这样一来神经网络因为有很多这种重复的字符，和很多插入在其中的空白符，所以最后在得到的文本会短上很多。于是这句"the quick brown fox"包括空格一共有19个字符，在这样的情况下，通过允许神经网络有重复的字符和插入空白符使得它能强制输出1000个字符，甚至可以输出1000个$y​$值来表示这段19个字符长的输出。

### 10. 触发字检测（Trigger Word Detection）

有关于触发字检测系统的文献，还处于发展阶段。这里介绍一个能够使用好的算法。

![ ](http://www.ai-start.com/dl2017/images/f2da69f9fa6462c8e591e79db452f6c1.png)

现在有一个如上图的RNN结构，要做的就是把一个音频片段（an audio clip）计算出它的声谱图特征得到特征向量$x^{<1>}$, $x^{<2>}$, $x^{<3>}$..。然后把它放到RNN中，最后就是定义目标标签$y$。

假如音频片段中的一点是某人刚刚说完触发字，比如"Alexa"，或者"Okay Google"，那么在这一点之前，就可以在训练集中把目标标签都设为0，然后在这个点之后把目标标签设为1。假如在一段时间之后，触发字又被说了一次，比如是在这个点说的，那么就可以再次在这个点之后把目标标签设为1。这样的标签方案对于RNN来说是可行的，并且确实运行得非常不错。不过该算法一个明显的缺点就是它构建了一个很不平衡的训练集，0的数量比1多太多了。

这里还有一个解决方法，虽然听起来有点简单粗暴，但确实能使其变得更容易训练。比起只在一个时间步上去输出1，其实可以在输出变回0之前，多次输出1，或说在固定的一段时间内输出多个1。这样的话，就稍微提高了1与0的比例，这确实有些简单粗暴。

在音频片段中，触发字刚被说完之后，就把多个目标标签设为1。这里触发字又被说了一次，说完以后，又让RNN去输出1。

### 11. 结论和致谢（Conclusion and thank you）

深度学习是一种超能力，通过深度学习算法，可以让计算机拥有"视觉"，可以让计算机自己合成小说，或者合成音乐，可以让计算机将一种语言翻译成另一种，或者对放射影像进行定位然后进行医疗诊断，或者构建自动驾驶系统。当我们结束这一系列课程的时候，希望你能够使用这些思想来发展你的事业，追逐你的梦想，但最重要的是，去做你认为最合适的能对人类有贡献的事。

![](http://www.ai-start.com/dl2017/images/7eed3c9b0c0566bfdfec0b706d837329.png)

