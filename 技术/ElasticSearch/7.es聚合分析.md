[TOC]

关于聚合分析两个核心概念`bucket`和`metric`：

-   `bucket`：根据分组统计，每个不同的分组就是一个bucket
-   `metric`：对分组做不同的聚合分析操作（求和、平均值等），称为metric

对于聚合分析操作，用`aggs`表示一个聚合操作

聚合分析（基于doc_value正排索引）
---

如果聚合操作基于倒排索引，需要对满足query到的所有docs的agg_field中的值aggs（如果docs海量，aggs非常恐怖），然后拿这些aggs的分词依次到倒排索引中找到new_doc，看new_doc是否在docs中，非常麻烦。所以，需要依赖doc_value的正排索引。

###正排索引

正排索引，也会写入磁盘文件中，os cache先进行缓存，以提升访问doc value正排索引的性能。如果os cache内存大小不足够放得下整个正排索引，就会将doc value的数据写入磁盘文件中。

es官方是建议：es大量是基于os cache来进行缓存和提升性能的，不建议用jvm内存来进行缓存，那样会导致一定的gc开销和OOM问题。给jvm更少的内存，给os cache更大的内存。如:64g服务器，给jvm最多16g，几十个g的内存给os cache，os cache可以提升doc value和倒排索引的缓存和查询效率。

如果的确不需要doc value进行聚合等操作，那么可以禁用，减少磁盘空间占用：

```json
PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "my_field": {
          "type":"keyword"
          "doc_values": false  # 禁用doc_value
        }
      }
    }
  }
}
```

**doc_value是给不分词的field用的**，分词field是没有doc_value。在索引建立的时候，如果某个field是分词的，那么是不会给它建立doc_value正排索引的，因为分词后，占用的空间过于大，所以默认是不支持对分词field进行聚合操作的。

###fielddata

如果对text field进行聚合操作，需要打开`fielddata = true`。fielddata加载是lazy的，只有进行聚合操作时，才会存于内存中，和doc_value结构相似。然后才可以对分词的field执行聚合操作，而且会消耗很大的内存：

```json
POST /test_index/_mapping/test_type 
{
    "properties": {
        "test_field": {
            "type": "text",
          	# fielddata是在内存中的
          	# 因为分词的字符串，需要按照term进行聚合，需要执行更加复杂的算法和操作
          	# 如果基于磁盘和os cache，那么性能会很差
            "fielddata": true
        }
    }
}

# 也可以不设置fielddata=true，而直接使用内置field，内置field是不分词，对string field进行聚合
GET /test_index/test_type/_search 
{
    "size": 0,
    "aggs": {
        "group_by_test_field": {
            "terms": {
              	"field": "test_field.keyword"
            }
        }
    }
}
```

由于fielddata是加载到内存中的，可以设置占用内存大小：

```properties
# fielddata占用的内存超出了这个比例的限制，那么就清除掉内存中已有的fielddata数据
# 默认无限制，如果限制内存使用，会导致频繁evict和reload，大量IO性能损耗，以及内存碎片和gc
indices.fielddata.cache.size: 20%
```

对fielddata内存使用监控：

```
GET /_stats/fielddata?fields=*
GET /_nodes/stats/indices/fielddata?fields=*
GET /_nodes/stats/indices/fielddata?level=indices&fields=*
```

如果一次query load的feilddata超过总内存，就会oom。circuit breaker会估算query要加载的fielddata大小，如果超出总内存，就短路，query直接失败

```properties
# fielddata的内存限制，默认60%
indices.breaker.fielddata.limit：
# 执行聚合的内存限制，默认40%
indices.breaker.request.limit：
# 综合上面两个，限制在70%以内
indices.breaker.total.limit：
```

#### fielddata预加载

如果真的要对分词的field执行聚合，那么每次都在query-time现场生产fielddata并加载到内存中来，速度可能会比较慢，可以预先生成加载fielddata到内存中来：

```json
POST /test_index/_mapping/test_type
{
    "properties": {
        "test_field": {
            "type": "string",
            # 建立倒排索引的时候，会同步生成fielddata并且加载到内存中来
            # 这样分词field的聚合性能会大幅度增强
            "fielddata": {
                "loading" : "eager" 
            }
        }
    }
}
```

#### 序号标记预加载

许多doc的field有相同的值，可以进行global ordinal标记：
​	doc1: status1
​	doc2: status2
​	doc3: status2
​	doc4: status1
​	有很多重复值的情况，会进行global ordinal标记
​	status1 --> 0
​	status2 --> 1
​	doc1: 0
​	doc2: 1
​	doc3: 1
​	doc4: 0

这样以来可以减少重复字符串的出现的次数，减少内存的消耗

```json
POST /test_index/_mapping/test_type
{
    "properties": {
        "test_field": {
            "type": "string",
            "fielddata": {
                "loading" : "eager_global_ordinals" 
            }
        }
    }
}
```



## 分组聚合操作

### 相同值分组

```json
GET /tvs/sales/_search
{
  	# 指定展示记录数，为0不展示
    "size" : 0,
  	# aggs表示聚合操作
    "aggs" : { 
  		# 对每个aggs，都要起一个自定义名字
        "popular_colors" : { 
  			# 根据字段的值进行分组
  			# 将相同的值划分到一个bucket中
            "terms" : { 
              "field" : "color" #根据color字段分组
            }
        }
    }
}


....
"aggregations": {
  	# 本次聚合操作
    "popular_color": {
        "doc_count_error_upper_bound": 0,
        "sum_other_doc_count": 0,
  		# 根据指定的field划分出的buckets，默认按doc_count降序排列
        "buckets": [
          {
            "key": "红色",
            "doc_count": 4 # 分组内的数量
          },
          {
            "key": "绿色",
            "doc_count": 2
          },
          {
            "key": "蓝色",
            "doc_count": 2
          }
        ]
    }
}
...
```

### 区间分组

```json
GET /tvs/sales/_search
{
   "size" : 0,
   "aggs":{
      "my_price":{
         # term是将相同的值划分到一个bucket中
         # histogram是将在一个区间内的doc划分到一个分组内
         "histogram":{ 
            "field": "price",
        	# 区间为 0~2000，2000~40000，4000~6000
            "interval": 2000
         }
      }
   }
}

# date_histogram
GET /tvs/sales/_search
{
   "size" : 0,
   "aggs": {
      "my_sales": {
         # 日期区间划分
         "date_histogram": {
            "field": "sold_date",
        	# interval=quarter季度划分
            "interval": "month", 
            "format": "yyyy-MM-dd",
        	# 某个区间没有值，也要返回该区间，否则该区间忽略
            "min_doc_count" : 0, 
        	# 区间的起止范围
            "extended_bounds" : { 
                "min" : "2016-01-01",
                "max" : "2017-12-31"
            }
         }
      }
   }
}
```

## 多种metric操作

如果对每个分组内不指定`metric`操作，默认只返回`doc_count`。常用的操作有`count`，`avg`，`max`，`min`，`sum`：

```json
GET /tvs/sales/_search
{
   "size" : 0,
   "aggs": {
      "group_by_colors": {
         "terms": {
            "field": "color"
         },
         # 对每个分组的聚合操作，需要再次指定aggs
         # 其内不再是term而是具体的sum,avg等操作
         "aggs": {
            "avg_price": { "avg": { "field": "price" } },
            "min_price" : { "min": { "field": "price"} }, 
            "max_price" : { "max": { "field": "price"} },
            "sum_price" : { "sum": { "field": "price" } } 
         }
      }
   }
}
```

### 聚合排序

默认是按照聚合结果的doc_count进行降序排列，可以对分组结果指定排序：

```json
GET /tvs/sales/_search
{
  "size": 0,
  "aggs": {
    "popular_colors": {
      "terms": {
        "field": "color",
        # 按照平均值升序排列
        "order": {
          "avg_price": "asc"
        }
      },
      "aggs": {
        "avg_price": {
          "avg": {
            "field": "price"
          }
        }
      }
    }
  }
}
```

### 分组前几记录查询

```json
GET /website/blogs/_search 
{
    "size": 0, 
    "aggs": {
        "group_by_username": {
            "terms": {
                "field": "userInfo.username.keyword"
            },
            "aggs": {
                "top_blogs": {
                    # aggs-top_hits对分组后数据取前几条记录
                    "top_hits": {
                    	# 指定返回记录的source内容
                        "_source": {
                            "include": "title"
                        }, 
                        "size": 5
                    }
                }
            }
        }
    }
}
```



### 下钻操作

对分组内的结果再进行分组，就是在`aggs-term`内再执行`aggs-term`

```json
GET /tvs/sales/_search 
{
    "size":0,
  	# 先按颜色分组
    "aggs":{	
        "group_by_color":{
            "terms":{
                "field":"color"
            },
			# 对分组内的结果，再按品牌分组
            "aggs":{
                "group_by_brand":{
                    "terms":{
                        "field":"brand",
                      	# 对下钻结果排序，是在深层的bucket内排序
                        "order": {
                          	"avg_price": "asc"
                        }
                    },
                    "aggs":{
                        "brand_avg_price":{
                            "avg":{
                                "field":"price"
                            }
                        }
                    }
                },
              	# 对颜色分组统计平均值
                "color_avg_price":{
                    "avg":{
                        "field":"price"
                    }
                }
            }
        }
    }
}
```

### `_global` bucket

aggregation的scope默认是针对query后的结果进行聚合操作，如果想搜出来一个基于query的聚合，和一个基于全部数据的聚合：

```json
GET /tvs/sales/_search 
{
    "size":0,
    "query":{
        "term":{
            "brand":{
                "value":"长虹"
            }
        }
    },
    "aggs":{
      	# 基于query结果的
        "single_brand_avg_price":{
            "avg":{
                "field":"price"
            }
        },
		# 基于全部数据
        "all":{
          	# global 指定全部数据
            "global":{},
            "aggs":{
                "all_brand_avg_price":{
                    "avg":{
                        "field":"price"
                    }
                }
            }
        }
    }
}
```

### having操作

```json
GET /tvs/sales/_search 
{
    "size":0,
    "query":{
        "term":{
            "brand":{
                "value":"长虹"
            }
        }
    },
    "aggs":{
        "recent_150d":{
          	# aggs-filter相当于sql中的having，对聚合结果进行过滤
            "filter":{
                "range":{
                    "sold_date":{
                        "gte":"now-150d"
                    }
                }
            },
            "aggs":{
                "recent_150d_avg_price":{
                    "avg":{
                        "field":"price"
                    }
                }
            }
        }
    }
}
```

## 近似聚合算法

有些聚合算法，可以在多节点上并行得到结果，如求max，可以分别算出每个节点的最大值，然后取各个节点里最大的值。但有些聚合算法不好并行，如count(distinct)，每个节点分别去重统计数量，但各个节点间又可能有重复数据。所以es采用近似聚合方式，不完全准确，但速度快。

三角选则原则：（精准+实时+大数据，选则两个）

1.  精准+实时: 没有大数据，数据量很小，一般就是单击跑
2.  精准+大数据：hadoop，批处理，非实时，可以处理海量数据，保证精准，可能会跑几个小时
3.  大数据+实时：es，不精准，近似估计，可能会有百分之几的错误率

### 去重计数

```json
GET /tvs/sales/_search
{
    "size" : 0,
    "aggs" : {
        "distinct_brand" : {
            # aggs-cardinality就是count(distinct)算法
            "cardinality" : {
                "field" : "brand",
          		# cardinality算法，会占用precision_threshold * 8 byte 内存消耗
          		# 值设置的越大，占用内存越大,可以确保更多unique value的场景下，100%的准确
          		# 100 * 8 = 800个字节，可以保证数百万的unique value，错误率在5%以内
                "precision_threshold" : 100 
            }
        }
    }
}


# cardinality底层算法：HLL算法，会对所有的uqniue value取hash值，通过hash值近似去求distcint count
# 默认情况下，发送一个cardinality请求的时候，会动态地对所有的field value，取hash值; 
# 可以将hash算法前置
PUT /tvs/
{
    "mappings":{
        "sales":{
            "properties":{
                "brand":{
                    "type":"text",
                    "fields":{
                        "hash":{
                            "type":"murmur3"
                        }
                    }
                }
            }
        }
    }
}

GET /tvs/sales/_search
{
    "size" : 0,
    "aggs" : {
        "distinct_brand" : {
            "cardinality" : {
              # 对hash字段进行cardinality计算
              "field" : "brand.hash",
              "precision_threshold" : 100 
            }
        }
    }
}
```

### 百分比请求的最大值（tp99等）

```json
GET /website/logs/_search 
{
    "size": 0,
    "aggs": {
        "latency_percentiles": {
          	# aggs-percentiles 百分比请求的最大值是多少，相当于tp99等概念
          	# 常用于网站的延时统计等
            "percentiles": {
                "field": "latency",
                "percents": [50,95,99] # tp50,tp95,tp99
            }
        },
        "latency_avg": {
            "avg": {
              	"field": "latency"
            }
        }
    }
}
```

### 在某些值的占比是多少（比如请求在200ms和1000ms的占比）

```json
GET /website/logs/_search
{
    "size":0,
    "aggs":{
        "group_by_province":{
            "terms":{
                "field":"province"
            },
            "aggs":{
                "latency_percentile_ranks":{
                  	# 每个分组latency在200和1000的占比分别是多少
                    "percentile_ranks":{
                        "field":"latency",
                        "values":[200,1000],
                  		# TDigest算法最多节点个数限制，默认100，100 *20 = 2000个节点计算
                  		# 一个节点占用32字节，100 * 20 * 32 = 64KB
                  		# 节点越多，越准确，性能越差
                  		"compression":100
                    }
                }
            }
        }
    }
}


```



## bucket优化：深度优先-->广度优先

```json
{
    "aggs" : {
        "actors" : {
            "terms" : {
                "field" : "actors",
                # 外层分组取前10个
                "size" : 10,
                # 使用广度优先，先构建外层，然后根据外层结果再去构建内层
                # 而不是整体构建出来再进行整体裁剪，这样内外层都会舍弃大量数据
                "collect_mode" : "breadth_first" 
            },
            "aggs" : {
                "costars" : {
                    "terms" : {
                        "field" : "films",
                        "size" :  5
                    }
                }
            }
        }
    }
}
```

