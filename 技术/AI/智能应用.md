## 大模型

市面上已有许多不同类型的AI模型，每种模型适用于特定的场景

- 语言大模型：DeepSeek、OpenAI、Qianfan ...
  - 能生成流畅自然语言文本，用于聊天机器人、内容创作等场景，可根据用户输入生成回答、故事、文章等。
  - 这些模型通过海量文本数据训练，掌握语言模式与逻辑，但生成内容需人工审核，避免错误或不当信息。
  - 语言大模型在多语言翻译、语言学习辅助等方面也有广泛应用，帮助人们跨越语言障碍，提升跨文化交流效率。
- 嵌入模型：Amazon Bedrock、DashScope、ZhiPu AI ...
  - 将文本映射为向量，用于语义相似度计算、信息检索等，可快速找到与查询语义最相关的文档或数据。
  - 在推荐系统、搜索引擎优化等领域应用广泛，通过向量空间距离衡量语义相关性，提高检索准确性和效率。
  - 嵌入模型还可用于文本聚类、情感分析等任务，为数据挖掘和文本处理提供有力支持。
- 图片大模型：Google Imagen、OpenAI Dall·E、Xinference ...
  - 可根据文本描述生成高质量图像，可用于创意设计、虚拟场景构建等，为艺术创作和视觉内容生产带来新可能。
  - 这些模型基于深度学习架构，理解文本与图像间关系，生成符合描述的多样化图像，但生成图像版权和使用需谨慎处理。
  - 图片大模型在图像编辑、增强现实等领域也有应用，为图像处理和视觉体验提升提供技术支持。
- 评分重排名模型：Cohere、Jina、Voyage AI ...
  - 主要用于对搜索结果、推荐列表等进行重排序，提升结果的相关性和准确性。
  - 这些模型通过学习用户行为数据和反馈，优化排序算法，使用户更快速地找到所需信息。
  - 在电商推荐、新闻资讯推送等领域，评分重排名模型能够显著提高用户体验和平台的运营效率。



## 模型的不足及解决方案

虽然大模型目前看已经非常强大了，但是还是存在一定的问题的：

- 上下文窗口限制，不具备记忆能力

  上下文窗口大小的限制，比如GPT3.5窗口大小限制4096，不过各大厂商也都在卷窗口大小。

- 实时信息更新慢，新旧知识难以区分

  大模型都是预训练的通用模型。对于新鲜知识、专项的数据，大模型是无法知道的

- 无法为领域问题，提供专业靠谱的答案

  大模型基于相似度进行推理而生成答案的。对未知问题会出现幻觉，不受控。

- 无法灵活的操控外部系统

面对这些问题，可以从模型底层、应用层进行增强模型性能：

- 模型底层通过`微调、continue pretrain（继续预训练）`方式提升模型能力
- 应用层使用`提示词工程、函数调用、检索增强生成技术`几个方面进行增强大模型的性能。



## AI Agent

Al Agent是基于LLM的能够自主理解、自主规划决策、执行复杂任务的智能体。它通常具备以下关键特性：

1. **自主性（Autonomy）**：能够在一定范围内独立运行，不需要持续的人为干预。
2. **感知能力（Perception）**：能够通过传感器、API或其他数据源感知环境变化，如用户输入、系统状态或外部信息。
3. **推理与决策（Reasoning & Decision-Making）**：能够根据输入信息和预设目标，使用规则、逻辑或机器学习模型进行推理并做出决策。
4. **行动能力（Action）**：可以执行具体任务，如查询数据库、调用API、控制物理设备等。
5. **学习能力（Learning）**（可选）：有些AI Agent具备自我学习的能力，可以通过交互或反馈不断优化自身行为。

Agents不是chatGPT的升级版，它不仅告诉你"如何做"，更会帮你去做

**常见类型：**

- **规则驱动型（Rule-Based Agent）**：基于预定义的规则运行，例如专家系统。
- **基于搜索和规划的智能体（Search & Planning Agent）**：如自动路径规划、博弈AI（如AlphaGo）。
- **机器学习驱动型（ML-Based Agent）**：如聊天机器人、推荐系统，使用深度学习或强化学习进行决策。
- **多智能体系统（Multi-Agent System, MAS）**：多个AI Agent协作完成复杂任务，如自动驾驶车队管理。



## 关键技术

### Prompt Templates

优秀的提示词：

- 【立角色】：引导AI进入具体场景，赋予其行家身份
- 【述问题】：告诉AI你的困惑和问题，以及背景信息
- 【定目标】：告诉AI你的需求，希望达成的目标
- 【补要求】：告诉AI回答时注意什么，或者如何回复

提示词模板：

1. 将提示词提炼成模板
2. 实现提示词复用、版本管理、动态变化等



### 记忆功能

实现大模型聊天记忆非常简单，就是把用户所有的提问、大模型回答/产生的内容，放在一个`List<ChatMessage>`中，随着用户提问将List一并发送给大模型，让大模型具备了聊天记忆功能

- 随着提问不断增多，上下文会变的很长，很快超出大模型的上下文token限制。

  数据淘汰机制（窗口+token控制、内容进行总结摘要，减少存储内容）

- 如果多人同时使用大模型，如何隔离不同用户的上下文信息。

  不同聊天有不同的chatId



### Bringing Your Data & APIs to the AI Model

#### 1. 函数调用

函数调用功能可以**增强模型推理效果或进行其他外部操作**，包括信息检索、数据库操作、知识图谱搜索与推理、操作系统、触发外部操作等工具调用场景。

函数调用可以让大模型根据提示词输出一个请求调用函数的消息，其中包含所有需要调用的函数的信息、以及调用函数时所携带的参数信息。这是将大模型（LLM）能力与外部工具/API连接起来的方式。(大模型本身不会执行函数！！！)

主要使用的场景；

1. 信息检索（Information Retrieval）。

   此类工具可用于从外部资源（如数据库、Web服务、文件系统或者 WEB 搜索引擎）检索信息。

   目标：增强模型的知识，使其能够回答其其它方式不能回答的问题。例如，工具用于检索给定的位置天气、检索最新的新闻文章或者查询数据库。

2. 采取行动（Taking Action）

   此类工具可用于在软件系统中的执行操作（如发送电子邮件、在数据库中创建新记录、提交表单或触发工作流）。

   目标：自动执行原本需要人工干预或者显式编程的任务。例如，与机器人交互生成待办事项、创建会议安排等。

![](https://gtw.oss-cn-shanghai.aliyuncs.com/AI/%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8.jpg)

原理：

1. 当想让某个工具可供大模型使用时，会在 chat 请求中包含工具的定义（工具名称、工具参数、工具的描述）
2. 当模型决定调用工具时，大模型会返回一个响应，其中包括工具名称和输入的参数。
3. 应用程序负责使用工具名称来识别并使用提供的输入参数执行工具。
4. 工具调用的结果由应用程序处理。
5. 应用程序将工具调用结果发送给大模型。
6. 大模型使用工具调用结果作为附加上下文生成最终响应。

从整个过程来看，函数调用要与大模型进行两次交互；

- 第一次：通过提示词 + 函数定义 模型返回要调用的函数和函数所有需要的参数。
- 第二次：将第一次返回的函数调用结果 + 用户提示词 发送给大模型返回最终的结果。



#### 2. RAG

RAG（Retrieval-Augmented Generation）检索增强生成，即大模型LLM在回答问题或生成文本前，**会先从大量的文档中检索出相关信息，然后基于这些检索出的信息进行回答或生成文本**，从而可以提高回答的质量，而不是任由LLM来发挥。

![](https://gtw.oss-cn-shanghai.aliyuncs.com/AI/RAG.webp)

[RAG入门及RAG面临的挑战和解决方案](https://juejin.cn/post/7395866692796841999)

**Embedding模型**：

![](https://gtw.oss-cn-shanghai.aliyuncs.com/AI/%E5%90%91%E9%87%8F%E5%8C%96.jpg)

Embedding模型是指将高维度的数据（例如文字、图片、视频）映射到低维度空间的过程，`Embedding就相当于给文本穿上了“数字化”的外衣`，目的是让机器更好的理解和处理各种类型数据（文本、图片及视频）。

使用场景

- 自然语言处理：将单词或句子转换成向量表示，用于文本分类，机器翻译，情感分析等任务。
- 推荐系统：将用户和产品映射成向量表示，从而能够更好地理解用户的喜好和匹配物品。
- 图像处理：将图像转换成向量表示，用于图像分类，对象检测等任务。
- RAG系统：生成N维嵌入向量数据，使机器更好的理解和处理各种类型处理，为相似搜索提供基础。

解决问题

- 降维：在高维度空间中，数据点之间可能存在很大的距离，使得样本稀疏，嵌入模型可以减少数据稀疏性。
- 捕捉语义信息：Embedding不仅仅是降维，更重要的是，它能够捕捉到数据的语义信息。语义相近的词在向量上也是相近的
- 特征表示：原始数据的特征往往难以直接使用，通过嵌入模型可以将特征转换成更有意义的表示。
- 计算效率：在低维度空间中对数据进行处理和分析往往更加高效。

向量数据库的核心在于相似性搜索(Similarity Search)，这是向量数据库区别于传统数据库的重要特性



**数据工程的ETL（提取、转换、加载）**：

![](https://gtw.oss-cn-shanghai.aliyuncs.com/AI/%E6%A3%80%E7%B4%A2%E7%A6%BB%E7%BA%BF%E9%98%B6%E6%AE%B5.webp)

- 提取：解析Json格式（JsonReader）、解析纯文本格式（TextReader）、读取解析PDF文件（PagePdfDocumentReader、ParagraphPdfDocumentReader）、多种文档格式读取解析数据（TikaDocumentReader）
- 分割转换：将文档按照Token完整性进行拆分、关键词提取、文档摘要
- 加载：持久化到文件、向量数据库中，便于后续数据检索（召回）



**大模型调用**：

![](https://gtw.oss-cn-shanghai.aliyuncs.com/AI/%E6%A3%80%E7%B4%A2%E5%9C%A8%E7%BA%BF%E9%98%B6%E6%AE%B5.webp)

用户提问 -> 数据检索（召回） -> prompt拼装 -> LLM生成



### 结构化输出

传统上，AI 模型的输出以 `java.lang.String` ，即使要求回复是 JSON 格式也是如此。它返回的是JSON字符串，但它不是 JSON 数据结构。此外，在提示中要求”for JSON”并不是 100% 准确的



## 应用框架

目前市面上存在多种大模型、嵌入模型。模型定义、接口规范并不统一，当接入大模型时需要对其API细节进行了解。

框架简化Java 应用程序集成LLMs，统一接入大模型API，封装内部细节，可以无缝从一个大模型对接切换到另外一个模型而无需修改代码。提供包括各种工具：从低级提示模板、聊天记忆管理和输出解析等

- [Spring AI](https://spring.io/projects/spring-ai#overview)
- [LangChain4j](https://docs.langchain4j.dev/)
- [Jlama](https://github.com/tjake/Jlama)

