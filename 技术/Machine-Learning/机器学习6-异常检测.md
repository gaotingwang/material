[TOC]

异常检测
---

### 高斯分布（正态分布）

假设$x$是一个实数随机变量（即：$x\in R$），如果$x$的概率分布服从高斯分布：其中均值为$\mu$，方差为$\sigma^2$，那么将它记作：
$$
x \sim N(\mu,\sigma^2)
$$

> 这里的∼符号读作：”服从…分布”。大写字母$N$表示Normal (正态)，有两个参数，其中$\mu$表示均值，$σ^2$表示方差。

高斯分布的数学公式如下：
$$
p(x;\mu,\sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})
$$
![高斯分布](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83.png)

#### 高斯分布与$\mu$和$\sigma$关系

| $\mu=0,\sigma=1$                         | $\mu=0,\sigma=0.5$                       | $\mu=0,\sigma=2$                         | $\mu=3,\sigma=0.5$                       |
| ---------------------------------------- | ---------------------------------------- | ---------------------------------------- | ---------------------------------------- |
| ![高斯分布关系1](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB1.png) | ![高斯分布关系2](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB2.png) | ![高斯分布关系3](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB3.png) | ![高斯分布关系4](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB4.png) |

### 异常检查算法

1. 从样本中选择一些能体现出**异常行为的特征**$x_i$。

2. 分别计算出每个特征的参数$\mu_1,\ldots,\mu_n,\sigma_1^2,\ldots,\sigma_n^2$。
   $$
   \begin{split}
   \mu_j  & = & \frac{1}{m}\sum_{i=1}^{m}x_j^{(i)} \\
   \sigma_j^2 & = & \frac{1}{m}\sum_{i=1}^{m}(x_j^{(i)} - \mu_j)^2
   \end{split}
   $$

   ```matlab
   mu = mean(X);

   % 将均值复制多行
   % mus = mu(ones(m,1),:);
   mus = repmat(mu,m,1);

   sigma2 = mean((X - mus) .* (X - mus));
   ```

3. 给定一个新的样本$x$，计算出它对应的$p(x)$:
   $$
   p(x)=\prod_{j=1}^np(x_j;\mu_j,\sigma_j^2) = \prod_{j=1}^n\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})
   $$

   ```matlab
   function p = multivariateGaussian(X, mu, Sigma2)

   k = length(mu);

   if (size(Sigma2, 2) == 1) || (size(Sigma2, 1) == 1)
       Sigma2 = diag(Sigma2);
   end

   X = bsxfun(@minus, X, mu(:)');
   p = (2 * pi) ^ (- k / 2) * det(Sigma2) ^ (-0.5) * ...
       exp(-0.5 * sum(bsxfun(@times, X * pinv(Sigma2), X), 2));

   end
   ```

通过判断$p(x) < \epsilon$，来判断是否有异常发生。

### 异常检测系统构建

我们要考虑的异常检测问题是一个非监督问题，使用的是无标签数据。但如果有一些带标签的数据，能够指明哪些是异常样本，哪些是非异常样本，这就是要找的能够评价异常检测算法的标准方法。

#### 数据集划分

1. 对于训练集，还是需要把数据看成是无标签的，通常来讲这些样本都是**正常**的，但可能有一些异常的也被分到训练集里，这也没关系（毕竟异常的是少数）

   总样本3/5的这些样本都对应$y=0$的情况，通过用这些训练样本来拟合$p(x)=\prod_{j=1}^np(x_j;\mu_j,\sigma_j^2) $，以此来计算参数$\mu_1,\ldots,\mu_n,\sigma_1^2,\ldots,\sigma_n^2$。

2. 接下来我们要定义交叉验证集和测试集。通过这两个集合我们将得到异常检测算法。

   将剩余2/5的样本一半放入**交叉验证集**，另一半放入**测试集**中。同时将有异常的样本，同样也把它们进行一个分割：一半异常样本放到验证集中，剩下一半异常样本放入测试集中。

#### 获取$\epsilon$

如果有一组交叉验证集样本，一种选择参数$\epsilon$的方法就是通过尝试多个不同的$\epsilon$，然后选出一个使得$F1−score$最大的$\epsilon$，这个$\epsilon$就是在交叉验证集上表现最好的。之后就能用测试集来最终评价算法的表现了。

#### 异常算法的评估

预设一个比较小的$\epsilon$，对于$p(x) \lt \epsilon$的样本视为异常样本，然后分别在测试集合和交叉验证集上进行测试和验证。我们知道在测试集合交叉验证集上是存在$y=1$的异常样本的，只不过量比较少而已。

这与监督学习有些类似，在对有标签的数据进行预测。所以可以通过**对标签预测正确的次数来评价算法的好坏**。

当然这些标签会比较偏斜，因为$y=0$(也就是正常的样本)肯定是比出现$y=1$(也就是异常样本)的情况更多，那么总是预测$y=0$它的分类准确度自然会很高。因此我们应该算出以下数据来更科学的衡量算法的好坏：

- 应该算出**真阳性**、**假阳性**、**假阴性**和**真阴性**的比率来作为评价度量值

  ```matlab
  cvPredictions = double(pval < epsilon);

  % 真阳性
  tp = sum((cvPredictions == 1) & (yval == 1)); % 预测值和真实值都为1
  % 假阳性
  fp = sum((cvPredictions == 1) & (yval == 0)); % 预测值为1，真实值为0
  % 假阴性
  fn = sum((cvPredictions == 0) & (yval == 1)); % 预测值为0，真实值为1
  ```

- 也可以算出**查准率**和**召回率**

  ```matlab
  % 查准率
  prec = tp / (tp + fp);
  % 召回率
  rec = tp / (tp + fn);
  ```

- 计算出$F1−score$，通过一个很简单的数字来总结出查准和召回的大小。

  ```matlab
  % F1Score
  F1 = (2 * prec * rec) / (prec + rec);

  % 最终取使F1Score最大的epsilon
  ```

通过这些方法，就可以评价异常检测算法在交叉验证和测试集样本中的表现。

### 特征选取

事实上应用异常检测时，对它的效率影响最大的因素之一，是使用什么特征变量。

- 特征变量获取

  对应异常样本，在指定特征$x_1$下的$p(x_1)$并不低，我们无法从这一特征下区分出这一异常样本，需要引入另一特征$x_2$。

  选择异常检测需要考虑的特征时，先找出异常样本，然后尝试通过引入新的特征来验证对异常样本的识别的准确性。如果有所提高，就可以考虑引入这个特征。

  其实，解决这类问题的思路就是尝试组合新的特征，从而能更好的检测异常情况。

- 对不服从高斯分布的数据进行转换

  在异常检测算法中，做的事情之一就是使用正态(高斯)分布来对特征向量建模。通常情况下，都需要用直方图来可视化这些数据，这么做的原因是为了在使用算法之前，确保数据看起来是服从高斯分布的（当然即使数据并不是高斯分布，它也基本上可以良好地运行，但最好转换成高斯分布的样式之后在带入计算）。

  对于一个不服从高斯分布的数据进行转换的过程：

|                   原始数据                   |                $x^{0.5}$                 |                $x^{0.2}$                 |                $x^{0.1}$                 |                $x^{0.05}$                |                $\log(x)$                 |
| :--------------------------------------: | :--------------------------------------: | :--------------------------------------: | :--------------------------------------: | :--------------------------------------: | :--------------------------------------: |
| ![数据调整为高斯分布1](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%831.png) | ![数据调整为高斯分布2](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%832.png) | ![数据调整为高斯分布3](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%833.png) | ![数据调整为高斯分布4](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%834.png) | ![数据调整为高斯分布5](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%835.png) | ![数据调整为高斯分布6](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%836.png) |
|              ` hist(x,50)`               |            `hist(x.^0.5,50)`             |            `hist(x.^0.2,50)`             |            `hist(x.^0.1,50)`             |            `hist(x.^0.05,50)`            |            `hist(log(x),50)`             |

### 异常检测 VS 监督学习

既然有了带标签的数据，为什么不直接用监督学习的方法（比如逻辑回归或者神经网络）呢？下面这张表格对比了什么时候应该用什么算法：

|                   异常检测                   |                   监督学习                   |
| :--------------------------------------: | :--------------------------------------: |
|    正样本量很少(通常是在0\~20\~50个之间)，负样本很多的时候     |                正负样本都很多的时候                |
| 有多种不同的异常类型时（因为对任何算法来说，从大量正样本中去学习到异常具体是什么，都是困难的）；未知的异常与已知的异常完全不一样时，可以直接对负样本建模。 | 有足够多的正样本来让算法学习到对应的特征，并且在未知的正样本中，也和已知的样本是类似的。 |

在遇到具体情况时，要选择异常检查还是监督学习的方式。其实关键区别就是**在异常检测算法中只有一小撮正样本**，因此监督学习算法不能从这些样本中学到太多东西。

对于垃圾邮件的问题，能得到绝大多数不同类型的垃圾邮件，因为我们有大量的垃圾邮件样本的集合。所以为什么通常把垃圾邮件问题看作是监督学习问题的原因，虽然垃圾邮件的种类通常有太多太多 。

对于欺诈检测(fraud detection)，如果掌握了许多种不同类型的诈骗方法，并且只有相对较小的训练集（只有很少一部分用户有异常行为）那么会使用异常检测算法。当然，有时候欺诈检测的方法也可能会偏向于使用监督学习算法，但是如果并没有看到许多在网站上进行异常行为的用户样本，那么欺诈检测通常还是被当做是一个异常检测算法，而不是一个监督学习算法。

### 多元高斯分布

使用之前的异常检测算法，其实是以中心区域向外以正圆的形式扩散的。也就是说距离中心区域距离相等的点，对应的$p(x)$都是一样的，所以可能无法检测到这一个异常样本，因为它也处在一个$p(x)$比较大的范围内：

<img src="http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%831.png" width="400px" alt="多元高斯分布1"/>

为了解决异常检测算法的这一问题，使用改良版的异常检测算法，要用到叫做**多元高斯分布（多元正态分布）**。

在多元高斯分布中，对于$n$维特征，不需要对模型$p(x_1),p(x_2),\ldots,p(x_n)$分开，而要建立$p(x)$整体的模型。

1. 多元高斯分布的参数包括向量$\mu$和一个$n×n$的矩阵$\sum$（协方差矩阵）

$$
\begin{split}
\mu & = & \frac{1}{m}\sum_{i=1}^{m}x^{(i)} \\
\sum & = & \frac{1}{m}\sum_{i=1}^{m}(x^{(i)} - \mu)(x^{(i)} - \mu)^T
\end{split}
$$

1. 带入之后计算$p(x)$:

$$
p(x;\mu,\sum)=\frac{1}{(2\pi)^{\frac{n}{2}}\vert \sum \vert^{\frac{1}{2}}}exp(-\frac{1}{2}(x-\mu)^T{\sum}^{-1}(x-\mu))
$$

| $ \mu= \begin{bmatrix} 0 \\ 0 \end{bmatrix}\sum= \begin{bmatrix} 1   & 0  \\ 0   & 1\end{bmatrix}$ | $ \mu= \begin{bmatrix} 0 \\ 0 \end{bmatrix}\sum= \begin{bmatrix} 0.6   & 0  \\ 0   & 1\end{bmatrix}$ | $ \mu= \begin{bmatrix} 0 \\ 0 \end{bmatrix}\sum= \begin{bmatrix} 1   & 0.5  \\ 0.5   & 1\end{bmatrix}$ | $ \mu= \begin{bmatrix}1.5 \\ -0.5 \end{bmatrix}\sum= \begin{bmatrix} 1   & 0  \\ 0   & 1\end{bmatrix}$ |
| :--------------------------------------: | :--------------------------------------: | :--------------------------------------: | :--------------------------------------: |
| ![多元高斯关系1-1](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%85%B3%E7%B3%BB1-1.png) | ![多元高斯关系2-1](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%85%B3%E7%B3%BB2-1.png) | ![多元高斯关系3-1](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%85%B3%E7%B3%BB3-1.png) | ![多元高斯关系4-1](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%85%B3%E7%B3%BB4-1.png) |
| ![多元高斯关系1-2](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%85%B3%E7%B3%BB1-2.png) | ![多元高斯关系2-2](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%85%B3%E7%B3%BB2-2.png) | ![多元高斯关系3-2](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%85%B3%E7%B3%BB3-2.png) | ![多元高斯关系4-2](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%85%B3%E7%B3%BB4-2.png) |

不同的图片，能够帮助你了解**多元高斯分布**所能描述的概率分布是什么样。它最重要的优势就是能够描述当两个特征变量之间可能存在正相关或者是负相关关系的情况。

1. 最后，如果$p(x) \lt \epsilon$时，就把它标记为是一个异常样本，反之，如果$p(x) \geq \epsilon$则不标记为异常样本。

如果使用多元高斯分布来解决异常检测问题，你可能会得到这样一个高斯分布的概率模型：

<img src="http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%832.png" width="400px" alt="多元高斯分布2"/>

#### 多元高斯分布与原始模型关系

原始模型是一种等高线都沿着坐标轴方向的多元高斯分布，所以在**协方差矩阵$\sum$的非对角线元素都为0**的情况下，这两者是相同的：

即当：
$$
\sum = 
\begin{bmatrix}
 \sigma_1^2   & 0      & \cdots & 0      \\
 0  & \sigma_2^2       & \cdots & 0     \\
 \vdots & \vdots & \ddots & \vdots \\
 0  & 0      & \cdots & \sigma_n^2      \\
\end{bmatrix}
$$
则下面两个公式互等：
$$
\begin{split}
p(x) & = & p(x_1;\mu_1,\sigma_1^2)p(x_2;\mu_2,\sigma_2^2) \dots p(x_n;\mu_n,\sigma_n^2) \\
p(x;\mu,\sum) & = & \frac{1}{(2\pi)^{\frac{n}{2}}\vert \sum \vert^{\frac{1}{2}}}exp(-\frac{1}{2}(x-\mu)^T{\sum}^{-1}(x-\mu))
\end{split}
$$

|                   原始模型                   |                  多元高斯模型                  |
| :--------------------------------------: | :--------------------------------------: |
| 捕捉到这两个特征，建立一个新的特征$x_3$(比如$x3=\frac{x1}{x2}$)，去尝试手工组合并改变这个新的特征变量，从而使得算法能很好的工作。 |            自动捕捉不同特征变量之间的相关性。             |
|         运算量小(更适用于特征变量个数$n$很大的情况)         | 计算更复杂（$\sum$是$n×n$的矩阵，这里会涉及两个$n×n$的矩阵相乘的逻辑，之后要求逆计算量很大） |
|         即使训练样本数$m$很小的情况下，也能工作的很好         | 必须满足$m>n$，否则$\sum$不可逆（奇异矩阵）。这种情况下，还可以帮助你省去为了捕捉特征值组合而手动建立额外特征变量所花费的时间。 |

事实情况是，原始模型比较常用，而多元高斯模型比较少用。

#### 异常情况的应对

当在拟合多元高斯模型时，如果发现协方差矩阵$\sum$是**奇异的（不可逆的）**，一般只有两种情况：

- 第一种是它没有满足$m>n$的条件
- 第二种情况是，有冗余特征变量
  - 出现了两个完全一样的特征变量（可能不小心把同一个特征变量复制了两份）
  - 如果有$x_3=x_4+x_5$，这里$x_3$其实并没有包含额外的信息（一般为线性相关的这种），相对于$x_4$和$x_5$来说，它就是冗余特征变量。

