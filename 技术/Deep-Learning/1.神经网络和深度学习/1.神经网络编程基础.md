[TOC]

## 神经网络编程基础

为了能把训练集表示得更紧凑一点，定义一个矩阵用大写$X$的表示，它由输入向量$x^{(1)}$、$x^{(2)}$等组成，如下图放在矩阵的列中，把$x^{(1)}$作为第一列放在矩阵中，$x^{(2)}$作为第二列，$x^{(m)}$放到第$m$列，然后就得到了训练集矩阵$X$。所以这个矩阵有$m$列，然后这个矩阵的高度记为$n_x$，注意有时候可能因为其他某些原因，矩阵$X$会由训练样本按照行堆叠起来而不是列，如下图所示：$x^{(1)}$的转置直到$x^{(m)}$的转置，但是在实现神经网络的时候，**使用左边的这种形式，会让整个实现的过程变得更加简单**。

![数据集表示](http://www.ai-start.com/dl2017/images/55345ba411053da11ff843bbb3406369.png)

### 1. 逻辑回归(Logistic Regression)

对于二元分类问题来讲，给定一个输入特征向量$X$，一个算法的预测结果称之为$\hat{y}$，也就是对实际值 $y$ 的估计。$X$是一个$n_x$维的向量（相当于有$n_x$个特征的特征向量）。

我们用$w$来表示逻辑回归的参数，这也是一个$n_x$维向量（因为$w$实际上是特征权重，维度与特征向量相同），参数里面还有实数$b$（表示偏差）。所以给出输入$x$以及参数$w$和$b$之后，让$\hat{y}={{w}^{T}}x+b$。

这时候我们得到的是一个关于输入$x$的线性函数，实际上这是在做线性回归时所用到的，但是这对于二元分类问题来讲不是一个非常好的算法。因此在逻辑回归中，我们的输出$\hat{y}$应该是等于由上面得到的线性函数式子作为自变量的**sigmoid**函数中，将线性函数转换为非线性函数。
$$
\begin{eqnarray*}
\sigma(z) &&=&& \frac{1}{1 + e^{-z}}  \\
\hat{y} &&=&& \sigma({{w}^{T}}x+b) 
\end{eqnarray*}
$$
![sigmoid函数](http://www.ai-start.com/dl2017/images/7e304debcca5945a3443d56bcbdd2964.png)

在继续进行下一步之前，介绍一种符号惯例，可以让参数$w$和参数$b$分开。在符号上要注意的一点是**当我们对神经网络进行编程时经常会让参数$w$和参数$b$分开，在这里参数$b$对应的是一种偏置**。

在之前的机器学习课程里，可能已经见过处理这个问题时的其他符号表示。比如在某些例子里，定义一个额外的特征称之为${{x}_{0}}$，并且使它等于1，那么现在$X$就是一个$n_x + 1$维的变量，然后定义$\hat{y}=\sigma \left( {{\theta }^{T}}x \right)$的**sigmoid**函数。在这个备选的符号惯例里，有一个参数向量${{\theta }_{0}},{{\theta }_{1}},{{\theta }_{2}},...,{{\theta }_{{{n}_{x}}}}$，这样${{\theta }_{0}}$就充当了$b$，这是一个实数，而剩下的${{\theta }_{1}}$ 直到${{\theta }_{{{n}_{x}}}}$充当了$w$。

当你实现你的神经网络时，有一个比较简单的方法是保持$b$和$w$分开。

### 2. 逻辑回归的代价函数（Logistic Regression Cost Function）

为了让模型通过学习调整参数，需要给予一个$m$样本的训练集，这会让你在训练集上找到合适的参数$w$和参数$b$，来得到你的输出。

![逻辑回归函数](http://www.ai-start.com/dl2017/images/4c9a27b071ce9162dbbcdad3393061d2.png)

对训练集的预测值，我们将它写成$\hat{y}$，我们更希望它会接近于训练集中的$y$值，为了对上面的公式更详细的介绍，我们需要说明上面的定义是对一个训练样本来说的，这种形式也使用于每个训练样本，我们使用这些带有圆括号的上标来区分索引和样本，训练样本$i$所对应的预测值是${{y}^{(i)}}$,是用训练样本的${{w}^{T}}{{x}^{(i)}}+b$然后通过**sigmoid**函数来得到，也可以把$z$定义为${{z}^{(i)}}={{w}^{T}}{{x}^{(i)}}+b$,我们将使用上标$(i)$来指明数据表示$x$或者$y$或者$z$或者其他数据的第$i$个训练样本，这就是上标$(i)$的含义。

**损失函数：**

损失函数又叫做误差函数，用来衡量算法的运行情况，**Loss function:$L\left( \hat{y},y \right)$.**

我们通过这个$L$称为的损失函数，来衡量预测输出值和实际值有多接近。==一般我们用预测值和实际值的平方差或者它们平方差的一半，但是通常在逻辑回归中我们不这么做，因为当我们在学习逻辑回归参数的时候，会发现我们的优化目标不是凸优化，只能找到多个局部最优值，梯度下降法很可能找不到全局最优值== 。虽然平方差是一个不错的损失函数，但是我们在逻辑回归模型中会定义另外一个损失函数。

我们在逻辑回归中用到的损失函数是：
$$
L\left( \hat{y},y \right)=-y\log(\hat{y})-(1-y)\log (1-\hat{y})
$$
为什么要用这个函数作为逻辑损失函数？当我们使用平方误差作为损失函数的时候，会想要让这个误差尽可能地小。对于这个逻辑回归损失函数，我们也想让它尽可能地小，为了更好地理解这个损失函数怎么起作用，我们举两个例子：

- 当$y=1$时损失函数$L=-\log (\hat{y})$，如果想要损失函数$L$尽可能得小，那么$\hat{y}$就要尽可能大，因为**sigmoid**函数取值$[0,1]$，所以$\hat{y}$会无限接近于1。
- 当$y=0$时损失函数$L=-\log (1-\hat{y})$，如果想要损失函数$L$尽可能得小，那么$\hat{y}$就要尽可能小，因为**sigmoid**函数取值$[0,1]$，所以$\hat{y}$会无限接近于0。

**在这门课中有很多的函数效果和现在这个类似，就是如果$y$等于1，我们就尽可能让$\hat{y}$变大，如果$y$等于0，我们就尽可能让 $\hat{y}$ 变小。**

**代价函数：**

损失函数是在单个训练样本中定义的，它衡量的是算法在单个训练样本中表现如何，为了衡量算法在全部训练样本上的表现如何，我们需要定义一个算法的代价函数，算法的代价函数是对$m$个样本的损失函数求和然后除以$m$
$$
J\left( w,b \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{L\left( {{{\hat{y}}}^{(i)}},{{y}^{(i)}} \right)}=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( -{{y}^{(i)}}\log {{{\hat{y}}}^{(i)}}-(1-{{y}^{(i)}})\log (1-{{{\hat{y}}}^{(i)}}) \right)}
$$
损失函数只适用于像这样的单个训练样本，而代价函数是参数的总代价，所以==在训练逻辑回归模型时候，我们需要找到合适的$w$和$b$，来让代价函数 $J$ 的总代价降到最低== 。根据我们对逻辑回归算法的推导及对单个样本的损失函数的推导和针对算法所选用参数的总代价函数的推导，结果表明逻辑回归可以看做是一个非常小的神经网络。

### 3. 梯度下降法（Gradient Descent）

![梯度下降说明](http://www.ai-start.com/dl2017/images/c5eda5608fd2f4d846559ed8e89ed33c.jpg)

如图，代价函数是一个凸函数(**convex function**)，像一个大碗一样。最低点就是代价函数的最小值点。假定代价函数只有一个参数:
$$
\begin{eqnarray*}
&& Repeat\{ && \\
&& && w := w - \alpha\frac{dJ(w)}{dw} \\
&& \} &&
\end{eqnarray*}
$$
$a $ 表示学习率（**learning rate**），用来控制步长（**step**），即向下走一步的长度。$\frac{dJ(w)}{dw}$  就是函数$J(w)$对$w$ 求导（**derivative**）。逻辑回归的代价函数是含有两个参数的：
$$
\begin{eqnarray*}
w && := && w - \alpha\frac{\partial J(w,b)}{\partial w} \\
b && := && b - \alpha\frac{\partial J(w,b)}{\partial b} 
\end{eqnarray*}
$$
$\partial $ 表示求偏导符号，可以读作round，$\frac{\partial J(w,b)}{\partial w}$  就是函数$J(w,b)$ 对$w$ 求偏导，在代码中我们会使用$dw$ 表示这个结果，$\frac{\partial J(w,b)}{\partial b}$  就是函数$J(w,b)$对$b$ 求偏导，在代码中我们会使用$db$ 表示这个结果，小写字母$d$ 用在求导数（**derivative**），即函数只有一个参数，偏导数符号$\partial $ 用在求偏导（**partial derivative**），即函数含有两个以上的参数。

### 4. 逻辑回归中的梯度下降（Logistic Regression Gradient Descent）

假设样本只有两个特征${{x}_{1}}$和${{x}_{2}}$，为了计算$z$，我们需要输入参数${{w}_{1}}$、${{w}_{2}}$ 和$b$，除此之外还有特征值${{x}_{1}}$和${{x}_{2}}$。因此$z$的计算公式为：
$$
z={{w}_{1}}{{x}_{1}}+{{w}_{2}}{{x}_{2}}+b
$$
回想一下逻辑回归的公式定义如下：
$$
\hat{y}=\sigma (z)
$$
其中$\sigma \left( z \right)=\frac{1}{1+{{e}^{-z}}}$ ，$z={{w}^{T}}x+b$
损失函数：
$$
L( {{{\hat{y}}}^{(i)}},{{y}^{(i)}})=-{{y}^{(i)}}\log {{\hat{y}}^{(i)}}-(1-{{y}^{(i)}})\log (1-{{\hat{y}}^{(i)}})
$$
代价函数：
$$
J\left( w,b \right)=\frac{1}{m}\sum\nolimits_{i}^{m}{L( {{{\hat{y}}}^{(i)}},{{y}^{(i)}})}
$$
其中$\hat{y}$是逻辑回归的输出，$y$是样本的标签值。这里先复习下梯度下降法，$w$和$b$的修正量可以表达如下：
$$
\begin{eqnarray*}
w && := && w - \alpha\frac{\partial J(w,b)}{\partial w} \\
b && := && b - \alpha\frac{\partial J(w,b)}{\partial b} 
\end{eqnarray*}
$$

**计算损失函数对$w$和$b$的偏导：**

想要计算出的代价函数$L(\hat y,y)$对$w$和$b$的导数，需要反向的推倒出中间的所有偏导。

首先需要反向计算出代价函数$L(\hat y,y)$关于$\hat y$的导数，通过微积分得到：
$$
\frac{dL(\hat y,y)}{d\hat y}=-y/\hat y-(1-y)/(1-\hat y)
$$
现在可以再反向一步，计算$\hat y$对$z$的偏导：
$$
\begin{eqnarray*}
\frac{d\hat y}{dz} &&=&& \frac{e^{-z}}{(1 + e^{-z})^2} \\
&&=&& \frac{1 + e^{-z} - 1}{(1 + e^{-z})^2} \\
&&=&& \frac{1}{1 + e^{-z}} ( 1 - \frac{1}{1 + e^{-z}} ) \\
&&=&& \hat y \cdot (1-\hat y)
\end{eqnarray*}
$$
$$
dz = \frac{dL}{dz} = \frac{dL}{d\hat y} \cdot \frac{d\hat y}{dz}= \hat y - y
$$

现在进行最后一步反向推导，$z$对$w$和$b$的偏导:
$$
\begin{eqnarray*}
\frac{dz}{d{{w}_{1}}} &&=&& {{x}_{1}} \\
\frac{dz}{d{b}} &&=&& 1
\end{eqnarray*}
$$
最后，把所有的反向推倒进行汇总：
$$
\begin{eqnarray*}
dw_1 && = && \frac{dL}{dw_1} && = && \frac{dL}{d\hat y} \cdot \frac{d\hat y}{dz} \cdot \frac{dz}{d{{w}_{1}}} && = && {{x}_{1}} \cdot dz \\
db && = &&\frac{dL}{db} && = && \frac{dL}{d\hat y} \cdot \frac{d\hat y}{dz} \cdot \frac{dz}{d{b}} && = && dz
\end{eqnarray*}
$$
然后更新${{w}_{1}}:={{w}_{1}}-\alpha d{{w}_{1}}$，更新$b=:b-\alpha db$。这就是关于单个样本实例的梯度下降算法中参数更新一次的步骤。

### 5. m 个样本的梯度下降(Gradient Descent on m Examples)

上一章应用梯度下降在逻辑回归的一个训练样本上，现在想要把它应用在$m$个训练样本上。首先，让需要时刻记住关于损失函数$J(w,b)$的定义：
$$
J\left( w,b \right)=\frac{1}{m}\sum\nolimits_{i}^{m}{L( {{{\hat{y}}}^{(i)}},{{y}^{(i)}})}
$$
$J(w,b)$是有求和的全局代价函数，实际上是1到$m$项各个损失的平均。 所以$\frac{\partial J(w,b)}{\partial {{w}_{1}}}$它表明全局代价函数对${{w}_{1}}$的微分，==也同样是各项损失函数对${{w}_{1}}$微分的平均，即$dw_1 = (dw_1^{(1)} +dw_1^{(2)} + \cdots+ dw_1^{(m)} ) / m$==。

```python
J = 0;dw1 = 0;dw2 = 0;db = 0;
for i = 1 to m
    z(i) = wx(i) + b;
    a(i) = sigmoid(z(i));
    J += -[y(i)log(a(i)) + (1-y(i)）log(1-a(i));
    dz(i) = a(i) - y(i);
    dw1 += x1(i)dz(i); # 先算出全部样本对w1的偏导之和
    dw2 += x2(i)dz(i);
    db += dz(i);

# 计算均值                            
J /= m; # J = 全部损失函数之和的均值
dw1 /= m; # J对w1的微分最后取各项对w1微分的均值
dw2 /= m;
db /= m;
                            
# 梯度下降下一次使用的w,b      
w = w - alpha * dw; 
b = b - alpha * db;
```

当应用深度学习算法，你会发现在代码中显式地使用**for**循环使算法很低效，同时在深度学习领域会有越来越大的数据集。所以算法没有显式的**for**循环会是重要的，并且会帮助你适用于更大的数据集。所以这里有一些叫做向量化技术,它可以允许你的代码摆脱这些显式的**for**循环。

### 6. 向量化(Vectorization)

定义：$\color{blue}{X = \begin{pmatrix}  x_1^{(1)} & x_1^{(2)} & \cdots & x_1^{(m)} \\  x_2^{(1)} & x_2^{(2)} & \cdots & x_2^{(m)} \\ \vdots& \vdots & \ddots & \vdots \\ x_n^{(1)} & x_n^{(2)} & \cdots & x_n^{(m)} \end{pmatrix}}$，$\color{blue}{W =\begin{bmatrix}w_1\\ w_2\\ \vdots \\w_n \end{bmatrix}}$，同理$\color{blue}{dW = \begin{bmatrix}dw_1\\ dw_2\\ \vdots \\dw_n \end{bmatrix}}$

根据公式可得出：$\color{red}{Z=W^{T} \cdot X + b}$，$\color{blue}{Z=\begin{bmatrix}z^{(1)},z^{(2)} ,\cdots,z^{(m)}  \end{bmatrix}}$

$\color{red}{\hat Y = \sigma(Z)}$，$\color{blue}{Y=\begin{bmatrix}y^{(1)},y^{(2)} ,\cdots,y^{(m)}  \end{bmatrix}}$

根据推导的$dz$求导公式：$\color{red}{dZ = \hat Y - Y}$，$\color{blue}{dZ=\begin{bmatrix}dz^{(1)},dz^{(2)} ,\cdots,dz^{(m)}  \end{bmatrix}}$

根据$dw_1 = (dw_1^{(1)} +dw_1^{(2)} + \cdots+ dw_1^{(m)} ) / m$，其中$dw_1^{(1)} = x_1^{(1)} \cdot dz^{(1)} / m$，得出$\color{red}{dW = \frac{1}{m} \cdot X \cdot dZ^T}$

最后$db$为所有$dz$的平均数$\color{red}{db = \frac{1}{m} \cdot sum(dZ)}$

### 7. logistic 损失函数的解释

在逻辑回归中，需要预测的结果$\hat{y}$ ，约定 $\hat{y}=p(y=1|x)$ ，即算法的输出$\hat{y}$ 是给定训练样本 $x$ 条件下 $y$ 等于1的概率。因此，如果 $\hat{y}$ 代表 $y=1$ 的概率，那么$1-\hat{y}$就是 $y=0$的概率。接下来，我们就来分析这两个条件概率公式。
$$
\begin{eqnarray*}
If & & y=1: & & p(y|x)=\hat y \\
If & & y=0: & & p(y|x)=1-\hat y
\end{eqnarray*}
$$
这两个条件概率公式定义形式为 $p(y|x)$并且代表了 $y=0$ 或者 $y=1$ 这两种情况，我们可以将这两个公式合并成一个公式。需要指出的是我们讨论的是二分类问题的损失函数，因此，$y$的取值只能是0或者1。上述的两个条件概率公式可以合并成如下公式：
$$
p(y|x)={\hat{y}}^{y}{(1-\hat{y})}^{(1-y)}
$$

- 假设 $y=1$，因为 $\hat{y}$的1次方等于$\hat{y}$，则$p = \hat y^1\cdot{(1-\hat{y})}^{(1-1)}$。因此当$y=1$时 $p(y|x)=\hat{y}$。
- 当 $y=0$ 时，$p = \hat y^0\cdot{(1-\hat{y})}^{(1-0)}$，所以$p(y|x)=1-\hat{y}$。

由于$\log$ 函数是严格单调递增的函数，最大化 $\log(p(y|x))$ 等价于最大化 $p(y|x)$ 并且地计算 $p(y|x)$ 的 $\log$对数，就是计算 $\log({\hat{y}}^{(y)}{(1-\hat{y})}^{(1-y)})$通过对数函数化简为：
$$
\log({\hat{y}}^{(y)}{(1-\hat{y})}^{(1-y)}) = \log\hat y^{(y)} + \log(1-\hat y)^{(1-y)} = ylog\hat{y}+(1-y)log(1-\hat{y})
$$
而这就是前面提到的损失函数的负数 $(-L(\hat{y},y))$ ，前面有一个负号的原因是当训练学习算法时需要算法输出值的概率是最大的（以最大的概率预测这个值），然而在逻辑回归中我们需要最小化损失函数，因此最小化损失函数与最大化条件概率的对数 $\log(p(y|x))$ 关联起来了，因此这就是单个训练样本的损失函数表达式。

关于代价函数，在 $m$个训练样本中，假设所有的训练样本是独立同分布的，这些样本的联合概率就是每个样本概率的乘积:
$$
P\left(\text{labels  in training set} \right) = \prod_{i =1}^{m}{P(y^{(i)}|x^{(i)})}
$$
如果想做最大似然估计，需要寻找一组参数，使得给定样本的观测值概率最大。令这个概率最大化等价于令其对数最大化，在等式两边取对数：
$$
\log p\left( \text{labels  in  training set} \right) = \log\prod_{i =1}^{m}{P(y^{(i)}|x^{(i)})} = \sum_{i = 1}^{m}{\log P(y^{(i)}|x^{(i)})} = \sum_{i =1}^{m}{- L(\hat y^{(i)},y^{(i)})}
$$
在统计学里面，有一个方法叫做最大似然估计，即求出一组参数，使这个式子取最大值，也就是说，使得这个式子取最大值，$\sum_{i= 1}^{m}{- L(\hat y^{(i)},y^{(i)})}$，可以将负号移到求和符号的外面，$- \sum_{i =1}^{m}{L(\hat y^{(i)},y^{(i)})}$，由于训练模型时，目标是让成本函数最小化，所以不是直接用最大似然概率，要去掉这里的负号，这样就推导出了前面给出的logistic回归的成本函数$J(w,b)= \sum_{i = 1}^{m}{L(\hat y^{(i)},y^{\hat( i)})}$。最后为了方便，可以对成本函数进行适当的缩放，就在前面加一个额外的常数因子$\frac{1}{m}$，即:$J(w,b)= \frac{1}{m}\sum_{i = 1}^{m}{L(\hat y^{(i)},y^{(i)})}$。

总结一下，为了最小化成本函数$J(w,b)​$，我们从**logistic**回归模型的最大似然估计的角度出发，假设训练集中的样本都是独立同分布的条件下。