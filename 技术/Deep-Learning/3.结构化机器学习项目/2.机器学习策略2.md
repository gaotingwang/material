[TOC]

机器学习策略（2）(ML Strategy (2))
---

### 1. 进行误差分析（Carrying out error analysis）

学习算法还没有达到人类的表现，那么人工检查一下算法犯的错误也许可以让你了解接下来应该做什么，这个过程称为错误分析。

假设正在调试猫分类器，然后取得了90%准确率，相当于10%错误，在开发集(dev-set)上做到这样，说明离希望的目标还有很远。也许看了一下算法分类出错的例子，注意到算法将一些狗分类为猫。问题在于，是不是应该去开始做一个项目专门处理狗？这项目可能需要花费几个月的时间才能让算法在狗图片上犯更少的错误，这样做值得吗？或者与其花几个月做这个项目，有可能最后发现这样一点用都没有。

这里有个错误分析流程，可以让我们很快知道这个方向是否值得努力。

**手工操作：**

首先，收集一下比如说100个错误标记的开发集(dev-set)样本，然后手动检查，一次只看一个，看看你的开发集(dev-set)里有多少错误标记的样本是狗。假设事实上，100个错误标记样本中只有5%是狗，这意味着100个样本，在典型的100个出错样本中，即使完全解决了狗的问题，也只能修正这100个错误中的5个，那就是10%下降到9.5%。你就可以确定这样花时间不好，或者也许应该花时间，但至少这个分析给出了一个上限。在机器学习中，称之为性能上限，就意味着，最好能到哪里，完全解决狗的问题可以产生多少帮助。

假设观察一下这100个错误标记的开发集(dev-set)样本，发现实际有50张图都是狗，所以有50%都是狗的照片，现在花时间去解决狗的问题可能效果就很好。这种情况下，如果真的解决了狗的问题，那么错误率可能就从10%下降到5%了。然后你可能觉得让错误率减半的方向值得一试，可以集中精力减少错误标记的狗图的问题。

在机器学习中，有时候我们很鄙视手工操作。但如果要搭建应用系统，那这个简单的人工统计步骤，错误分析，可以节省大量时间，可以迅速决定什么是最重要的，或者最有希望的方向。实际上，用人工简短的几十分钟，可以决定是不是把未来几个月的时间投入到解决错误标记的狗图这个问题。

**如何使用错误分析来评估某个想法：**

比如样本里狗的问题是否值得解决。有时在做错误分析时，也可以同时并行评估几个想法。

![](http://www.ai-start.com/dl2017/images/d8f6d23ebbf3031932034f29f1630dc2.png)

建立这样一个表格，通常可以用电子表格来做，普通文本文件也可以。在最左边，人工过一遍想分析的图像集，所以图像可能是从1到100。电子表格的第一行就对应要评估的想法，所以狗的问题，猫科动物的问题，模糊图像的问题，通常也会在电子表格中留下空位来写评论。

在错误分析过程中，看看算法识别错误的开发集(dev-set)样本，如果发现第一张识别错误的图片是狗图，那么就在那里打个勾，为了帮助自己记住这些图片，有时可以在评论里注释。也许最后检查的图像中8%是狗，可能43%属于大猫，61%属于模糊。

在这个步骤做到一半时，有时你可能会发现其他错误类型，比如说可能发现有**Instagram**滤镜，那些花哨的图像滤镜，干扰了分类器。在这种情况下，实际上可以在错误分析途中，可以增加这样一列，然后再过一遍，并确定这个新的错误类型占了多少百分比，这个分析步骤的结果可以给出一个估计，是否值得去处理每个不同的错误类型。

这个分析没有给出一个严格的数学公式，告诉你应该做什么，但它能让你对应该选择哪些手段有个概念。它也告诉你，相应的改善能提升多大的性能。也许可以选择其中两个，或者团队成员足够多，可以把团队可以分成两个团队，其中一个想办法改善大猫的识别，另一个团队想办法改善模糊图片的识别。

这个快速统计的步骤，可以经常做，最多需要几小时，就可以真正帮助我们**选出高优先级任务**，并了解每种手段对**性能有多大提升空间**。

**总结：**

总结一下，**==进行错误分析，找一组错误样本，可能在你的开发集(dev-set)里或者测试集(test-set)里，观察错误标记的样本，统计属于不同错误类型的错误数量。在这个过程中，归纳出新的错误类型。如果发现新的干扰项，就可以在途中新建一个错误类型==**。

总之，通过统计不同错误标记类型占总数的百分比，可以发现哪些问题需要优先解决，或者提供构思新优化方向的灵感。

### 2. 清除标注错误的数据（Cleaning up Incorrectly labeled data）

如果发现有些输出标签 $y$ 是错的，是否值得花时间去修正这些标签呢？

首先，来考虑训练集(train-set)，事实证明，深度学习算法对于训练集(train-set)中的随机错误是相当健壮的（**robust**）。只要这些错误样本离随机错误不太远，如果错误足够随机，那么放着这些错误不管可能也没问题，而不要花太多时间修复它们。只要总数据集总足够大，实际错误率可能不会太高。

深度学习算法对随机误差很健壮，但对系统性的错误就没那么健壮了。比如说，如果做标记的人一直把白色的狗标记成猫，那就成问题了。因为分类器学习之后，会把所有白色的狗都分类为猫。但随机错误或近似随机错误，对于大多数深度学习算法来说不成问题。

如果是开发集(dev-set)和测试集(test-set)中都有这些标记出错的样本呢？如果担心开发集(dev-set)或测试集(test-set)上标记出错的样本带来的影响，一般建议在错误分析时，添加一个额外的列。

![](http://www.ai-start.com/dl2017/images/e5c7f1005d695914f4a2fc988aa46821.png)

这样可以统计标签错误的样本数。有时对于其中的少数样本，分类器输出和标签不同，是因为标签错了，而不是分类器出错，然后统计出所有错误类型的百分。

现在问题是，是否值得修正这6%标记出错的样本？如果这些标记错误严重影响了你在开发集(dev-set)上评估算法的能力，那么就应该去花时间修正错误的标签。但是，如果它们没有严重影响到你用开发集(dev-set)评估成本偏差的能力，那么可能就不应该花宝贵的时间去处理。

- 假设分类器有10%错误率，那么应该看看错误标记引起的错误的数量或者百分比。在这种情况下，6％的错误来自标记出错，所以其中0.6%是因为标记出错，剩下的占9.4%，是其他原因导致的。在这种情况下，有9.4%错误率需要集中精力修正，而标记出错导致的错误是总体错误的一小部分而已。如果一定要这么做，也可以手工修正各种错误标签，但也许这不是当下最重要的任务。
- 假设把错误率降到了2％，但总体错误中的0.6%还是标记出错导致的。所以现在，0.6%除以2%，实际上错误分析中变成30%标签而不是6%标签了。有那么多错误样本其实是因为标记出错导致的，所以现在其他原因导致的错误是1.4%。当测得的那么大一部分的错误都是开发集(dev-set)标记出错导致的，那似乎修正开发集(dev-set)里的错误标签似乎更有价值。
- 如果开发集(dev-set)的主要目的是：希望用它来从两个分类器$A$和$B$中选择一个。所以在测试两个分类器$A$和$B$时，在开发集(dev-set)上一个有2.1%错误率，另一个有1.9%错误率。这时不能再信任开发集(dev-set)了，因为它无法告诉你这个分类器是否比这个好，因为0.6%的错误率是标记出错导致的。因为可能分类器$A$中，标记出错对算法错误的整体评估标准有严重的影响。而分类器$B$中，标记出错对算法影响的百分比相对较小的。现在就有很好的理由去修正开发集(dev-set)里的错误标签。

如果决定要去修正开发集(dev-set)数据，这里还有一些额外的方针和原则需要考虑：

1. 首先不管用什么修正手段，都要==**同时作用到开发集(dev-set)和测试集(test-set)上**==，因为开发和测试集(test-set)必须来自相同的分布。

2. 其次，强烈建议要==同时考虑检验算法**判断正确**和**判断错误**的样本==，要检查算法出错的样本很容易，只需要看看哪些样本需要修正。但还有可能有些样本算法判断正确，那些也需要修正。

   如果只修正算法出错的样本，算法的偏差估计可能会变大，这会让算法有一点不公平的优势。

   这点不是很容易做，所以通常不会这么做。通常不会这么做的原因是，如果分类器很准确，那么判断错的次数比判断正确的次数要少得多。那么就有2%出错，98%都是对的，所以更容易检查2%数据上的标签，然而检查98%数据上的标签要花的时间长得多，所以通常不这么做，但也是要考虑到的。

3. 最后，修正训练集(train-set)中的标签其实相对没那么重要，可能决定只修正开发集(dev-set)和测试集(test-set)中的标签，因为它们通常比训练集(train-set)小得多。可能不想把所有额外的精力投入到修正大得多的训练集(train-set)中的标签，所以这样其实是可以的。

在构造实际系统时，通常需要更多的人工错误分析，更多的人类见解来架构这些系统。其次，如果在搭建你的机器学习系统的话，然后你想确定应该优先尝试哪些想法，或者哪些方向，花时间亲自检查数据非常值得。

### 3. 快速搭建你的第一个系统，并进行迭代（Build your first system quickly, then iterate）

一般来说，对于几乎所有的机器学习程序可能会有50个不同的方向可以前进，并且每个方向都是相对合理的可以改善你的系统。但挑战在于，如何选择一个方向集中精力处理。

**如果想搭建全新的机器学习程序，就是快速搭好第一个系统，然后开始迭代。**

- 快速设立开发集(dev-set)和测试集(test-set)还有指标，这样就决定了目标所在，如果目标定错了，之后改也是可以的，但**一定要设立某个目标**。

- 然后马上搭好一个机器学习系统原型，然后用训练集(train-set)训练一下，看看效果，开始理解算法表现如何，在开发集(dev-set)测试集(test-set)，评估指标上表现如何。

- 当建立第一个系统后，就可以马上用到之前说的偏差方差分析，还有之前的错误分析，来确定下一步优先做什么。

  比如错误分析让你了解到大部分的错误的来源是说话人远离麦克风，这对语音识别构成特殊挑战，那么你就有很好的理由去集中精力研究这些技术，所谓远场语音识别的技术，这基本上就是处理说话人离麦克风很远的情况。

==建立初始系统的所有意义在于，它可以是一个快速和粗糙的实现。初始系统的全部意义在于，有一个学习过的系统，有一个训练过的系统，让你确定偏差方差的范围，就**可以知道下一步应该优先做什么**。让你能够进行错误分析，可以观察一些错误，然后想出所有能走的方向，哪些是实际上最有希望的方向==。

所以建议快速建立你的第一个系统，然后迭代。不过如果你在这个应用程序领域有很多经验，这个建议适用程度要低一些。还有一种情况适应程度更低，当这个领域有很多可以借鉴的学术文献，处理的问题和你要解决的几乎完全相同，比如说，人脸识别就有很多学术文献，如果你尝试搭建一个人脸识别设备，那么可以从现有大量学术文献为基础出发，一开始就搭建比较复杂的系统。

如果你第一次处理某个新问题，不鼓励你想太多，或者把第一个系统弄得太复杂。建议先构建一些快速而粗糙的实现，然后用来帮你找到改善系统要优先处理的方向。

### 4. 在不同的划分上进行训练并测试（Training and testing on different distributions）

在深度学习时代，越来越多的团队都用来自和开发集(dev-set)、测试集(test-set)分布不同的数据来训练，这里有一些微妙的地方，一些最佳做法来处理训练集(train-set)和测试集(test-set)存在差异的情况。

假设在开发一个手机应用，用户会上传他们用手机拍摄的照片，想识别用户从应用中上传的图片是不是猫。现在你有两个数据来源，一个是真正关心的数据分布，来自应用上传的数据，这些照片一般更业余，有些甚至很模糊，只收集到10,000张照片。另一个数据来源就是可以用爬虫程序挖掘网页直接下载，可以下载很多高分辨率、拍摄专业的猫图片，大约20万张。困境在于，这20万张图片并不完全来自你想要的分布，那么可以怎么做呢？

- 有一种选择，是将两组数据合并在一起，然后把这21万张照片随机分配到训练、开发和测试集(test-set)中。这样做好处在于：训练集(train-set)、开发集(dev-set)和测试集(test-set)都来自同一分布，这样更好管理。

  坏处在于，这坏处还不小，如果观察开发集(dev-set)，这2500个样本其中很多图片都来自网页下载的图片，并不是我们真正关心的数据分布，真正要处理的是来自手机的图片。设立开发集(dev-set)的目的是告诉团队去瞄准的目标，而现在瞄准目标的方式，大部分精力都用在优化来自网页下载的图片，这其实不是我们想要的，所以不建议使用第一个选项。

- 建议走另外一条路，训练集(train-set)是来自网页下载的200,000张图片，然后再加上5000张来自手机上传的图片。然后，开发集(dev-set)就是2500张来自应用的图片，测试集(test-set)也是2500张来自应用的图片。

  这样将数据分成训练集(train-set)、开发集(dev-set)和测试集(test-set)的好处在于，现在瞄准的目标就是我们想要处理的目标。我们试试搭建一个学习系统，让系统在处理手机上传图片分布时效果良好。缺点在于，当然了，现在训练集(train-set)分布和开发集(dev-set)、测试集(test-set)分布并不一样。但事实证明，这样把数据分成训练、开发和测试集(test-set)，在长期能带来更好的系统性能。以后会讨论一些特殊的技巧，可以处理训练集(train-set)的分布和开发集(dev-set)和测试集(test-set)分布不一样的情况。

让训练集(train-set)数据来自和开发集(dev-set)、测试集(test-set)不同的分布，这样就可以有更多的训练数据。在这些样本中，这将改善你的学习算法。

### 5. 不匹配数据划分的偏差和方差（Bias and Variance with mismatched data distributions）

当训练集(train-set)来自和开发集(dev-set)、测试集(test-set)不同分布时，分析偏差和方差的方式可能不一样。

继续用猫分类器为例，人类在这个任务上能做到几乎完美，所以贝叶斯错误率在这个问题里几乎是0%。所以要进行错误率分析，通常需要看训练误差，也要看看开发集(dev-set)的误差。比如说，训练集(train-set)误差是1%，开发集(dev-set)误差是10%。

如果开发集(dev-set)来自和训练集(train-set)一样的分布，这里存在很大的方差问题，算法不能很好的从训练集(train-set)出发泛化。
但如果训练数据和开发数据来自不同的分布，就不能再放心下这个结论了。可能因为训练集(train-set)很容易识别，因为训练集(train-set)都是高分辨率图片，很清晰的图像，所以算法在开发集(dev-set)上做得不错，但开发集(dev-set)要难以识别得多。所以也许软件没有方差问题，这只不过反映了开发集(dev-set)包含更难准确分类的图片。

所以这个分析的问题在于，当看训练误差，再看开发误差，有两件事变了。首先算法只见过训练集(train-set)数据，没见过开发集(dev-set)数据。第二，开发集(dev-set)数据来自不同的分布。而且因为同时改变了两件事情，很难确认这增加的9%误差率，有多少是因为算法没看到开发集(dev-set)中的数据导致的，有多少是因为开发集(dev-set)数据就是不一样。

为了分辨清楚两个因素的影响，定义一组新的数据是有意义的，我们称之为训练-开发集（train-dev），所以这是一个新的数据子集。我们应该从训练集(train-set)的分布里挖出来，但不会用来训练网络。

![](http://www.ai-start.com/dl2017/images/6a3c48f8a71b678c2769165f38523635.png)

我们要做的是**随机打散训练集(train-set)，然后分出一部分训练集(train-set)作为训练-开发集（training-dev）**，就像开发集(dev-set)和测试集(test-set)来自同一分布，**训练集(train-set)、训练-开发集也来自同一分布**。
不同的地方是，现在只在训练集(train-set)训练神经网络，不会让神经网络在训练-开发集上跑进行后向传播。为了进行误差分析，应该做的是看看分类器在训练集(train-set)上的误差，训练-开发集上的误差，还有开发集(dev-set)上的误差。

![](http://www.ai-start.com/dl2017/images/c5d2293143857294c49859eb875272f5.png)

根据正交化思想，每次只确定一个性质：

- **数据来自同一分布，判断是否是方差问题**：比如说这个样本中，训练误差是1%，训练-开发集上的误差是9%，然后开发集(dev-set)误差是10%。然后就可以从这里得到结论，从训练数据变到训练-开发集数据时，错误率真的上升了很多。

  训练数据和训练-开发数据的差异在于，神经网络能看到第一部分数据并直接在上面做了训练，但没有在训练-开发集上直接训练，这就说明算法存在方差问题。因为训练-开发集的错误率是在和训练集(train-set)来自同一分布的数据中测得的。所以可以知道，尽管神经网络在训练集(train-set)中表现良好，但无法泛化到来自相同分布的训练-开发集里，它无法很好地泛化推广到来自同一分布，确实有方差问题。

- **方差较小时，判断是否是不同分布问题**：再来看一个不同的样本，假设训练误差为1%，训练-开发误差为1.5%，开发集(dev-set)的错误率为10%。现在方差问题就很小了，因为当训练数据转到训练-开发集数据，神经网络还没有看到的数据，错误率只上升了一点点。但当转到开发集(dev-set)时，错误率就大大上升了，所以这是数据不匹配的问题（下节课会讲到一些处理方法）。

再来看几个样本，假设训练误差是10%，训练-开发误差是11%，开发误差为12%，要记住，人类水平对贝叶斯错误率的估计大概是0%。如果得到了这种等级的表现，那就真的存在偏差问题了。存在可避免偏差问题，因为算法做的比人类水平差很多，所以这里的偏差真的很高。

最后一个例子，如果训练集(train-set)错误率是10%，训练-开发错误率是11%，开发错误率是20%，那么这其实有两个问题。第一，可避免偏差相当高，因为训练集(train-set)上都没有做得很好，而人类能做到接近0%错误率，但算法在训练集(train-set)上错误率为10%。第二，这里方差似乎很小，但数据不匹配问题很大。所以对于这个样本，有很大的偏差或者可避免偏差问题，还有数据不匹配问题。

我们判断的一般的原则，要看的关键数据是：

- 人类水平错误率
- 训练集(train-set)错误率
- 训练-开发集错误率
- 开发集错误率

根据这些错误率之间差距有多大，可以大概知道，可避免偏差、方差数据、不匹配问题各自有多大。技术上讲还可以再加入一个测试集(test-set)错误率。不应该在测试集(test-set)上开发，因为不希望对测试集(test-set)过拟合。**如果开发集(dev-set)表现和测试集(test-set)表现有很大差距，那么可能对开发集(dev-set)过拟合了，所以也许需要一个更大的开发集(dev-set)**。开发集(dev-set)和测试集(test-set)来自同一分布，所以这里存在很大差距的话。那么可能要往回退一步，然后收集更多开发集(dev-set)数据。

还有一种情况，人类的表现是4%，训练错误率是7%，训练-开发错误率是10%。算法在开发集(dev-set)上做的更好，只有6%。如果见到这种现象，说明其中训练数据其实比开发集(dev-set)和测试集(test-set)难识别得多。所以有时候如果开发测试集分布比应用实际处理的数据要容易得多，那么这些错误率可能真的会下降。

![](http://www.ai-start.com/dl2017/images/347df851fe3809b308850a9e14cfdbb0.png)

将之前举例的数字放在表格中，表格的$x$轴，表示不同的数据集。比如说，购买的数据，然后是收集的和后视镜有关的语音数据。

在另一条轴上，标记处理数据不同的方式。人类水平、神经网络训练过的数据集上达到的错误率、神经网络没有训练过的数据集上达到的错误率。

最后将数字填入单元格里（红色方框内的内容），右下角的单元格是开发集(dev-set)错误率，也可能是测试集(test-set)错误，刚刚例子中的6%。开发集(dev-set)和测试集(test-set)，实际上是两个数字，但都可以放入这个单元格里。

剩下的单元格中也可以放入数据，也是有用的。如果结果也是6%（获得这个数字的方式是让一些人自己标记他们的后视镜语音识别数据，看看人类在这个任务里能做多好，也许结果也是6%；收集一些后视镜语音识别数据，把它放在训练集(train-set)中，让神经网络去学习，然后测量那个数据子集上的错误率）如果得到这样的结果，那就是说明已经在后视镜语音数据上达到人类水平了，所以也许这个数据分布做的已经不错了。

当继续进行更多分析时，分析并不一定会给你指明一条前进道路，但有时候你可能洞察到一些特征。比如比较General speech recognition Human level 4%和rearview mirror speech data 6%，可以得知对于人类来说，后视镜的语音数据实际上比一般语音识别更难，因为人类都有6%的错误，而不是4%的错误。有时候填满整个表格，可能会洞察到更多特征。

### 6. 定位数据不匹配（Addressing data mismatch）

如果错误分析显示有数据不匹配的问题该怎么办？这个问题没有完全系统的解决方案，但我们可以看看一些可以尝试的事情。

如果发现有严重的数据不匹配问题，通常可以亲自做错误分析，尝试了解训练集(train-set)和开发测试集的具体差异。技术上，为了避免对测试集(test-set)过拟合，要做错误分析，应该人工去看开发集(dev-set)而不是测试集(test-set)。

如果认为存在数据不匹配问题，首先做错误分析，看看训练集(train-set)，或者看看开发集(dev-set)，**试图了解这两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像开发集(dev-set)的数据作训练**。

**还有一种办法是人工数据合成（artificial data synthesis）**，人工数据合成确实有效。在语音识别中，已经看到人工数据合成显著提升了已经非常好的语音识别系统的表现，所以这是可行的。但当你使用人工数据合成时，一定要谨慎，要记住你**有可能从所有可能性的空间只选了很小一部分去模拟数据**。

比如说，在安静的背景里录得10,000小时音频数据，然后只录了一小时车辆背景噪音，那么将这1小时汽车噪音回放10,000次，并叠加到在安静的背景下录得的10,000小时数据。如果这么做了，人听起来这个音频没什么问题。但是有一个风险，有可能学习算法对这1小时汽车噪音过拟合。因为这1小时的噪音，可能只模拟了全部数据空间的一小部分，可能只从汽车噪音的很小的子集来合成数据。

但是使用10,000小时永不重复的汽车噪音，而不是1小时重复学习，算法有可能取得更好的性能。人工数据合成的挑战在于，人耳是无法分辨这10,000个小时听起来和那1小时没什么区别，所以最后可能会制造出这个原始数据很少的，在一个小得多的空间子集合成的训练数据，但自己没意识到。

### 7. 迁移学习（Transfer learning）

深度学习中，最强大的理念之一就是，有的时候神经网络可以从一个任务中习得知识，并将这些知识应用到另一个独立的任务中。

![](http://www.ai-start.com/dl2017/images/b55897ab16a969f7472b07a5d1dbe869.png)

假设已经训练好一个图像识别神经网络，在$(x,y)$对上训练，其中$x$是图像，$y$是图像，是猫、狗或其他东西。如果把这个神经网络拿来，然后让它适应或者说迁移，在不同任务中学到的知识，比如阅读$X$射线扫描图。
可以做的是把神经网络最后的输出层删掉，还有最后一层的权重删掉，然后为最后一层重新赋予随机权重，然后让它在放射诊断数据上训练，只需要重新训练网络的新层。

具体来说，要实现迁移学习，要做的是，把数据集换成新的$(x,y)$对，现在这些变成放射科图像，而$y$是想要预测的诊断，最后要做的是初始化最后一层的权重，我们称之为$w^{[L]}$和$b^{[L]}$随机初始化。要用放射科数据集重新训练神经网络有几种做法。如果放射科数据集很小，可能只需要重新训练最后一层的权重，就是$w^{[L]}$和$b^{[L]}$并保持其他参数不变。如果有足够多的数据，可以重新训练神经网络中剩下的所有层。经验规则是，**如果有一个小数据集，就只训练输出层前的最后一层，或者是最后一两层；如果有很多数据，那么也许可以重新训练网络中的所有参数**。

如果重新训练神经网络中的所有参数，那么这个在初期训练阶段，称为预训练（pre-training），因为在用图像识别数据去预先初始化，或者预训练神经网络的权重。如果以后更新所有权重，然后在放射科数据上训练，有时这个过程叫微调（fine tuning）。如果在深度学习文献中看到预训练和微调，预训练和微调的权重来源于迁移学习。

从非常大的图像识别数据库中习得这些能力可能有助于学习算法在放射科诊断中做得更好，算法学到了很多结构信息，图像形状的信息，其中一些知识可能会很有用，所以学会了图像识别，它就可能学到足够多的信息，可以了解不同图像的组成部分是怎样的，这些知识可以帮助放射科诊断网络学习更快一些，或者需要更少的学习数据。

![](http://www.ai-start.com/dl2017/images/965626f5cf666ec7ed093e0f5a0d8b52.png)

迁移学习什么时候是有意义的呢？迁移学习起作用的场合是，在迁移来源问题中你有很多数据，但迁移目标问题你没有那么多数据。可以学习低层次特征，可以在神经网络的前面几层学到如何识别很多有用的特征。例如从图像识别训练中学到的很多知识可以迁移，并且真正帮你加强放射科识别任务的性能，即使放射科数据很少。

反过来的话，迁移学习可能就没有意义了。比如，放射科数据更多，只有100张猫猫狗狗或者随机物体的图片肯定不会有太大帮助，因为来自猫狗识别任务中，每一张图的价值肯定不如一张$X$射线扫描图有价值，对于建立良好的放射科诊断系统而言是这样。

所以总结一下，什么时候迁移学习是有意义的？

- 如果你想从任务$A$学习并迁移一些知识到任务$B$，那么当任务$A$和任务$B$都有同样的输入$x$时，迁移学习是有意义的。例如$A$和$B$的输入都是图像，或者两者输入都是音频。
- 当任务$A$的数据比任务$B$多得多时，迁移学习意义更大。所有这些假设的前提都是，你希望提高任务$B$的性能，因为任务$B$每个数据更有价值，对任务$B$来说通常任务$A$的**数据量必须大得多**，才有帮助。因为任务$A$里单个样本的价值没有比任务$B$单个样本价值大。然后如果你觉得任务$A$的低层次特征，可以帮助任务$B$的学习，那迁移学习更有意义一些。

最后总结一下，迁移学习最有用的场合是，如果尝试优化任务$B$的性能，通常这个任务数据相对较少，如图像识别，其中可能用1百万张图片训练过了，并从中学到很多低层次特征，所以那也许能帮助网络在任务$B$在放射科任务上做得更好，尽管任务$B$没有这么多数据。如果任务$A$实际上数据量比任务$B$要少，这种情况下增益可能不多。

### 8. 多任务学习（Multi-task learning）

在多任务学习中，是同时开始学习的，试图让单个神经网络同时做几件事情，然后希望这里每个任务都能帮到其他所有任务。

例如我们在研发无人驾驶车辆，那么无人驾驶车可能需要同时检测不同的物体，比如检测行人、车辆、停车标志，还有交通灯各种其他东西。

如果这是输入图像$x^{(i)}$，那么这里不再是一个标签 $y^{(i)}$，而是有4个标签。如果尝试检测其他物体，也许 $y^{(i)}$的维数会更高，先用4个，所以 $y^{(i)}$是个4×1向量。如果从整体来看这个训练集(train-set)标签和以前类似，我们将训练集(train-set)的标签水平堆叠起来，像这样$y^{(1)}$一直到$y^{(m)}$：
$$
Y = \begin{bmatrix}
| & | & | & \ldots & | \\
y^{(1)} & y^{(2)} & y^{(3)} & \ldots & y^{(m)} \\
| & | & | & \ldots & | \\
\end{bmatrix}
$$
现在这个矩阵$Y$变成$4×m$矩阵。而之前，当$y$是单实数时，这就是$1×m$矩阵。

![](http://www.ai-start.com/dl2017/images/91f56940e94af25b0d7a46fa8dde9075.png)

要训练这个神经网络，需要定义神经网络的损失函数，对于一个输出$\hat y$，是个4维向量，对于整个训练集(train-set)的平均损失：
$$
\frac{1}{m}\sum_{i = 1}^{m}{\sum_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})}}
$$
$\sum_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})}$这些单个预测的损失，所以这就是对四个分量的求和，logistic损失：
$$
L(\hat y_{j}^{(i)},y_{j}^{(i)}) = - y_{j}^{(i)}\log\hat y_{j}^{(i)} - (1 - y_{j}^{(i)})log(1 - \hat y_{j}^{(i)})
$$
与之前分类猫的例子主要区别在于，整个训练集(train-set)的平均损失，现在要对$j=1$到4求和，这与softmax回归不同，softmax将单个标签分配给单个样本。而这里可以有很多不同的标签，所以不是只给图片一个标签，需要遍历不同类型。如果训练了一个神经网络，试图最小化这个成本函数，做的就是多任务学习。

另外也可以训练四个不同的神经网络，但**神经网络一些早期特征，在识别不同物体时都会用到**，然后会发现，训练一个神经网络做四件事情会比训练四个完全独立的神经网络分别做四件事性能要更好，这就是多任务学习的力量。

![](http://www.ai-start.com/dl2017/images/dbca02c8a624c00bdf088c56c8122609.png)

事实证明，**多任务学习也可以处理图像只有部分物体被标记的情况**。也许有些样本都有标记，有些样本只标记了部分，部分是问号。即使是这样的数据集，也可以在上面训练算法，同时做四个任务，即使一些图像只有一小部分标签，其他是问号或者不管是什么。
训练算法的方式：即使这里有些标签是问号，或者没有标记，就是对$j$从1到4求和，就**只对带0和1标签的$j$值求和**。当有问号的时候，就在求和时忽略那个项，这样只对有标签的值求和，于是就能利用这样的数据集。

多任务学习什么时候有意义呢？当三件事为真时，它就是有意义的：

1. 第一，如果训练的一组任务，**==可以共用低层次特征==**。对于无人驾驶的例子，同时识别交通灯、汽车和行人是有道理的，这些物体有相似的特征，也许能帮你识别停车标志，因为这些都是道路上的特征。

2. 第二，这个准则没有那么绝对，所以不一定是对的。

   在迁移学习时，从$A$任务学到知识然后迁移到$B$任务，需要任务$A$的数据量远大于$B$。

   在多任务学习中，通常有更多任务而不仅仅是两个，假设有100个任务，每个任务大概有1000个样本。比如我们专注加强第100个任务的表现，我们用$A100$表示。如果试图单独去做这个最后的任务，只有1000个样本去训练这个任务，这是100项任务之一。而通过在其他99项任务的训练，这些加起来可以一共有99000个样本，这可能大幅提升算法性能，可以提供很多知识来增强这个任务的性能。不然对于任务$A100$，只有1000个样本的训练集(train-set)，效果可能会很差。

   如果有对称性，这其他99个任务，也许能提供一些数据或提供一些知识来帮到这100个任务中的每一个任务。如果想要从多任务学习得到很大性能提升，那么**==其他任务加起来必须要有比单个任务大得多的数据量==**。要满足这个条件，其中一种方法是，每个任务中的数据量很相近。关键在于，如果对于单个任务已经有1000个样本了，那么对于所有其他任务，最好也有超过1000的样本，这样其他任务的知识才能帮你改善这个任务的性能。

3. 最后，当可以**==训练一个足够大的神经网络==**，同时做好所有的工作，多任务学习更有意义。多任务学习会降低性能的唯一情况，和训练单个神经网络相比性能更低的情况就是神经网络还不够大。**如果可以训练一个足够大的神经网络，那么多任务学习肯定不会或者很少会降低性能**，我们都希望它可以提升性能，比单独训练神经网络来单独完成各个任务性能要更好。

在实践中，多任务学习的使用频率要低于迁移学习。如果训练数据很少，可以找一个数据很多的相关问题来预先学习，并将知识迁移到这个新问题上。但多任务学习比较少见，就是需要同时处理很多任务，都要做好，你可以同时训练所有这些任务，也许计算机视觉是一个例子，在物体检测中，其中一个神经网络尝试检测一大堆物体，比分别训练不同的神经网络检测物体更好。**平均来说，目前迁移学习使用频率更高，比多任务学习频率要高，但两者都可以成为你的强力工具**。

总结一下，多任务学习能训练一个神经网络来执行许多任务，这可以给你更高的性能，比单独完成各个任务更高的性能。但要注意，实际上迁移学习比多任务学习使用频率更高。因为很难找到那么多相似且数据量对等的任务可以用单一神经网络训练。再次，在计算机视觉领域，物体检测这个例子是最显著的例外情况。

多任务学习和迁移学习都是工具包中的重要工具。

### 9. 端到端的深度学习（end-to-end deep learning）

深度学习中最令人振奋的最新动态之一就是端到端深度学习的兴起，那么端到端学习到底是什么呢？简而言之，以前有一些学习系统，它们需要多个阶段的处理。端到端深度学习就是忽略所有这些不同的阶段，用单个神经网络代替它。

![](http://www.ai-start.com/dl2017/images/c31b0402d98fb34aecf167e65f83cb37.png)

看一些例子，以语音识别为例，目标是输入$x$，比如说一段音频，然后把它映射到一个输出$y$，就是这段音频的听写文本。在传统上，语音识别需要很多阶段的处理。首先需要提取一些特征，一些手工设计的音频特征，从音频中提取一组特定的人工设计的特征。在提取出一些低层次特征之后，可以应用机器学习算法在音频片段中找到音位，然后将音位串在一起构成独立的词，最后将词串起来构成音频片段的听写文本。

和这种有很多阶段的流水线相比，端到端深度学习做的是，训练一个巨大的神经网络，输入就是一段音频，输出直接是听写文本。端到端深度学习就只需要把训练集(train-set)拿过来，直接学到了$x$和$y$之间的函数映射，直接绕过了其中很多步骤。

事实证明，**端到端深度学习的挑战之一是，需要大量数据才能让系统表现良好**，比如，你只有3000小时数据去训练你的语音识别系统，那么传统的流水线效果真的很好。但当你拥有非常大的数据集时，比如10,000小时数据或者100,000小时数据，这样端到端方法突然开始很厉害了。

怎么搭建人脸识别这样的系统呢？迄今为止最好的方法似乎是一个多步方法，首先，运行一个软件来检测人脸，所以第一个检测器找的是人脸位置，并裁剪图像，使人脸居中显示，再喂到神经网络里，让网络去学习，或估计那人的身份。训练第二步的方式，训练网络的方式就是输入两张图片，然后你的网络做的就是将输入的两张图比较一下，判断是否是同一个人。

为什么两步法更好呢？实际上有两个原因。一是，解决的两个问题，每个问题实际上要简单得多。第二，两个子任务的训练数据都很多。具体来说，有很多数据可以用于人脸识别训练，对于这里的任务1来说，任务就是观察一张图，找出人脸所在的位置，把人脸图像框出来，所以有很多数据，有很多标签数据$(x,y)$，其中$x$是图片，$y$是表示人脸的位置，可以建立一个神经网络，可以很好地处理任务1。然后任务2，也有很多数据可用，今天，业界领先的公司拥有，比如说数百万张人脸照片，所以输入一张裁剪得很紧凑的照片，今天业界领先的人脸识别团队有至少数亿的图像，他们可以用来观察两张图片，并试图判断照片里人的身份，确定是否同一个人，所以任务2还有很多数据。
相比之下，如果你想一步到位，这样$(x,y)$的数据对就少得多，其中$x$是门禁系统拍摄的图像，$y$是那人的身份，因为没有足够多的数据去解决这个端到端学习问题，但却有足够多的数据来解决子问题1和子问题2。

实际上，把这个分成两个子问题，比纯粹的端到端深度学习方法，达到更好的表现。不过如果有足够多的数据来做端到端学习，也许端到端方法效果更好。但在今天的实践中，并不是最好的方法。

端到端深度学习系统是可行的，它表现可以很好，也可以简化系统架构，不需要搭建那么多手工设计的单独组件，但它也不是灵丹妙药，并不是每次都能成功。

**是否使用端到端的深度学习：**

看看端到端深度学习的一些优缺点，这样就可以根据一些准则，判断应用程序是否有希望使用端到端方法。

优点：

- **首先端到端学习是让数据说话**。所以如果有足够多的$(x,y)$数据，那么不管从$x$到$y$最适合的函数映射是什么，训练一个足够大的神经网络，使用纯机器学习方法，直接从$x$到$y$输入去训练的神经网络，可能更能够捕获数据中的任何统计信息，而不是被迫引入人类的成见。
- 所需手工设计的组件更少，所以这也许能够**简化设计工作流程**，不需要花太多时间去手工设计功能，手工设计这些中间表示方式。

缺点：

- **需要大量的数据**。要直接学到这个$x$到$y$的映射，你可能需要大量$(x,y)$数据。我们在以前的视频里看过一个例子，其中你可以收集大量子任务数据，比如人脸识别，我们可以收集很多数据用来分辨图像中的人脸，当你找到一张脸后，也可以找得到很多人脸识别数据。但是对于整个端到端任务，可能只有更少的数据可用。所以$x$这是端到端学习的输入端，$y$是输出端，所以你需要很多这样的$(x,y)$数据，在输入端和输出端都有数据，这样可以训练这些系统。这就是为什么我们称之为端到端学习，因为你直接学习出从系统的一端到系统的另一端。
- **排除了可能有用的手工设计组件**。学习算法有两个主要的知识来源，一个是数据，另一个是手工设计的任何东西，可能是组件，功能，或者其他东西。当有大量数据时，手工设计的东西就不太重要了。但是没有太多的数据时，构造一个精心设计的系统，实际上可以将人类对这个问题的很多认识直接注入到问题里，进入算法里应该挺有帮助的。

手工设计有时候是一把双刃剑，比如，强制算法以音位为单位思考，也许能让算法自己找到更好的表示方法。可能有坏处，可能有好处，但往往好处更多，手工设计的组件往往在训练集(train-set)更小的时候帮助更大。

如果在构建一个新的机器学习系统，决定是否使用端到端深度学习，关键的问题在于，是否有足够的数据能够直接学到从$x$映射到$y$足够复杂的函数。

**补充例子：**

最后吴恩达老师讲了一个更复杂的例子，之前一直在花时间帮忙主攻无人驾驶技术的公司drive.ai，怎么造出一辆自己能行驶的车呢？这里你可以做一件事，这不是端到端的深度学习方法。你可以把你车前方的雷达、激光雷达或者其他传感器的读数看成是输入图像。但是为了说明起来简单，我们就说拍一张车前方或者周围的照片，然后驾驶要安全的话，你必须能检测到附近的车，你也需要检测到行人，你需要检测其他的东西，当然，我们这里提供的是高度简化的例子。

弄清楚其他车和形如的位置之后，你就需要计划你自己的路线。所以换句话说，当你看到其他车子在哪，行人在哪里，你需要决定如何摆方向盘在接下来的几秒钟内引导车子的路径。如果你决定了要走特定的路径，也许这是道路的俯视图，这是你的车，也许你决定了要走那条路线，这是一条路线，那么你就需要摆动你的方向盘到合适的角度，还要发出合适的加速和制动指令。所以从传感器或图像输入到检测行人和车辆，深度学习可以做得很好，但一旦知道其他车辆和行人的位置或者动向，选择一条车要走的路，这通常用的不是深度学习，而是用所谓的运动规划软件完成的。如果你学过机器人课程，你一定知道运动规划，然后决定了你的车子要走的路径之后。还会有一些其他算法，我们说这是一个控制算法，可以产生精确的决策确定方向盘应该精确地转多少度，油门或刹车上应该用多少力。

所以这个例子就表明了，如果你想使用机器学习或者深度学习来学习某些单独的组件，那么当你应用监督学习时，你应该仔细选择要学习的$x$到$y$映射类型，这取决于那些任务你可以收集数据。相比之下，谈论纯端到端深度学习方法是很激动人心的，你输入图像，直接得出方向盘转角，但是就目前能收集到的数据而言，还有我们今天能够用神经网络学习的数据类型而言，这实际上不是最有希望的方法，或者说这个方法并不是团队想出的最好用的方法。而我认为这种纯粹的端到端深度学习方法，其实前景不如这样更复杂的多步方法。因为目前能收集到的数据，还有我们现在训练神经网络的能力是有局限的。

这就是端到端的深度学习，有时候效果显著，但也要注意应该在什么时候使用端到端深度学习。