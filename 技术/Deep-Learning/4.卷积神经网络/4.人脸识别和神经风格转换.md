[TOC]

## 特殊应用：人脸识别和神经风格转换

### 1. 什么是人脸识别？（What is face recognition?）

首先，了解一下人脸识别的一些术语。在人脸识别的相关文献中，人们经常提到人脸验证（face verification）和人脸识别（face recognition）。

- 人脸验证（face verification）:输入一张图片，以及某人的ID或者是名字，这个系统要做的是，验证输入图片是否是这个人。有时候也被称作1对1问题（1：1），只需要弄明白这个人是否和他声称的身份相符。
- 人脸识别（face recognition）:有一个$K$人的数据库，输入一张图片，需要输出该照片对应的ID，或未识别。人脸识别是一个1对多问题（$1:K$）。

人脸识别问题比人脸验证问题难很多。假设有一个验证系统，准确率是99%，还可以。但是，假设在识别系统中，$K=100$，如果把这个人脸验证系统应用在100个人身上，如果每个人犯错的概率是1%，犯错的机会就是100倍了。如果有一个上百人的数据库，想得到一个可接受的识别误差，要构造一个验证系统，其准确率为99.9%或者更高，然后才可以在100人的数据库上运行，而且要保证有很大几率不出错。

### 2. One-Shot学习（One-shot learning）

人脸识别所面临的一个挑战就是需要解决一次学习问题，这意味着在大多数人脸识别应用中，需要通过单单一张图片或者单单一个人脸样例就能去识别这个人。而历史上，当深度学习只有一个训练样例时，它的表现并不好。

![](http://www.ai-start.com/dl2017/images/a44671322cb67db58ce08068353708db.png)

假设数据库里有4张公司的员工照片，仅仅通过一张已有的照片，来识别前面这个人确实是她。所以在一次学习问题中，只能通过一个样本进行学习，以能够认出同一个人。大多数人脸识别系统都需要解决这个问题，因为在数据库中每个雇员或者组员可能都只有一张照片。

所以要让人脸识别能够做到一次学习，为了能有更好的效果，要做的是学习Similarity函数：$d(img1,img2) = degree\ of\ difference\ between\ images$。它以两张图片作为输入，然后输出这两张图片的差异值。

如果放进同一个人的两张照片，它能输出一个很小的值，如果放进两个长相差别很大的人的照片，它就输出一个很大的值。所以在识别过程中，如果这两张图片的差异值小于某个阈值$\tau$（它是一个超参数），那么这时就能预测这两张图片是同一个人，如果差异值大于τ，预测这是不同的两个人，这就是解决人脸验证问题的一个可行办法。

要将它应用于识别任务，要做的是拿输入照片，然后用$d$函数去和数据库中的照片做对比，通过Similarity计算，最终能够知道输入照片是否有效。

### 3. Siamese 网络（Siamese network）

上一节讲的函数d的作用就是输入两张人脸，然后告诉我们它们的相似度。实现这个功能的一个方式就是用Siamese网络。

之前卷积网络，输入图片$x^{(1)}$，然后通过一些列卷积，池化和全连接层，最终得到特征向量，会被送进softmax单元来做分类，但在这里不会这么做。我们关注的重点是全连接层最后的向量，假如它有128个数，把它叫做$f(x^{(1)})$。可以把$f(x^{(1)})$看作是输入图像$x^{(1)}$的编码。

![](http://www.ai-start.com/dl2017/images/ecd4f7ca6487b4ccb19c1f5039e9d876.png)

建立一个人脸识别系统的方法就是，把第二张图片喂给**有同样参数的同样的神经网络**，然后得到一个不同的128维的向量，这个向量代表第二个图片，把第二张图片的编码叫做$f(x^{(2)})$。

$x^{(1)}$和$x^{(2)}$代表两个输入图片，要做的就是定义$d$，将$x^{(1)}$和$x^{(2)}$的距离定义为这两幅图片的编码之差的范数：
$$
d( x^{( 1)},x^{( 2)}) =|| f( x^{( 1)}) - f( x^{( 2)})||_{2}^{2}
$$
对于两个不同的输入，运行相同的卷积神经网络，然后比较它们，这一般叫做Siamese网络架构。

**训练Siamese网络：**

这两个网络有相同的参数，所以实际要做的就是训练一个网络，它计算得到的编码可以用于函数$d$，它可以告诉你两张图片是否是同一个人。

更准确地说，神经网络的参数定义了一个编码函数$f(x^{(i)})$，如果给定输入图像$x^{(i)}$，这个网络会输出$x^{(i)}$的128维的编码。**要做的就是学习参数，使得如果两个图片$x^{( i)}$和$x^{( j)}$是同一个人，那么得到的两个编码的距离够小。相反，如果$x^{(i)}$和$x^{(j)}$是不同的人，那么让它们之间的编码距离大一点**。

如果改变网络所有层的参数，就会得到不同的编码结果，要做的就是用反向传播来改变这些所有的参数，以确保满足这些条件。

### 4. Triplet 损失（Triplet 损失）

要想通过学习神经网络的参数来得到优质的人脸图片编码，方法之一就是定义三元组损失函数然后应用梯度下降。

![](http://www.ai-start.com/dl2017/images/d56e1c92b45d8b9e76c1592fdbf0fc7f.png)

用三元组损失的术语来说，要做的通常是看一个 Anchor 图片，想让Anchor图片和Positive图片的距离很接近。当Anchor图片与Negative图片对比时，想让它们的距离离得更远一点。

这就是为什么叫做三元组损失，它代表通常会同时看三张图片，Anchor图片、Postive图片，还有Negative图片，简写成$A$、$P$、$N$。想要$|| f(A) - f(P) ||^{2}$的数值很小，准确地说，想让它小于等$f(A)$和$f(N)$之间的距离，把这些写成公式:
$$
\begin{split}
&\underbrace{|| f(A) - f(P)||^{2}}_{d(A,P)} \leq \underbrace{|| f(A) - f(N)||^{2}}_{d(A,N)}\\
&\underbrace{|| f(A) - f(P)||^{2}}_{d(A,P)} - \underbrace{|| f(A) - f(N)||^{2}}_{d(A,N)} \leq 0
\end{split}
$$
如果所有图像的$f$都是一个零向量，那么总能满足这个方程，即0-0≤0，这就是0减去0还等于0，这种情况是没有用的。为了阻止网络出现这种情况，需要修改这个目标，加入$\alpha$间隔(margin)：
$$
\begin{split}
&\underbrace{|| f(A) - f(P)||^{2}}_{d(A,P)} + \alpha \leq \underbrace{|| f(A) - f(N)||^{2}}_{d(A,N)}\\
&\underbrace{|| f(A) - f(P)||^{2}}_{d(A,P)} - \underbrace{|| f(A) - f(N)||^{2}}_{d(A,N)} + \alpha \leq 0
\end{split}
$$
举个例子，假如间隔$\alpha$设置成0.2，$d(A,P) =0.5$，$d(A,N)$只大一点，比如说0.51，条件就不能满足。虽然0.51也是大于0.5的，但还是不够好。我们想要$d(A,N)$比$d(A,P)$大很多，会想让$d(A,N)$至少是0.7或者更高。

可以把$\alpha$这项调大或者这个调小，在$d(A,P)$和$d(A,N)$之间至少相差0.2，这就是间隔参数$a$的作用。它拉大了Anchor和Positive 图片与Anchor和Negative 图片对之间的差距。

**三元组损失函数：**

三元组损失函数的定义基于三张图片，假如三张图片$A$、$P$、$N$，即Anchor样本、Positive样本和Negative样本，其中Positive图片和Anchor图片是同一个人，但是Negative图片和Anchor不是同一个人。

接下来定义损失函数：
$$
L( A,P,N) = max(|| f( A) - f( P)||^{2} -|| f( A) - f( N)||^{2} + \alpha,0)
$$
这个$max$函数的作用就是，只要$|| f( A) - f( P)||^{2} -|| f( A) - f( N)||^{2} + \alpha \leq0$，那么损失函数就是0。通过最小化这个损失函数达到的效果就是使$|| f( A) - f( P)||^{2} -||f( A) - f( N)||^{2} +\alpha$成为0，或者小于等于0。只要这个损失函数小于等于0，网络不会关心它负值有多大。

整个网络的代价函数应该是训练集中这些单个三元组损失的总和:
$$
J = \sum_{i=1}^mL(A^{(i)},P^{(i)},N^{(i)})
$$
**为了定义三元组的数据集需要成对的$A$，$P$和$A$，$N$，为了训练系统，数据集里面需要有同一个人的多个照片**。如果只有每个人一张照片，那么根本没法训练这个系统。训练完这个系统之后，对于人脸识别系统，可能只想要识别的某个人的一张照片。但对于训练集，需要确保有同一个人的多个图片。

**训练集选择：**

如果从训练集中，随机地选择$A$、$P$和$N$，遵守$A$和$P$是同一个人，而$A$和$N$是不同的人这一原则。有个问题就是，如果随机的选择它们，那么这个约束条件（$d(A,P) + a \leq d(A,N)$）很容易达到，因为随机选择的图片，$A$和$N$比$A$和$P$差别很大的概率很大。如果$A$和$N$是随机选择的不同的人，有很大的可能性$||f(A) - f(N)||^{2}$会比左边这项$||f( A) - f(P)||^{2}$大，而且差距远大于$\alpha$，这样网络并不能从中学到什么。

所以为了构建一个数据集，要做的就是尽可能选择难训练的三元组$A$、$P$和$N$。具体而言，$A$、$P$和$N$的选择使得$d(A,P)$很接近$d(A,N)$，即$d(A,P) \approx d(A,N)$，这样学习算法会竭尽全力使右边$d(A,N)$这式子变大，或者使左边$d(A,P)$这个式子变小，这样左右两边至少有一个$\alpha$的间隔。并且选择这样的三元组还可以增加学习算法的计算效率，如果随机的选择这些三元组，其中有太多会很简单，梯度算法不会有什么效果。因为网络总是很轻松就能得到正确的结果，只有选择难的三元组梯度下降法才能发挥作用，使得这两边离得尽可能远。

如果对此感兴趣的话，可以参考 [FaceNet: A Unified Embedding forFace Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)。如果想要了解更多的关于通过选择最有用的三元组训练来加速算法的细节，可以看一下这篇论文，这是一个很棒的论文。

**算法命名：**

顺便说一下关于深度学习领域如何命名的，通常会将系统命名为“\_\_Net”或者“Deep\_\_”，比如FaceNet，DeepFace。这些是深度学习领域流行的命名算法的方式。

现在的人脸识别系统，尤其是大规模的商业人脸识别系统都是在很大的数据集上训练，超过百万图片的数据集并不罕见，一些公司用千万级的图片，还有一些用上亿的图片来训练这些系统。这些是很大的数据集，即使按照现在的标准，这些数据集并不容易获得。幸运的是，一些公司已经训练了这些大型的网络并且上传了模型参数。

所以相比于从头训练这些网络，在这一领域，由于这些数据集太大，**这一领域的一个实用操作就是下载别人的预训练模型，而不是一切都要从头开始**。但是即使下载了别人的预训练模型，了解怎么训练这些算法也是有用的，以防针对一些应用需要从头实现这些想法。

### 5. 面部验证与二分类（Face verification and binary classification）

Triplet loss是一个学习人脸识别卷积网络的好方法，另一个方法是选取一对神经网络，Siamese网络。

![](http://www.ai-start.com/dl2017/images/c3bf61934da2f20a7d15e183c1d1d2ab.png)

选取一对神经网络，使其同时计算这些嵌入，比如说128维的嵌入，或者更高维，然后将其输入到逻辑回归单元，然后进行预测，如果是相同的人，那么输出是1，若是不同的人，输出是0。这就把人脸识别问题转换为一个二分类问题，训练这种系统可以替换Triplet loss的方法。

最后的逻辑回归单元输出$\hat y$处理：
$$
\hat y = \sigma(\sum_{k = 1}^{128}{w_{i}| f( x^{( i)})_{k} - f( x^{( j)})_{k}| + b})
$$
符号$f( x^{( i)})_{k}$代表图片$x^{(i)}$的编码，下标$k$代表选择这个向量中的第$k$个元素，$| f(x^{( i)})_{k} - f( x^{( j)})_{k}|$是对这两个编码取元素差的绝对值。你可能想，把这128个元素当作特征，然后把他们放入逻辑回归中，最后的逻辑回归可以增加参数$w_{i}$和$b$，就像普通的逻辑回归一样。

还有其他不同的形式来计算$| f( x^{( i)})_{k} - f( x^{( j)})_{k}|$，比如说，公式可以是$\frac{(f( x^{( i)})_{k} - f(x^{( j)})_{k})^{2}}{f(x^{( i)})_{k} + f( x^{( j)})_{k}}$，这个公式也被叫做$\chi^{2}$公式，$\chi$也被称为平方相似度。

在这个学习公式中，输入是一对图片$(x^{(i)},x^{(j)})$，作为训练输入$x$，输出$y$是0或者1，取决于输入是相似图片还是非相似图片。与之前Triplet类似，**Siamese网络输入的两组图片的参数是相同的**。

**使用技巧：**

不需要每次都计算已有图片的这些特征，可以提前计算好，那么当一个新员工走近时，可以使用卷积网络来计算新输入的编码，然后和预先计算好的编码进行比较，最后输出预测值$\hat y$。

因为不需要存储原始图像，如果有一个很大的员工数据库，不需要为每个员工每次都计算这些编码。这个预先计算的思想，可以节省大量的计算，这个预训练的工作可以用在Siamese网路结构中，将人脸识别当作一个二分类问题，也可以用在学习和使用Triplet loss函数上。

Siamese网路把人脸验证当作一个监督学习，创建一个只有成对图片的训练集，不是三个一组，目标标签是1表示一对图片是一个人，目标标签是0表示图片中是不同的人。利用不同的成对图片，使用反向传播算法去训练神经网络，训练Siamese神经网络。

### 6. 什么是神经风格转换？（What is neural style transfer?）

最近，卷积神经网络最有趣的应用是神经风格迁移。

![](http://www.ai-start.com/dl2017/images/7b75c69ef064be274c82127a970461cf.png)

为了描述如何实现神经网络迁移，使用$C$来表示内容图像，$S$表示风格图像，$G$表示生成的图像。将$C$的内容生成跟$S$一样的风格内容$G$。

为了实现神经风格迁移，需要知道卷积网络在不同的神经网络，深层的、浅层的提取的特征。

### 7. 深度卷积网络在学什么？（What are deep ConvNets learning?）

深度卷积网络到底在学什么？展示一些可视化的例子，可以帮助理解卷积网络中深度较大的层真正在做什么，这样有助于理解如何实现神经风格迁移。

假如训练了一个卷积神经网络，希望看到不同层之间隐藏单元的计算结果。可以这样做，从第一层的隐藏单元开始，遍历整个训练集，然后找到那些使得单元激活最大化的一些图片或者是图片块。换句话说，训练集经过神经网络，然后弄明白哪一张图片最大限度地激活特定的单元。

注意在第一层的隐藏单元，只能看到小部分卷积神经，如果画出来哪些激活了激活单元，只有一小块图片块是有意义的，因为这就是特定单元所能看到的全部。

![](http://www.ai-start.com/dl2017/images/1472cbf93948173ac314ceb4eb5e4c97.png)

选择一个隐藏单元，发现有9个图片最大化了单元激活，可能找到这样的9个图片块（编号1），似乎是图片浅层区域隐藏单元所看到的，找到了像这样的边缘或者线（编号2），这就是那9个最大化地激活了的隐藏单元激活项的图片块。

![](http://www.ai-start.com/dl2017/images/4000d4a71a5820691197d506654216bd.png)

对其他隐藏单元也进行处理，会发现其他隐藏单元趋向于激活类似于上图的图片。有的似乎对垂直明亮边缘左边有绿色的图片块感兴趣，有的隐藏单元倾向于橘色。

以此类推，每一个不同的图片块都最大化地激活了。可以这样理解，第一层的隐藏单元通常会找一些简单的特征，比如说边缘或者颜色阴影。

在深层部分，一个隐藏单元会看到一张图片更大的部分，在极端的情况下，可以假设每一个像素都会影响到神经网络更深层的输出，靠后的隐藏单元可以看到更大的图片块。

![](http://www.ai-start.com/dl2017/images/83f73c165fe6ec9c98ab2993d3efaf7f.png)

第二层似乎检测到更复杂的形状和模式，比如说编号1这个隐藏单元，它会找到有很多垂线的垂直图案，编号2这个隐藏单元似乎在左侧有圆形图案时会被高度激活，编号3这个的特征是很细的垂线，以此类推，第二层检测的特征变得更加复杂。

![](http://www.ai-start.com/dl2017/images/ac77f5f5dd63264cf8af597c3aa20d59.png)

越往后，第五层检测到更加复杂的事物，编号1也有一个神经元，似乎是一个狗检测器，但是可以检测到的狗似乎更加多样性。编号2可以检测到键盘质地的物体。编号3可能检测到文本，这个编号4检测到花。

我们已经有了一些进展，从检测简单的事物，从第一层的边缘，第二层的质地，到深层的复杂物体。

希望这让你可以更直观地了解卷积神经网络的浅层和深层是如何计算的。

### 8. 代价函数（Cost function）

要构建一个神经风格迁移系统，为生成的图像定义一个代价函数，通过最小化代价函数，可以生成想要的任何图像。

为了实现神经风格迁移，要做的是定义一个关于$G$的代价函数$J$用来评判某个生成图像的好坏，然后使用梯度下降法去最小化$J(G)$，以便于生成这个图像。这个代价函数定义为两个部分，第一部分被称作内容代价，它是用来度量生成图片$G$的内容与内容图片$C$的内容有多相似$J_{\text{content}}(C,G)$；第二部分是风格代价函数$J_{\text{style}}(S,G)$，也就是关于$S$和$G$的函数，用来度量图片$G$的风格和图片$S$的风格的相似度。
$$
J( G) = \alpha J_{\text{content}}( C,G) + \beta J_{\text{style}}(S,G)
$$
最后用两个超参数$\alpha$和$\beta$来确定内容代价和风格代价，两者之间的权重用两个超参数来确定。

为了生成一个新图像，接下来要做的是随机初始化生成图像$G$，它可能是100×100×3，或者是任何想要的尺寸。然后对于代价函数$J(G)$，使用梯度下降的方法将其最小化，更新$G:= G - \frac{\partial}{\partial G}J(G)$。在这个步骤中，实际上更新的是图像$G$的像素值。

![](http://www.ai-start.com/dl2017/images/dd376e74155008845e96d662cc45493a.png)

假设从编号1的内容图片和编号2的风格图片开始，随机初始化$G$，随机初始化的生成图像就是编号3这张随机选取像素的白噪声图。接下来运行梯度下降算法，最小化代价函数$J(G)$，逐步处理像素，这样慢慢得到一个生成编号4、5、6图片，越来越像用风格图片的风格画出来的内容图片。

### 9. 内容代价函数（Content cost function）

先定义内容代价部分：

- 用隐含层$l$来计算内容代价。

  如果$l$是个很小的数，比如用隐含层1，这个代价函数就会使生成图片$G$像素上非常接近内容图片$C$。然而如果用很深的层，那么那就会问，内容图片里是否有狗，然后它就会确保生成图片里有一个狗。

  所以在实际中，通常$l$会选择在网络的中间层，既不太浅也不很深。

- 然后用一个预训练的卷积模型，可以是VGG网络或者其他的网络也可以。

- 衡量两个图片$C$和$G$在$l$层的激活函数值，一个内容图片$a^{[l][C]}$和一个生成图片$a^{[l][G]}$，它们在内容上的相似度。如果这两个激活值相似，那么就意味着两个图片的内容相似。

最后定义：
$$
J_{\text{content}}( C,G) = \frac{1}{2}|| a^{[l][C]} - a^{[l][G]}||^{2}
$$
为定义两个激活值不同或者相似的程度，取$l$层的隐含单元的激活值，按元素相减，然后取平方，也可以在前面加上归一化或者不加，比如$\frac{1}{2}$或者其他的，都影响不大。因为这都可以由$J(G)$中的超参数$\alpha$来调整。要清楚**这里用的符号都是展成向量形式的**。

### 10. 风格代价函数（Style cost function）

这节了解风格代价函数，那么图片的风格到底是什么意思？

![](http://www.ai-start.com/dl2017/images/efa0f6e81320966647658cba96ff28ee.png)

如上图这里是否含有不同隐藏层，现在选择了某一层$l$，去为图片的风格定义一个深度测量。现在要做的就是将==图片的风格定义为$l$层中各个通道之间**激活项的相关性系数**==。

![](http://www.ai-start.com/dl2017/images/e2bc16e5d114bac50383a1998220c4f5.png)

现在将$l$层的激活项取出，这是个$ n_{H} \times n_{W} \times n_{C}$的激活项，它是一个三维的数据块。如何知道这些不同通道之间激活项的相关系数呢？

![](http://www.ai-start.com/dl2017/images/e3d74c1ce2393ae4e706a1cc4024f311.png)

为了解释将这个激活块的不同通道，渲染成不同的颜色。假如有5个通道，为了能捕捉图片的风格，首先，先看前两个通道，前两个通道分别是图中的红色和黄色部分，该如何计算这两个通道间激活项的相关性系数？

在第一个通道中含有某个激活项，第二个通道也含有某个激活项，于是它们组成了一对数字。然后这个激活项块中其他位置的激活项，它们也分别组成了很多对数字。现在得到了很多个数字对，取得这两个$n_{H}\times n_{W}$的通道中所有的数字对后，然后去算它们的相关性系数。

**相关性系数：**

![](http://www.ai-start.com/dl2017/images/fd244a4fe8bb2d27956dd9bc7d8bcf52.png)

先来看一个之前讲的一个可视化例子。这个红色编号1的通道，它能找出图片中的特定位置是否含有编号3的这些垂直纹理，而编号2黄色的通道，对应编号4这个神经元，它可以粗略地找出橙色的区域。

如果这两个通道有高度相关性，那么这幅图片中出现垂直纹理的地方，这块地方很大概率是橙色的。如果说它们是不相关的，意味着图片中有垂直纹理的地方很大概率不是橙色的。而**相关性系数描述的就是当图片某处出现这种垂直纹理时，该处又同时是橙色的可能性**。

**==相关性系数这个概念提供了一种去测量这些不同的特征（垂直纹理，这些橙色或是其他的特征）的方法，去测量它们在图片中的各个位置同时出现或不同时出现的频率==**。

如果在通道之间使用相关系数来描述通道的风格，能做的就是测量生成图像中第一个通道是否与第二个通道相关。**通过测量，能得知在生成的图像中垂直纹理和橙色同时出现或者不同时出现的频率，这样就能够测量生成的图像的风格与输入的风格图像的相似程度**。

**风格矩阵：**

为了能够测量出刚才所说的相关性系数，需要计算出这张图像的风格矩阵。用$a_{i,j,k}^{[l]}$来记录相应位置的激活项，也就是$l$层中的$i,j,k$位置，所以$i$代表高度，$j$代表宽度，$k$代表着$l$层中的不同通道。

风格矩阵$G^{[l]}$，是个$n_{c} \times n_{c}$的矩阵，也就是一个方阵。用$G_{\text{kk}^{'}}^{[l]}$表示$k$通道与$k'$通道中的激活项之间的相关系数，$k$和$k'$会在1到$n_{c}$之间取值，$n_{c}$就是$l$层中通道的总数量，所以是一个$n_{c} \times n_{c}$的矩阵。

在这个矩阵中$k$和$k'$元素被用来描述$k$通道和$k'$通道之间的相关系数，只代表一种元素，具体地：
$$
G_{kk^{'}}^{[l]( S)} = \sum_{i = 1}^{n_{H}^{[l]}}{\sum_{j = 1}^{n_{W}^{[l]}}{a_{i,\ j,\ k}^{[l](S)}a_{i,\ j,\ k^{'}}^{[l](S)}}}
$$
这个$i$和$j$是激活块中对应位置的坐标，也就是该激活项所在的高和宽，所以$i$会从1加到$n_{H}^{[l]}$，$j$会从1加到$n_{W}^{[l]}$。$k$和$k'$则表示对应的通道，所以$k$和$k'$值的范围是从1开始到这个神经网络中该层的通道数量$n_{C}^{[l]}$。

这个式子就是把图中各个高度和宽度的激活项都遍历一遍，并将$k$和$k'$通道中对应位置的激活项都进行相乘，这就是$G_{{kk}^{'}}^{[l]}$的定义。它其实是一种非标准的互协方差，因为我们并没有减去均值而只是把这些元素直接相乘。

通过对$k$和$k'$通道中所有的数值进行计算就得到了$G$矩阵，也就是风格矩阵。

再对生成图像做同样的操作：
$$
G_{kk^{'}}^{[l]( G)} = \sum_{i = 1}^{n_{H}^{[l]}}{\sum_{j = 1}^{n_{W}^{[l]}}{a_{i,\ j,\ k}^{[l](G)}a_{i,\ j,\ k^{'}}^{[l](G)}}}
$$
上标$(S)$和$(G)$分别表示在风格图像$S$中的激活项和在生成图像$G$的激活项。

要注意，如果两个通道中的激活项数值都很大，那么$G_{{kk}^{'}}^{[l]}$也会变得很大。对应地，如果他们不相关那么$G_{{kk}^{'}}^{[l]}$就会很小。

**代价函数：**

将$S$和$G$代入到风格代价函数中去计算，得到这两个矩阵之间的误差：
$$
\begin{split}
J_{\text{style}}^{[l]}( S,G) &= || G^{[l][S]} - G^{[l][G]}||^{2}_F\\
&=\frac{1}{(2n_{H}^{[l]}n_{W}^{[l]}n_{C}^{[l]})^2}\sum_k\sum_{k'}(G_{kk'}^{[l][S]} - G_{kk'}^{[l][G]})^2
\end{split}
$$
因为它们是矩阵，所以在这里加一个$F$（Frobenius范数），这实际上是计算两个矩阵对应元素相减的平方的和，作者在这里使用了一个归一化常数，也就是$\frac{1}{2n_{H}^{[l]l}n_{W}^{[l]}n_{C}^{[l]}}$，再在外面加一个平方，但是一般情况下不用写这么多只要将它乘以一个超参数$\beta$就行。

这是对$l$层定义的风格代价函数，实际上，如果对各层都使用风格代价函数，会让结果变得更好。如果要对各层都使用风格代价函数，把各个层的风格代价函数都加起来，就能定义它们全体：
$$
J_{\text{style}}( S,G) =\sum_l \lambda^{[l]}J_{\text{style}}^{[l]}( S,G) 
$$
还需要对每个层定义权重，也就是一些额外的超参数，用$\lambda^{[l]}$来表示，这样就能够在神经网络中使用不同的层，包括之前的一些可以测量类似边缘这样的低级特征的层，以及之后的一些能测量高级特征的层，使得我们的神经网络在计算风格时能够同时考虑到这些低级和高级特征的相关系数。这样，在基础的训练中在定义超参数时，可以尽可能的得到更合理的选择。

最后把所有东西封装起来，可以定义一个全体代价函数：
$$
J(G) = \alpha J_{\text{content}( C,G)} + \beta J_{{style}}(S,G)
$$
之后用梯度下降法，或者更复杂的优化算法来找到一个合适的图像$G$，并计算$J(G)$的最小值。这样的话，将能够得到非常好看的结果。

### 11. 一维到三维推广（1D and 3D generalizations of models）

我们大部分讨论的图像数据，某种意义上而言都是2D数据，考虑到图像如此普遍，许多你所掌握的思想不仅局限于2D图像，甚至可以延伸至1D，乃至3D数据。

![](http://www.ai-start.com/dl2017/images/fbd6d69ed332d3e4e044b7f1686f2fd7.png)

关于2D卷积，输入一个14×14的图像，并使用一个5×5的过滤器进行卷积，通过这个操作你会得到10×10的输出。如果使用了多通道，比如14×14×3，那么相匹配的过滤器是5×5×3，如果使用了多重过滤，比如16，最终得到的是10×10×16。

**一维扩展：**

事实证明同样可以用于1维数据，比如一个心电图EKG信号，进行医学诊断。

![](http://www.ai-start.com/dl2017/images/8b2d8ac94e71fb591c44c29ded5d6b7e.png)

只有一个14尺寸输入，在这种情况下，需要使用一个1维过滤进行卷积，只需要一个1×5的过滤器，而不是一个5×5的。可在不同的位置中应用类似的方法，将发现一个14x1维的数据与5x1维数据进行卷积，并产生一个10x1维输出。如果使用多通道，有16个过滤器，最后会获得一个10×16的数据，这可能是卷积网络中的某一层。

对于卷积网络的下一层，如果输入一个10×16数据，也可以使用一个5x1维过滤器进行卷积，这需要16个通道进行匹配，如果有32个过滤器，另一层的输出结果就是6×32。

所以卷积网络同样可以被用于1D数据，对于许多1维数据应用，实际上会使用递归神经网络进行处理，这个网络会在下一个课程中学到，但是有些人依旧愿意尝试使用卷积网络解决这些问题。

下一门课将讨论序列模型，包括递归神经网络、LCM与其他类似模型，我们将探讨使用1D卷积网络的优缺点。

**三维扩展：**

假设有了一个3D输入数据，以CT扫描为例。

![](http://www.ai-start.com/dl2017/images/38e111b08f94c905ff97f627a4b986ff.png)

对这份数据的理解方式是，假设数据现在具备一定长度、宽度与高度，其中每一个切片都与躯干的切片对应。

![](http://www.ai-start.com/dl2017/images/cbdb2ba568ef4906d8904b952667de67.png)

进行CT扫描时，可以看到人体躯干的不同切片，本质上这个数据是3维的。

![](http://www.ai-start.com/dl2017/images/49076b88b9ecbd1597f6ae37e8d87dc3.png)



如果有一个3D对象，比如说是14×14×14，如果有一个1的通道，技术上来说也可以再×1。如果使用16过滤器5×5×5×1，接下来的输出将是10×10×10×16，这将成为3D数据卷积网络上的一层。

如果下一层卷积使用5×5×5×16维度的过滤器再次卷积，如果有32个过滤器，操作也与之前相同，最终得到一个6×6×6×32的输出。

CT医疗扫描是3D数据的一个实例，另一个数据处理的例子是可以将电影中随时间变化的不同视频切片看作是3D数据，可以将这个技术用于检测动作及人物行为。

总而言之这就是1D、2D及3D数据处理，图像数据无处不在，以至于大多数卷积网络都是基于图像上的2D数据，希望其他模型同样会对我们有帮助。