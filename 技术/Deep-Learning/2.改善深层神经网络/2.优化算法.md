[TOC]

## 优化算法

### 1. Mini-batch 梯度下降（Mini-batch gradient descent）

机器学习的应用是一个高度依赖经验的过程，伴随着大量迭代的过程，你需要训练诸多模型，才能找到合适的那一个，所以，优化算法能够帮助你快速训练模型。

其中一个难点在于，深度学习没有在大数据领域发挥最大的效果，我们可以利用一个巨大的数据集来训练神经网络，而在巨大的数据集基础上进行训练速度很慢。因此，使用快速的优化算法，使用好用的优化算法能够大大提高团队的效率，那么首先来谈谈**mini-batch**梯度下降法。

![mini-batch](http://www.ai-start.com/dl2017/images/ef8c62ba3c82cb37e6ed4783e7717a8d.png)

向量化能够相对较快地处理所有$m$个样本。如果$m$很大的话，处理速度仍然缓慢。比如说，如果$m$是500万或5000万或者更大的一个数，在对整个训练集执行梯度下降法时，必须处理整个训练集，然后才能进行一步梯度下降法，然后需要再重新处理500万个训练样本，才能进行下一步梯度下降法。所以如果在处理完整个500万个样本的训练集之前，先让梯度下降法处理一部分，算法速度会更快。

**算法讲解：**

可以把训练集分割为小一点的子集训练，这些子集被取名为**mini-batch**，假设每一个子集中只有1000个样本，那么把其中的$x^{(1)}$到$x^{(1000)}$取出来，将其称为第一个子训练集，然后再取出接下来的1000个样本，从$x^{(1001)}$到$x^{(2000)}$，以此类推。

接下来定义一个新的符号，把$x^{(1)}$到$x^{(1000)}$称为$X^{\{1\}}$，$x^{(1001)}$到$x^{(2000)}$称为$X^{\{2\}}$，如果训练样本一共有500万个，每个**mini-batch**都有1000个样本，也就是说，总共有5000个**mini-batch** ，所以最后得到是$X^{\left\{ 5000 \right\}}$ 。对$Y$也要进行相同处理，从$Y^{\{1\}}$，一直到$Y^{\{ 5000\}}$ 。

$X^{\{ t\}}$和$Y^{\{ t\}}$的维数：如果$X^{\{1\}}$是一个有1000个样本的训练集，或者说是1000个样本的$x$值，所以维数应该是$(n_{x},1000)$，$X^{\{2\}}$的维数应该是$(n_{x},1000)$，以此类推。因此所有的子集维数都是$(n_{x},1000)$，而$Y^{\{ t\}}$的维数都是$(1,1000)$。

**batch**梯度下降法指的是我们之前讲过的梯度下降法算法，就是同时处理整个训练集。相比之下，**mini-batch**梯度下降法，每次同时处理的单个的**mini-batch** $X^{\{t\}}$和$Y^{\{ t\}}$，而不是同时处理全部的$X$和$Y$训练集。那么究竟**mini-batch**梯度下降法的原理是什么？

![mini-batch梯度下降](http://www.ai-start.com/dl2017/images/0818dc0f8b7b8c1703d0c596f6027728.png)

在训练集上运行**mini-batch**梯度下降法，运行`for t=1……5000`，因为我们有5000个各有1000个样本的组，在**for**循环里就是对$X^{\{t\}}$和$Y^{\{t\}}$执行一步梯度下降法。接下来要计算损失成本函数$J$，因为子集规模是1000，$J= \frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})}$，$L(\hat y^{(i)},y^{(i)})$指的是来自于**mini-batch**$X^{\{ t\}}$和$Y^{\{t\}}$中的样本。

如果用到了正则化，也可以使用正则化的术语，$J^{\{t\}} = \frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})} +\frac{\lambda}{2000}\sum_{l}^{}{||w^{[l]}||}_{F}^{2}$。

其实跟之前我们执行梯度下降法如出一辙，除了现在的对象不是$X$，$Y$，而是$X^{\{t\}}$和$Y^{\{ t\}}$。接下来，执行反向传播来计算$J^{\{t\}}$的梯度，只使用$X^{\{ t\}}$和$Y^{\{t\}}$，然后更新加权值，$W$实际上是$W^{\lbrack l\rbrack}$，更新为$W^{[l]}:= W^{[l]} - \alpha dW^{[l]}$，对$b$做相同处理，$b^{[l]}:= b^{[l]} - \alpha db^{[l]}$。这是使用**mini-batch**梯度下降法训练样本的一步。

**总结：**

使用**batch**梯度下降法，一次遍历训练集只能做一个梯度下降，使用**mini-batch**梯度下降法，一次遍历训练集，能做5000个梯度下降。当然正常来说还需要多次遍历训练集，还需要为另一个循环设置另一个**for**循环。这样可以一直处理遍历训练集，直到最后收敛到一个合适的精度。

### 2. 理解mini-batch梯度下降法（Understanding mini-batch gradient descent）

![mini-batch cost函数](http://www.ai-start.com/dl2017/images/b5c07d7dec7e54bed73cdcd43e79452d.png)

使用**batch**梯度下降法时，每次迭代都需要历遍整个训练集，可以预期每次迭代成本都会下降，所以如果成本函数$J$是迭代次数的一个函数，它应该会随着每次迭代而减少。

使用**mini-batch**梯度下降法，如果作出成本函数在整个过程中的图，则并不是每次迭代都是下降的，如果要作出成本函数$J^{\{t\}}$的图，很可能会看到上图右边的结果，走向朝下，但有更多的噪声。没有每次迭代都下降是不要紧的，但走势应该向下。噪声产生的原因在于也许$X^{\{1\}}$和$Y^{\{1\}}$是比较容易计算的**mini-batch**，因此成本会低一些。不过也许出于偶然，$X^{\{2\}}$和$Y^{\{2\}}$是比较难运算的**mini-batch**，或许有一些残缺的样本，这样一来，成本会更高一些，所以才会出现这些摆动，因为是在运行**mini-batch**梯度下降法作出成本函数图。

==需要决定的变量之一是**mini-batch**的大小==，$m$就是训练集的大小，极端情况下，如果**mini-batch**的大小等于$m$，其实就是**batch**梯度下降法，在这种极端情况下，你就有了**mini-batch**  $X^{\{1\}}$和$Y^{\{1\}}$，并且该**mini-batch**等于整个训练集，所以把**mini-batch**大小设为$m$可以得到**batch**梯度下降法。

另一个极端情况，假设**mini-batch**大小为1，就有了新的算法，叫做随机梯度下降法，每个样本都是独立的**mini-batch** 。如果**mini-batch**大小为1，它就是你的第一个训练样本，这就是你的第一个训练样本。接着再看第二个**mini-batch**，也就是第二个训练样本，采取梯度下降步骤，然后是第三个训练样本，以此类推，一次只处理一个。

![mini-batch成本函数轮廓](http://www.ai-start.com/dl2017/images/bb2398f985f57c5d422df3c71437e5ea.png)

（图中蓝线）看在两种极端下成本函数的优化情况，如果这是想要最小化的成本函数的轮廓，**batch**梯度下降法从某处开始，相对噪声低些，幅度也大一些，可以继续找最小值。

（图中紫线）相反在随机梯度下降法中，从某一点开始，我们重新选取一个起始点，每次迭代，你只对一个样本进行梯度下降，大部分时候你向着全局最小值靠近，有时候你会远离最小值，因为那个样本恰好给你指的方向不对。因此随机梯度下降法是有很多噪声的，平均来看，它最终会靠近最小值，不过有时候也会方向错误。因为随机梯度下降法永远不会收敛，会一直在最小值附近波动，但它并不会在达到最小值并停留在此。

如果每次只处理一个样本，那这个方法很好，这样做没有问题，通过减小学习率，噪声会被改善或有所减小，但随机梯度下降法的一大缺点是，但会失去所有向量化带来的加速，因为一次性只处理了一个训练样本，这样效率过于低下。

所以实践中最好选择不大不小的**mini-batch**尺寸，实际上学习率达到最快。可以发现两个好处：一方面，得到了大量向量化，如果**mini-batch**大小为1000个样本，就可以对1000个样本向量化，比一次性处理多个样本快得多；另一方面，不需要等待整个训练集被处理完就可以开始进行后续工作，实际上一些位于中间的**mini-batch**大小效果最好。

（图中绿线）用**mini-batch**梯度下降法，经过一次迭代，两次，三次，四次，它不会总朝向最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向，它也不一定在很小的范围内收敛或者波动，如果出现这个问题，可以慢慢减少学习率。

**mini-batch大小选取：**

==一般的**mini-batch**大小为64到512，考虑到电脑内存设置和使用的方式，如果**mini-batch**大小是2的$n$次方，代码会运行地快一些==。也有**mini-batch**的大小为1024，不过比较少见，64到512的**mini-batch**比较常见。

最后需要注意的是在**mini-batch**中，要确保$X^{\{ t\}}$和$Y^{\{t\}}$要符合**CPU**/**GPU**内存，取决于你的应用方向以及训练集的大小。如果你处理的**mini-batch**和**CPU**/**GPU**内存不相符，不管用什么方法处理数据，会注意到算法的表现急转直下变得惨不忍睹。事实上**mini-batch**大小是另一个重要的变量，需要做一个快速尝试，才能找到能够最有效地减少成本函数的那个，一般会几个不同的2次方，然后看能否找到一个让梯度下降优化算法最高效的大小。

### 3. 指数加权平均数（Exponentially weighted averages）

还有一些优化算法，它们比梯度下降法快，要理解这些算法，需要用到指数加权平均。
![指数加权平均数](http://www.ai-start.com/dl2017/images/a3b26bbce9cd3d0decba5aa8b26af035.png)
假设一年的温度如上图蓝点所示，看起来有些杂乱，如果要计算趋势的话，也就是温度的局部平均值，或者说移动平均值。要做的是:

首先使$v_{0} =0$，每天，需要使用0.9的加权数乘以之前的数值加上当日温度的0.1倍，即$v_{1} =0.9v_{0} + 0.1\theta_{1}$，所以这里是第一天的温度值。

第二天，0.9乘以之前的值加上当日的温度0.1倍，即$v_{2}= 0.9v_{1} + 0.1\theta_{2}$，以此类推。就可以绘制出上图的红线。

大体公式就是：$v_{t} = 0.9v_{t - 1} +0.1\theta_{t}$，把0.9这个常数变成$\beta$，将之前的0.1变成$(1 - \beta)$，即：$v_{t} = \beta v_{t - 1} + (1 - \beta)\theta_{t}$ 。由于以后要考虑的原因，在计算时可视$v_{t} \approx \frac{1}{(1 -\beta)} $大概是几日的平均温度。

如果$\beta$是0.9，$\frac{1}{(1 - 0.9)} =10$，这是十天的平均值，也就是红线部分。将$\beta$设置为0.98，$\frac{1}{(1 - 0.98)} =50$，这就是粗略平均了一下过去50天的温度，这时作图可以得到绿线。

这里$\beta$越高，得到的曲线要平坦一些，原因在于多平均了几天的温度，所以这个曲线，波动更小，更加平坦。缺点是曲线进一步右移，因为现在平均的温度值更多，要平均更多的值，==指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定延迟== 。因为当$\beta=0.98$，相当于给前一天的值加了太多权重，只有0.02的权重给了当日的值，所以温度变化时，温度上下起伏，当$\beta$ 较大时，指数加权平均值适应地更缓慢一些。

如果$\beta$是另一个极端值，比如说0.5，根据右边的公式$\frac{1}{(1-\beta)}$，是平均了两天的温度：

![](http://www.ai-start.com/dl2017/images/369ae78c3b63e5b537cc0e30f60eb471.png)

作图运行后得到黄线，由于仅平均了两天的温度，平均的数据太少，所以得到的曲线有更多的噪声，有可能出现异常值，但是这个曲线能够更快适应温度变化。

所以指数加权平均数经常被使用，它在统计学中被称为指数加权移动平均值，简称为指数加权平均数。通过调整参数（$\beta$），可以取得稍微不同的效果，往往中间有某个值效果最好，$\beta$为中间值时得到的红色曲线，比起绿线和黄线更好地平均了温度。

### 4. 理解指数加权平均数（Understanding exponentially weighted averages）

指数加权平均数，是几个优化算法中的关键一环。计算指数加权平均数的关键方程：
$$
{{v}_{t}}=\beta {{v}_{t-1}}+(1-\beta ){{\theta }_{t}}
$$
使$\beta=0.9$，写下相应的几个公式：

![](http://www.ai-start.com/dl2017/images/9ab7565d5a3e13a9a525ec6d2f119a79.png)

将上述公式合并，求得$v_{100}$:

$v_{100} = 0.1\theta_{100} + 0.1 \times 0.9 \theta_{99} + 0.1 \times {(0.9)}^{2}\theta_{98} + 0.1 \times {(0.9)}^{3}\theta_{97} + 0.1 \times {(0.9)}^{4}\theta_{96} + \ldots$

分析$v_{100}$的组成，包括100号数据，99号数据，97号数据等等。画图的一个办法是，假设我们有一些日期的温度，横轴表示天数$t$，纵轴为对应的温度。有下图的数日的温度数值：

![](http://www.ai-start.com/dl2017/images/469d894aae98925841134e9766557fc7.png)

然后构建一个指数衰减函数，从0.1开始，到$0.1 \times 0.9$，到$0.1 \times {(0.9)}^{2}$，以此类推，所以就有了这个指数衰减函数：

![](http://www.ai-start.com/dl2017/images/a0bbcc060cac02d8d3f0b1403484f017.png)

计算$v_{100}$是通过数值100号数据值乘以0.1，99号数据值乘以0.1乘以${(0.9)}^{2}$，这是第二项，以此类推，所以选取的是每日温度，将其与指数衰减函数相乘，然后求和，就得到了$v_{100}$。所有的这些系数（$0.10.1 \times 0.90.1 \times {(0.9)}^{2}0.1 \times {(0.9)}^{3}\ldots$），相加起来为1或者逼近1，我们称之为偏差修正。

最后也许你会问，到底需要平均多少天的温度。实际上${(0.9)}^{10}$大约为0.35，这大约是$\frac{1}{e}$，e是自然算法的基础之一。大体上说，如果有$1-\varepsilon$，在这个例子中，$\varepsilon=0.1$，所以$1-\varepsilon=0.9$，${(1-\varepsilon)}^{(\frac{1}{\varepsilon})}$约等于$\frac{1}{e}$，大约是0.35。换句话说，10天后，曲线的高度下降到$\frac{1}{3}$，相当于在峰值的$\frac{1}{e}$。因此当$\beta=0.9$的时候，大概是对过去10天的温度计算一个指数加权平均数。因为10天后，权重下降到不到当日权重的三分之一。

如果$\beta = 0.98$需要多少次方才能达到这么小的数值？在例子中，$\varepsilon=0.02$，所以$\frac{1}{\varepsilon}$为50，我们由此得到公式，我们平均了大约$\frac{1}{(1-\beta)}$天的温度，这里$\varepsilon$代替了$1 - \beta$。${(0.98)}^{50}$大约等于$\frac{1}{e}$，所以前50天这个数值比$\frac{1}{e}$大，数值会快速衰减，所以本质上这是一个下降幅度很大的函数，可以看作平均了50天的温度。因为也就是说根据一些常数，你能大概知道能够平均多少日的温度，不过这只是思考的大致方向，并不是正式的数学证明。

**实操中算法实现：**

在实际中执行的话，初始令$v_{\theta} =0$，然后每一天，拿到第$t$天的数据，把$v$更新为$v_{\theta}: = \beta v_{\theta} + (1 -\beta)\theta_{t}$。
$$
\begin{split}
&V_{\theta} = 0 \\ 
&Repeat\{ \\
&&V_{\theta} := \beta \cdot V_{\theta} + (1-\beta) \theta_t\\
&\}
\end
{split}
$$
指数加权平均数公式的好处之一在于，它占用极少内存，电脑内存中只占用一行数字而已，然后把最新数据代入公式，不断覆盖就可以了，正因为这个原因，其效率，它基本上只占用一行代码，计算指数加权平均数也只占用单行数字的存储和内存，当然它并不是最好的，也不是最精准的计算平均数的方法。你可以直接算出过去10天的总和，过去50天的总和，除以10和50就好，如此往往会得到更好的估测。但缺点是，如果保存所有最近的温度数据，和过去10天的总和，必须占用更多的内存，执行更加复杂，计算成本也更加高昂。

后面的优化算法中会计算多个变量的平均值，从计算和内存效率来说，这是一个有效的方法，所以在机器学习中会经常使用，更不用说只要一行代码，这也是一个优势。

### 5. 指数加权平均的偏差修正（Bias correction in exponentially weighted averages）

有一个技术名词叫做偏差修正，可以让平均数运算更加准确，来看看它是怎么运行的。

![](http://www.ai-start.com/dl2017/images/26a3c3022a7f7ae7ba0cd27fc74cbcf6.png)

图中的红色曲线对应$\beta$的值为0.9，绿色曲线对应的$\beta$=0.98，如果执行$v_{\theta}: = \beta v_{\theta} + (1 -\beta)\theta_{t}$公式，在$\beta$等于0.98的时候，得到的并不是绿色曲线，而是紫色曲线，可以注意到紫色曲线的起点较低。

计算移动平均数的时候，初始化$v_{0} = 0$，$v_{1} = 0.98v_{0} +0.02\theta_{1}$，但是$v_{0} =0$，所以没有了$0.98v_{0}$，所以$v_{1} =0.02\theta_{1}$，所以如果一天温度是40华氏度，那么$v_{1} = 0.02\theta_{1} =0.02 \times 40 = 8$，因此得到的值会小很多，所以第一天温度的估测不准。

$v_{2} = 0.98v_{1} + 0.02\theta_{2}$，如果代入$v_{1}$，所以$v_{2}= 0.98 \times 0.02\theta_{1} + 0.02\theta_{2} = 0.0196\theta_{1} +0.02\theta_{2}$，假设$\theta_{1}$和$\theta_{2}$都是正数，计算后$v_{2}$要远小于$\theta_{1}$和$\theta_{2}$，所以$v_{2}$不能很好估测出这一年前两天的温度。

有个办法可以修改这一估测，让估测变得更好，更准确，特别是在估测初期，也就是不直接用$v_{t}$，而是用$\frac{v_{t}}{1- \beta^{t}}$，t就是现在的天数。举个具体例子，当$t=2$时，$1 - \beta^{t} = 1 -  {0.98}^{2} = 0.0396$，因此对第二天温度的估测变成了$\frac{v_{2}}{0.0396} =\frac{0.0196\theta_{1} +  0.02\theta_{2}}{0.0396}$，也就是$\theta_{1}$和$\theta_{2}$的加权平均数，并去除了偏差。

会发现随着$t$增加，$\beta^{t}$接近于0，所以当$t$很大的时候，偏差修正几乎没有作用，因此当$t$较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。

在机器学习中，在计算指数加权平均数的大部分时候，大家不在乎执行偏差修正，因为大部分人宁愿熬过初始时期，拿到具有偏差的估测，然后继续计算下去。如果你关心初始时期的偏差，在刚开始计算指数加权移动平均数的时候，偏差修正能帮助你在早期获取更好的估测。

### 6. 动量梯度下降法（Gradient descent with Momentum）

还有一种算法叫做**Momentum**，或者叫做动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法，简而言之，基本的想法就是计算梯度的指数加权平均数，并利用该梯度更新权重。

如果要优化成本函数，函数形状如下图，红点代表最小值的位置，如果进行梯度下降法的一次迭代，无论是**batch**或**mini-batch**下降法，这种上下波动减慢了梯度下降法的速度，你就无法使用更大的学习率，如果要用较大的学习率（紫色箭头），结果可能会偏离函数的范围，为了避免摆动过大，需要用一个较小的学习率，慢慢摆动到最小值。

![](http://www.ai-start.com/dl2017/images/cc2d415b8ccda9fdaba12c575d4d3c4b.png)

另一个看待问题的角度是，**在纵轴上，希望学习慢一点，因为不想要这些摆动，但是在横轴上，希望加快学习能快速从左向右移，移向最小值**。

**算法实现：**

所以使用动量梯度下降法，需要做的是，在每次迭代中，需要计算微分$dW$，$db$。如果现有的**mini-batch**就是整个训练集，效果也不错，需要做的是：
$$
\begin{split}
v_{{dW}}&:= \beta v_{{dW}} + \left( 1 - \beta \right)dW \\ 
W&:= W -\alpha v_{{dW}} \\
b&:= b - \alpha v_{db}
\end
{split}
$$
计算$v_{{dW}}= \beta v_{{dW}} + \left( 1 - \beta \right)dW$，这跟我们之前的计算相似，也就是$v = \beta v + \left( 1 - \beta \right)\theta_{t}$，$dW$的移动平均数，接着同样地计算$v_{db}$，$v_{db} = \beta v_{{db}} + ( 1 - \beta){db}$，然后重新赋值权重，$W:= W -\alpha v_{{dW}}$，同样$b:= b - \alpha v_{db}$，这样就可以减缓梯度下降的幅度。

在上面公式中可以发现这些纵轴上的摆动平均值接近于零，所以在纵轴方向，希望放慢一点，平均过程中，正负数相互抵消，所以平均值接近于零。但在横轴方向，所有的微分都指向横轴方向，因此横轴方向的平均值仍然较大。因此用算法几次迭代后，可以发现动量梯度下降法，最终纵轴方向的摆动变小了，横轴方向运动更快，因此算法走了一条更加直接的路径，在抵达最小值的路上减少了摆动。

**算法说明：**

现在有两个超参数，学习率$\alpha$以及参数$\beta$，$\beta$控制着指数加权平均数。$\beta$最常用的值是0.9，平均了前十次迭代的梯度。实际上$\beta$为0.9时，效果不错，也可以尝试不同的值，可以做一些超参数的研究，不过0.9是很棒的鲁棒数。

关于偏差修正，需要要拿$v_{dW}$和$v_{db}$除以$1-\beta^{t}$，实际上人们不这么做，因为10次迭代之后，因为移动平均已经过了初始阶段。实际中，在使用梯度下降法或动量梯度下降法时，人们不会受到偏差修正的困扰。

当然$v_{{dW}}$初始值是0，要注意到这是和$dW$拥有相同维数的零矩阵，也就是跟$W$拥有相同的维数，$v_{db}$的初始值也是向量零，所以和$db$拥有相同的维数，也就是和$b$是同一维数。

最后要说一点，如果查阅动量梯度下降法相关资料，经常用到的是：$v_{dW}= \beta v_{{dW}} +dW$。结果就是，$v_{{dW}}$缩小了$1-\beta$倍，相当于乘以$\frac{1}{1- \beta}$，所以要用梯度下降最新值的话，$\alpha$要根据$\frac{1}{1 -\beta}$相应变化。

实际上，二者效果都不错，只会影响到学习率$\alpha$的最佳值。这个公式用起来没有那么自然，因为有一个影响，如果最后要调整超参数$\beta$，就会影响到$v_{{dW}}$和$v_{db}$，也许还要修改学习率$a$，所以更喜欢没有删去$1-\beta$的这个公式，但是两个公式都将$\beta$设置为0.9，是超参数的常见选择，只是在这两个公式中，学习率$a$的调整会有所不同。

所以这就是动量梯度下降法，这个算法肯定要好于没有**Momentum**的梯度下降算法。

### 7. RMSprop

还有一个叫做**RMSprop**的算法，全称是**root mean square prop**算法，它也可以加速梯度下降。

![](http://www.ai-start.com/dl2017/images/d43cf7898bd88adff4aaac607c1bd5a1.png)

假设纵轴代表参数$b$，横轴代表参数$W$，可能有$W_{1}$，$W_{2}$或者其它重要的参数，为了便于理解，被称为$b$和$W$。如果想减缓纵轴方向的学习，同时加快至少不是减缓横轴方向的学习，**RMSprop**算法可以实现这一点。

**算法实现：**

在第$t$次迭代中，这里用到新符号$S_{dW}$，而不是$v_{dW}$：
$$
\begin{split}
S_{{dW}}&:= \beta_2 S_{{dW}} + \left( 1 - \beta_2 \right)dW^2 \\
S_{{db}}&:= \beta_2 S_{{db}} + \left( 1 - \beta_2 \right)db^2 \\
W &:= W -\alpha \frac{dW}{\sqrt{S_{dW}}} \\
b &:=b -\alpha\frac{db}{\sqrt{S_{db}}}
\end
{split}
$$
这里的平方是对每一个元素的操作。

**算法讲解：**

在例子中的$W$方向，希望学习速度快，而在垂直方向即例子中的$b$方向，希望减缓纵轴上的摆动，所以有了$S_{dW}$和$S_{db}$。我们希望$S_{dW}$会相对较小，所以要除以一个较小的数，而希望$S_{db}$又较大，所以要除以较大的数字，这样就可以减缓纵轴上的变化。

这些微分，垂直方向的要比水平方向的大得多，所以斜率在$b$方向特别大，所以这些微分中，$db$较大，$dW$较小。因为函数的倾斜程度，在纵轴上，也就是b方向上要大于在横轴上。$db$的平方较大，所以$S_{db}$也会较大，而相比之下，$dW$会小一些，因此$S_{dW}$会小一些，结果就是**纵轴上的更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除**。

**RMSprop**的影响就是更新最后会变成上图中的绿色线，纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，可以用一个更大学习率$\alpha$，然后加快学习，而无须在纵轴上垂直方向偏离。

要说明一点，这里一直把纵轴和横轴方向分别称为$b$和$W$，只是为了方便展示而已。实际中$dW$是一个高维度的参数向量，$db$也是一个高维度参数向量，在要消除摆动的维度中，最终要计算一个更大的和值，这个平方和微分的加权平均值，所以最后去掉了那些有摆动的方向。所以这就是**RMSprop**，全称是均方根。因为先将微分进行平方，然后最后使用平方根。

**算法细节补充：**

采用超参数$\beta_{2}$以保证在**Momentum**和**RMSprop**中二者参数不混淆。

要确保这里的算法不会除以0，如果$S_{dW}$的平方根趋近于0，得到的答案就非常大，为了确保数值稳定，在实际操练的时候，需要在分母上加上一个很小的$\varepsilon$，$\varepsilon$是多少没关系，$10^{-8}$是个不错的选择，这只是保证数值能稳定一些，都不会除以一个很小很小的数。

所以**RMSprop**跟**Momentum**有很相似的一点，可以消除梯度下降中的摆动，包括**mini-batch**梯度下降，但==**RMSprop**允许使用一个更大的学习率$\alpha$，从而加快算法学习速度==。

### 8. Adam 优化算法(Adam optimization algorithm)

**Adam**优化算法基本上就是将**Momentum**和**RMSprop**结合在一起。**Adam**代表的是**Adaptive Moment Estimation**，$\beta_{1}$用于计算这个微分（$dW$），叫做第一矩，$\beta_{2}$用来计算平方数的指数加权平均数（${(dW)}^{2}$），叫做第二矩，所以**Adam**的名字由此而来。

1. 首先进行初始化：

$$
v_{dW} = 0,S_{dW} =0,v_{db} = 0,S_{db} =0
$$

2. 在第$t$次迭代中，用当前的**mini-batch**计算$dW$，$db$：
   - 接下来计算**Momentum**指数加权平均数:
     $$
     v_{dW}:= \beta_{1}v_{dW} + ( 1 - \beta_{1})dW, v_{db}:= \beta_{1}v_{db} + ( 1 -\beta_{1} ){db}
     $$

   - 接着用**RMSprop**进行更新:
     $$
     S_{dW}:=\beta_{2}S_{dW} + ( 1 - \beta_{2}){(dW)}^{2}, S_{db} :=\beta_{2}S_{db} + \left( 1 - \beta_{2} \right){(db)}^{2}
     $$
     相当于**Momentum**更新了超参数$\beta_{1}$，**RMSprop**更新了超参数$\beta_{2}$。

   - 一般使用**Adam**算法的时候，要计算偏差修正: 
     $$
     \begin{split}
     v_{dW}^{\text{corrected}}= \frac{v_{dW}}{1 - \beta_{1}^{t}},v_{db}^{\text{corrected}} =\frac{v_{db}}{1 -\beta_{1}^{t}} \\
     S_{dW}^{\text{corrected}} =\frac{S_{dW}}{1 - \beta_{2}^{t}},S_{db}^{\text{corrected}} =\frac{S_{db}}{1 - \beta_{2}^{t}}
     \end
     {split}
     $$


3. 最后更新权重:

$$
\begin{split}
W&:= W - \frac{\alpha v_{dW}^{\text{corrected}}}{\sqrt{S_{dW}^{\text{corrected}}} +\varepsilon} \\
b&:=b - \frac{\alpha v_{\text{db}}^{\text{corrected}}}{\sqrt{S_{\text{db}}^{\text{corrected}}} +\varepsilon}
\end
{split}
$$

所以**Adam**算法结合了**Momentum**和**RMSprop**梯度下降法，并且是一种极其常用的学习算法，被证明能有效适用于不同神经网络，适用于广泛的结构。

**Adam超参说明：**

本算法中有很多超参数，超参数学习率$\alpha$很重要，也经常需要调试，可以尝试一系列值，然后看哪个有效。

$\beta_{1}$常用的缺省值为0.9，是$dW$的加权平均数，这是**Momentum**涉及的项。

超参数$\beta_{2}$，**Adam**论文作者推荐使用0.999，这是在计算${(dW)}^{2}$以及${(db)}^{2}$的移动加权平均值。

关于$\varepsilon$的选择其实没那么重要，**Adam**论文的作者建议$\varepsilon$为$10^{-8}$，但你并不需要设置它，因为它并不会影响算法表现。但是在使用**Adam**的时候，人们往往使用缺省值即可，$\beta_{1}$，$\beta_{2}$和$\varepsilon$都是如此，没人会去调整$\varepsilon$，然后尝试不同的$\alpha$值，看看哪个效果最好。

也可以调整$\beta_{1}$和$\beta_{2}$，但业内人士很少这么干。

### 9. 学习率衰减(Learning rate decay)

**加快学习算法的一个办法就是随时间慢慢减少学习率，将之称为学习率衰减**。

假设使用mini-batch梯度下降法，mini-batch数量不大，大概64或者128个样本，在迭代过程中会有噪音，下降朝向最小值，但是不会精确地收敛，所以算法最后在附近摆动，并不会真正收敛，因为你用的$\alpha$是固定值，不同的mini-batch中有噪音。

但要慢慢减少学习率$\alpha$的话，在初期的时候，$a$学习率还较大，学习还是相对较快，但随着$\alpha$变小，步伐也会变慢变小，所以最后曲线会在最小值附近的一小块区域里摆动，而不是大幅度在最小值附近摆动。

所以**慢慢减少$\alpha$的本质在于，在学习初期，能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让步伐小一些**。

**学习率衰减方法：**

数据集拆分成不同的mini-batch，遍历一次全部数据叫一代，第一次遍历训练集叫做第一代第二次就是第二代，依此类推。可以将学习率设为$\alpha= \frac{1}{1 + decay-rate * \text{epoch}\text{-num}}\alpha_{0}$（decay-rate称为衰减率，epoch-num为代数，$\alpha_{0}$为初始学习率），注意**衰减率decay-rate是另一个需要调整的超参数**。

代数函数，根据上述公式，学习率呈递减趋势。如果想用学习率衰减，要做的是要去尝试不同的值，包括超参数$\alpha_{0}$，以及超参数衰退率decay-rate，找到合适的值。除了这个学习率衰减的公式，人们还会用其它的公式。

**其他学习率衰减公式：**

- 指数衰减：其中$\alpha$相当于一个小于1的值，如$\alpha ={0.95}^{\text{epoch-num}} \alpha_{0}$，所以学习率呈指数下降。
- 人们用到的其它公式有$\alpha =\frac{k}{\sqrt{\text{epoch-num}}}\alpha_{0}$。
- $\alpha =\frac{k}{\sqrt{t}}\alpha_{0}$（$t$为mini-batch的数字）。
- 有时人们也会用一个离散下降的学习率，也就是某个步骤有某个学习率，一会之后，学习率减少了一半，一会儿减少一半，一会儿又一半，这就是离散下降（**discrete stair cease**）的意思。

### 10. 局部最优的问题(The problem of local optima)

在深度学习研究早期，人们总是担心优化算法会困在极差的局部最优，不过随着深度学习理论不断发展，我们对局部最优的理解也发生了改变。

![](http://www.ai-start.com/dl2017/images/1f7df04b804836fbcadcd258c0b55f74.png)

曾经人们在想到局部最优时脑海里会出现的图，在图中似乎各处都分布着局部最优。梯度下降法或者某个算法可能困在一个局部最优中，而不会抵达全局最优。如果作图计算一个数字，比如说这两个维度，就容易出现有多个不同局部最优的图，而这些低维的图曾经影响了我们的理解，但是这些理解并不正确。

事实上，如果创建一个神经网络，通常梯度为零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点通常是鞍点。

![](http://www.ai-start.com/dl2017/images/c5e480c51363d55e8d5e43df1eee679b.png)

一个具有高维度空间的函数，如果梯度为0，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在2万维空间中，那么想要得到局部最优，所有的2万个方向都需要是这样，但发生的机率也许很小，也许是$2^{-20000}$。

你更有可能遇到有些方向的曲线会这样向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，因此在高维度空间，你更可能碰到鞍点。

所以我们从深度学习历史中学到的一课就是，我们对低维度空间的大部分直觉，比如可以画出上面的图，并不能应用到高维度空间中。适用于其它算法，因为如果你有2万个参数，那么$J$函数有2万个维度向量，你更可能遇到鞍点，而不是局部最优点。

**深度学习遇到的问题：**

如果局部最优不是问题，那么问题是什么？是**平稳段会减缓学习**。平稳段是一块区域，其中导数长时间接近于0。曲面很平坦，得花上很长时间慢慢抵达平稳段的红点。之后可以沿着另一个长坡走，直到蓝色区域低点处，然后走出平稳段。

![](http://www.ai-start.com/dl2017/images/607bd30801c87ed74bb95c49f218f632.png)

此篇主要讲的是：

- 首先，不太可能困在极差的局部最优中，条件是在训练较大的神经网络，存在大量参数，并且成本函数$J$被定义在较高的维度空间。
- 第二点，平稳段是一个问题，这样使得学习十分缓慢，这也是像**Momentum**或是**RMSprop**，**Adam**这样的算法，能够加速学习算法的地方。在这些情况下，更成熟的优化算法，如**Adam**算法，能够加快速度，使算法尽早往下走出平稳段。

因为网络要解决优化问题，说实话，要面临如此之高的维度空间，没有人有那么好的直觉，知道这些空间长什么样，而且我们对它们的理解还在不断发展，希望这些能够让你更好地理解优化算法所面临的问题。