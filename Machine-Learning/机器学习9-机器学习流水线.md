[TOC]

照片OCR
---

**照片OCR**是指**照片光学字符识别（photo optical character recognition）**，这种照片OCR技术主要解决的问题是让计算机读出照片中拍到的文字信息。大概步骤如下：

1. 文字识别技术（Text detection）

   **文字识别技术（Text detection）**将给定的图片扫描一遍，找出这张图片中哪里有文字信息

2. 字符切分

   接下来就是重点关注这些文字区域，对这些文字区域的矩形轮廓进行字符切分

3. 字符分类

   当文字被分割成独立的字符之后，可以尝试运行一个分类器，输入这些可识别的字符，然后试着识别出上面的字符。

### 机器学习流水线（machine learning pipeline）

![机器学习流水线](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%81%E6%B0%B4%E7%BA%BF.png)

在很多复杂的机器学习系统中，这种流水线形式都非常普遍。在流水线中会有多个不同的模块，比如在OCR中有文字检测、字符分割和字母识别，其中每个模块都可能是一个机器学习组件。

用流水线的方式通常提供了一个很好的办法来将整个工作分给不同的组员去完成。（当然所有这些工作都可以由一个人来完成，如果你希望这样做的话。）在复杂的机器学习系统中，流水线的概念已经渗透到各种应用中。

### 滑动窗体

在照片OCR中，可以使用**滑动窗体(sliding windows)**分类器来识别图片中的文字。

文字识别是计算机视觉中的一个非同寻常的问题，因为取决于想要找到的文字的长度。这些长方形区域会呈现不同的宽高比。为了更好地介绍图像检测，从一个简单一点的行人探测的例子开始，以下是具体步骤：

1. 指定行人矩形比例，把宽高比标准化到一个具体比例

2. 搜集样本

3. 训练算法

   如果能得到大规模训练样本的话，然后要做的事是训练一个神经网络或者别的什么学习算法，输入这些维度的图像块，然后对$y$进行分类，把图像块分成”有行人”和”没有行人”两类。

   ![滑动窗体](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%BB%91%E5%8A%A8%E7%AA%97%E4%BD%93.gif)

   把这个绿色的长方形图片滑动一点点，得到一个新的图像块，并同样把它传入分类器看看这里面有没有行人。

   每次滑动窗口的大小是一个参数，通常被称为**步长(step size)**，有时也称为**步幅参数(stride parameter)**。步长为1代表每次移动一个像素，这样通常表现得最好但可能计算量比较大，因此通常使用4个像素、或者8个像素、或者更多像素作为步长值。

4. 这个矩形是非常小的，只能探测到某种尺寸的行人。接下来要做的是看看更大的图像块。因此用更大矩形来滑过图片，传入分类器运行。

   以此类推，接下来可以用一个更大的矩形，以同样的方式滑动窗口。直到完成最后的扫描过程之后，算法应该就能检测出图像中是否出现行人了。

整个步骤就是：训练一个分类器，然后用一个滑动窗分类器来找出图像中出现的行人。

#### OCR文字检测

跟行人检测类似可以先收集一些带标签的训练集，通过使用这些训练集来训练识别文字的分类器。

训练完了以后，就可以把它应用到测试集图片中。这里我们用一个固定的比例的矩形作为窗体来运行滑动窗体。白色区域代表找到了文字的区域，黑色区域代表没有找到文字。不同的灰度表示分类器给出的输出结果的概率值，所以比如有些灰色的阴影表示分类器在这片区域似乎发现了文字，但并不十分确信；而比较白亮的区域则表示分类器预测这个区域有文字 的概率比较大。

![文字检测](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%96%87%E5%AD%97%E6%A3%80%E6%B5%8B.png)

之后输入到一个被称为**“展开器”(expansion operator)**的地方，从数学上来讲，对于每一个像素，我们都考察一下它是不是在左边这幅图中的某个白色像素的范围之内。比如说，某一个像素点在最左边那幅图中白色像素点的五或十个像素范围中，那么我们将把右边那幅图的相同像素设为白色。

找到这些有文字的长方形以后，现在就能够剪下这些图像区域，然后应用流水线的后面步骤对文字进行识别。

### 字符分割

同样地，还是使用一种监督学习算法，用一些是否存在**字符之间的分割区域**的正样本和一些负样本来训练一个分类器。

| 正样本：存在字符间分各区域$(y=1)$                     | 负样本：不存在字符间分割区域$(y=0)$                    |
| ---------------------------------------- | ---------------------------------------- |
| ![字符分割1](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%AD%97%E7%AC%A6%E5%88%86%E5%89%B21.png) | ![字符分割2](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E5%AD%97%E7%AC%A6%E5%88%86%E5%89%B22.png) |

使用同样的**窗体滑动**方式（只不过使用的分类器不同），扫描文字检测系统输出的文字区域图像：

<img src="http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E7%AA%97%E4%BD%93%E6%BB%91%E5%8A%A81.png" width="400px" alt="窗体滑动1"/>

<img src="http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E7%AA%97%E4%BD%93%E6%BB%91%E5%8A%A82.png" width="400px" alt="窗体滑动2"/>

分类器告诉我们$y=1$时，就意味着我们需要在中间画一条线，分开两个字符，否则就跳过。如果正常的话，分类器会告诉我们应该在什么地方来将图像分割为独立的字符。

### 获取大量数据和人工数据

在机器学习中有一个很棒的想法，叫做**“人工数据合成”（artificial data synthesis）**可以帮助我们获取大量训练数据。

**人工数据合成**的概念通常包含两种不同的变体：

- 第一种，是白手起家来创造新的数据。

  有了原始数据，如果想要获得更多的训练样本，其中一种方法是可以采集同一个字符的不同种字体，然后将这些字符加上不同的随机背景来创造训练样本。通过这样的操作之后，可以得到这样一个合成之后的训练集。

  <mark>在生成模拟数据的时候，需要考虑对模拟的样本进行**模糊**、**变形**、**旋转**等操作</mark>，因为这样创造出来的样本比较真实。如果草率的生成一些样本，那么最终训练出来的算法可能效果不是很好。

- 第二种，是通过扩大一个已经存在的带标签的小的训练集，来获得数据。

  一定要考虑好添加的那些额外的变形量是有意义的，能让你产生的训练样本至少在某种程度上是具有一定的代表性，能代表你可能会在测试集中看到的某种图像。

上限分析
---

**在开发机器学习系统时，最宝贵的资源就是时间**，**上限分析(ceiling analysis)**这种方式通常能提供一种很有价值的信号，告诉你流水线中的哪个部分最值得你花时间。

### 主要思想

假设整个系统的估计准确率为72%（对测试集上的图像分别运行流水线上的每一个模块操作之后，整个测试集的准确率是72%）

1. 首先，模拟在**文字检测**准确率100%的情况下，得出当前系统的准确率。（可以通过人工的方式找出这种样本）
2. 然后以同样的方式，得出在**文字检测**，以及**字符切分**准确率100%的情况下，当前系统的准确率。
3. 我们也要写出在**文字检测**、**字符切分**以及**字符识别**准确率100%的情况下，当前系统的准确率（当然是100%）。

| 模块       | 准确率      |
| -------- | -------- |
| 整个系统     | 72%      |
| 文字检测     | 89%      |
| 字符切分     | 90%      |
| **字符识别** | **100%** |

有了这些数据，我们就知道了每一个模块进行改善它们各自的上升空间是多大。

可以看到，如果我们拥有完美的文字检测模块，那么整个系统的表现将会从准确率72%上升到89%，因此效果的增益是17%。这就意味着，如果在现有系统的基础上花费时间和精力改善文字检测模块的效果，那么系统的表现可能会提高17%。

而相对来讲，如果取得完美的字符分割模块，那么最终系统表现只提升了1%。这给我们提供了一个很重要的信息，那就是不管我们投入多大精力在字符分割上，系统效果的潜在上升空间也都是很小很小。所以就不会让一个比较大的工程师团队花时间忙于字符分割模块，因为通过上限分析我们知道了即使把字符分割模块做得再好，再怎么完美，系统表现最多也只能提升1%。

最后，如果取得完美的字符识别模块，那么整个系统的表现将提高10%。所以，同样你可以分析10%的效果提升值得投入多少工作量。

### 总结

**不要凭自己的直觉来判断应该改进哪个模块**，相反地如果要解决某个机器学习问题，最好能把问题分成多个模块，然后做一下上限分析。这通常可以告诉我们一个更可靠的，关于该把劲儿往哪儿使的方法。