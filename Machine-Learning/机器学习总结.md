[TOC]

整体流程：
---

1. 数据清洗后，加载数据

   对数据样本进行拆分，按照3:1:1的比例拆分出：**训练集(Training Set)**、**交叉验证集（cross validation set）**、**测试集(Test Set)**

2. <mark>若数据跨度大，需要对数据统一做均值归一化处理</mark>

   所有特征值都在一个相近范围，这样梯度下降就能更快收敛（<mark>对$x_0$不进行均值归一化操作</mark>）
   $$
   x_i := \frac{x_i (原值)- u_i(均值)}{s_i(标准偏差)}
   $$

3. 执行简单模型预测（便于快速实现）

4. 绘制学习曲线，在改进一个学习算法的时候，通常要先画出这些学习曲线。这项工作会让你更轻松地看出偏差或方差的问题（详情见博客）

   ![高偏差学习曲线](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF.png)

   **如果学习算法正处于高偏差的情形，那么选用更多的训练集数据对于改善算法表现无益。**

   ![高方差学习曲线](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E9%AB%98%E6%96%B9%E5%B7%AE%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF.png)

   **高方差情形下使用更多的样本数量对改进算法的表现事实上是有效果的。**

5. 绘制交叉验证曲线

   ![lambda与偏差方差](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/lambda%E4%B8%8E%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE.jpeg)

   - $\lambda$取一个比较大的值（比如$\lambda$的值取为10000甚至更大），所有参数$\theta_i$将被大大惩罚，参数的值将近似于等于0，并且假设模型$h(x)$的值将等于或者近似等于$\theta_0$，造成欠拟合。
   - $\lambda$的值很小（比如说$\lambda$的值等于0），相当于没有正则化项，造成过拟合。

线性回归
---

#### 代价函数（<mark>$\theta_0$不参与正则化</mark>）

$$
J(\theta)=\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2 + \frac{\lambda}{2m}\sum_{j=1}^{n}{\theta_j}^2
$$

矢量化：
$$
J(\theta) = \frac{1}{2m}(X\theta - \vec{y})^{T}(X\theta - \vec{y}) +\frac{\lambda}{2m} \theta^T\theta
$$

#### 梯度下降

$$
\begin{eqnarray*}
&& Repeat\{ && \\
&& && \theta_j := \theta_j - \alpha[\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} + \frac{\lambda}{m}\theta_j] \\
&& \} &&
\end{eqnarray*}
$$

即：
$$
\theta_j := \theta_j (1-\alpha\frac{\lambda}{m})- \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}
$$
比之前的梯度下降多出了$ (1-\alpha\frac{\lambda}{m})$，<mark>$\alpha\frac{\lambda}{m}$通常是小于1的正数，把$\theta_j$向0压缩了一点点</mark>。

矢量化：
$$
\theta := \theta - \alpha[\frac{1}{m} X^T(X\theta-y) + \frac{\lambda}{m}\theta]
$$

#### 梯度下降使用

$$
\theta_j := \theta_j - \alpha\frac{d}{d\theta_j}J(\theta)
$$

关于学习率$\alpha$的选择，为$\alpha$取一个范围的数，根据不同的$\alpha$来<mark>绘制$J(\theta)$与迭代次数的关系图</mark>来观察是否收敛，及收敛速度。

分类算法
---

### 逻辑回归

#### 代价函数（<mark>$\theta_0$不参与正则化</mark>）

$$
J(\theta)=-\frac{1}{m}\sum_{i=1}^m[y^{(i)}\log(h_\theta(x^{(i)})) + (1-y^{(i)})\log(1-h_\theta(x^{(i)}))]+ \frac{\lambda}{2m}\sum_{j=1}^{n}{\theta_j}^2
$$

矢量化：
$$
J(\theta) = -\frac{1}{m}(y^Tlog(g(X\theta)) + (1-y)^Tlog(1- g(X\theta)))+\frac{\lambda}{2m} \theta^T\theta
$$

#### 梯度下降

$$
\theta := \theta - \alpha[\frac{1}{m} X^T(g(X\theta)-y) + \frac{\lambda}{m}\theta]
$$

#### 多分类

依次拆分成每个类别对其他类别的二元分类，就得到了多个分类器，通过这些分类器来估算出给出$x$和参数$θ$时，$y=i$的概率：
$$
h_θ^{(i)}(x)=P(y=i|x;θ)　(i=1,2,3)
$$
训练样本$X \in R^{m×(N+1)}$，当训练类$k \in \{1,\ldots,K\}$的分类器时，需要一个m维向量的标签y，其中$y_i \in 0,1$表示第$i$个训练实例是否属于类$k$ ($y_i = 1$)，或者它属于其他不同的分类 ($y_i = 0$)。依次计算计算针对第k类的$\theta$。

参数<mark>$\Theta \in R^{K×(N+1)} $</mark>(此时$\theta$以行向量表示，不是之前的列向量)，其中**$\Theta$的每一行对应于一个分类**的学习逻辑回归参数。即$\Theta$矩阵中的行数等于输出层中的节点数，列数等于$X$即输入层的特征数。

为了做出预测，给定一个新的输入值$x$用来做预测，要做的就是在每个分类器里输入$x$，然后<mark>选择一个让$h_θ^{(i)}(x)$最大的$i$</mark>，这就是预测出的类别。

### SVM&Kernel

#### 核函数

- 线性核函数

  ```matlab
  function sim = linearKernel(x1, x2)
  %LINEARKERNEL returns a linear kernel between x1 and x2
  %   sim = linearKernel(x1, x2) returns a linear kernel between x1 and x2
  %   and returns the value in sim

  % Ensure that x1 and x2 are column vectors
  x1 = x1(:); x2 = x2(:);

  % Compute the kernel
  sim = x1' * x2;  % dot product

  end
  ```

- 高斯核函数

  标记点$l^{(i)}$的特征函数$f_i$：
  $$
  f_i = similarity(x,l^{(i)})=exp(-\frac{||x-l^{(i)}||^2}{2\sigma^2})=exp(-\frac{\sum_{j=1}^{n}(x_j-l_j^{(i)})^2}{2\sigma^2})
  $$
  对于新特征$f_i$，只要给定$\theta$就能得出$\theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3 + \cdots$大于或小于0，从而形成了决策边界。对于$\theta$如何得出，依赖于支持向量机。

#### 支持向量机

对于**支持向量机**假设函数的形式如下：
$$
\begin{eqnarray*}
h_\theta(x) = 1 & & if \ \theta^Tx \geq 0 \\
h_\theta(x) = 0 & & if \ \theta^Tx <0
\end{eqnarray*}
$$
在使用SVM学习算法的时候，具体来说就是求解这个最小化问题：
$$
min_\theta\ C\sum_{i=1}^{m}[y^{(i)}cost_1(\theta^Tx^{(i)}) + (1-y^{(i)})cost_0((\theta^Tx^{(i)})] + \frac{1}{2}\sum_{j=1}^{n}\theta_j^2
$$
当输入一个正样本$y^{(i)}=1$时，对于代价函数$cost_1(z)=0$需要使得当$\theta^Tx^{(i)} \geq 1$；对于一个负训练样本$y^{(i)}=0$时，对于代价函数$cost_0(z)=0$需要使得$\theta^Tx^{(i)} \leq -1$。最终只有$min\frac{1}{2}\sum_{j=1}^{n}\theta_j^2$，这样就会得到了一个非常有趣的决策边界。

![SVM决策边界2](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/SVM%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8C2.jpeg)

$\theta^Tx^{(i)} = p^{(i)} \cdot ||\theta||$，同时需要$p^{(i)} \cdot ||\theta|| \geq 1$或$p^{(i)} \cdot ||\theta|| \leq -1$，要想$\theta$的范数$||\theta|| $最小，就得样本$x^{(i)}$在$\theta$上的投影$p^{(i)}$的长度变大。这就是**为什么支持向量机可以产生大间距分类的原因**。

通过解决这个最小化问题，就能得到支持向量机的参数$\theta$。

#### SVM中的参数

1. 在使用支持向量机时，关于选择支持向量机中的参数$C=\frac{1}{\lambda}$，$C$对应着之前逻辑回归的的$\lambda$:
   - 较小的$\lambda$对应较大的$C$，这就意味着有可能得到一个低偏差但高方差的模型。
   - 较大的$\lambda$对应较小的$C$，这就意味着有可能得到一个高偏差但低方差的模型。
2. $\sigma^2$参数
   - <mark>**如果$\sigma^2$越小**，那么高斯核函数会变化的**很剧烈**，在这种情况下，最终得到的模型会是**低偏差和高方差**</mark>。
   - <mark>**如果$\sigma^2$越大**，那么高斯核函数倾向于变得**越平滑**，由于函数平滑且变化的比较平缓，这会给模型带来**较高的偏差和较低的方差**</mark>。

神经网络
---

如果一个神经网络在第$j$层有$S_j$个单元，在第$j+1$层有$S_{j+1}$个单元，那么<mark>第$j$层的权重$\Theta^{(j)}$的维度是：$S_{j+1} × (S_j+1)$</mark>。

### 向前传播

总结来说$h(x)$是经由第一层的$x_1$、$x_2$、$x_3$做$\theta X$运算，再做$g(z)$运算，又经过$\theta X$运算和$g(z)$运算来得到的

对于神经网络的代价函数是这个式子的一般化形式：
$$
J(\Theta)=-\frac{1}{m}\sum_{k=1}^K\sum_{i=1}^m[y_k^{(i)}\log((h_\Theta(x^{(i)}))_k) + (1-y_k^{(i)})\log(1-(h_\Theta(x^{(i)}))_k)]+ \frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{S_l}\sum_{j=1}^{S_{l+1}}{(\Theta_{j,i}^{(l)})^2}
$$
理解代价函数：非正则情形下，是对每种$K$值求其对应的逻辑回归的代价函数；正则化是( $\frac{\lambda}{2m} · 所有非偏置单元的平方$)

### 反向传播

反向传播算法的作用是用来求代价函数最小化，最终的目标是计算$min_\Theta J(\Theta)$，要想最小化$J(\Theta)$需要使用$\frac{d}{d\Theta_{j,i}^{(l)}}J(\Theta) $。$\delta_j^{(l)}$记作第$l$层第$j$个节点的误差：

输出层每一项的误差(layer L = 4)：$\delta_j^{(4)} = h_\Theta(x)_j - y_j$

隐藏层每一项的误差：$ \delta_j^{(3)} = (\Theta^{(3)})\delta_j^{(4)} \cdot \times g'(z^{(3)}) $，其中$ g'(z^{(3)}) = a^{(3)} \cdot  \times(1 - a^{(3)}) $：

需要注意这里<mark>没有$δ^{(1)}$项</mark>，因为第一层是输入层，不存在误差。

如果忽略标准化所产生的项，可以证明想要的偏导项，恰好就是下面这个表达式：
$$
\frac{d}{d\Theta_{j,i}^{(l)}}J(\Theta)  = a_j^{(l)}\delta_i^{(l+1)}
$$
所以到现在，可以通过反向传播计算这些$\delta$项，可以非常快速的计算出所有参数的偏导数项。

#### 具体实现反向传播算法

首先设置$\Delta_{ij}^{(l)} = 0 (for　all　l,i,j)$，$\Delta_{ij}^{(l)}$最终被用来计算$\frac{d}{d\Theta_{j,i}^{(l)}}J(\Theta) $，$\Delta_{ij}^{(l)}$最终是m个样本累加出来的

For  i = 1 to m

1. 取每个样本$x^{(i)}$，令$a^{(1)} = x^{(i)}$
2. 依次计算出$l=2,3,\ldots,L$的$z^{(l)}$和$a^{(l)}$
3. 用$y^{(i)}$计算$\delta^{(L)} = h_\Theta(x) - y^{(i)}$，这里注意<mark>需要分别计算$y$变成对应$k$值为1的形式 [0,0,1,0,0]</mark>
4. 依次计算$\delta^{(L-1)},\delta^{(L-2)},\ldots,\delta^{(2)}$
5. $\Delta_{ij}^{(l)} := \Delta_{ij}^{(l)} + a_j^{(l)}\delta_i^{(l+1)}$，即$\Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)}(a^{(l)})^T$

end

正则化之后$D_{ij}^{(l)}$的表示：
$$
\begin{eqnarray*}
D_{ij}^{(l)} := \frac{1}{m}\Delta_{ij}^{(l)} + \frac{\lambda}{m}\Theta_{ij}^{(l)} &　&  (j \neq 0)  \\
D_{ij}^{(l)} := \frac{1}{m}\Delta_{ij}^{(l)} &　&  (j = 0) 
\end{eqnarray*}
$$

### 梯度检验

渐变检查将确保我们的反向传播按预期工作。可以用下式近似我们的成本函数的导数：
$$
\frac{d}{d\Theta} \approx \frac{J(\Theta + \varepsilon) - J(\Theta - \varepsilon)}{2\varepsilon}
$$
对于多个矩阵theta，可以近似的求导数相对于$\Theta_j$如下
$$
\frac{d}{d\Theta_j} \approx \frac{J(\Theta_1,\ldots,\Theta_j + \varepsilon,\ldots,\Theta_n) - J(\Theta_1,\ldots,\Theta_j - \varepsilon,\ldots,\Theta_n)}{2\varepsilon}
$$
通常给$\varepsilon$取很小的值，比如可能取$\varepsilon=10^{-4}$，$\varepsilon$的取值在一个很大的范围内都是可行的，实际上，如果你让$\varepsilon$非常小，那么数学上上面的式子实际上就是导数。只是不用想非常非常小的$\varepsilon$，因为可能会产生数值问题，所以我通常让$\varepsilon=10^{-4}$就行。

### 随机初始化$\Theta$

在逻辑回归时，初始化所有变量为0是可行的，但在训练神经网络时，这样做是不可行的。

![神经网络theta初始化](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Ctheta%E5%88%9D%E5%A7%8B%E5%8C%96.png)

当初始化面这些颜色两两相同的权重时，这些权重都被赋予相同的初始值0，意味着经过计算后，这两个隐藏单元$a_1$，$a_2$的值是相同的。为了解决这个神经网络变量初始化的问题，采用**随机初始化**的方法。需要做的是对$\Theta_{ij}^{(l)}$的每个值进行初始化，$2\epsilon \cdot rand(\theta)  - \epsilon$ 使$\Theta_{ij}^{(l)}$范围在$[−ε,ε]$之间。

### 训练神经网络步骤

主要分为6个步骤：

1. 构建一个神经网络并且随机初始化$\Theta$（**Randomly initialize Weight**）。

2. 执行向前传播算法，也就是对于神经网络的任意一个输入$x^{(i)}$计算出对应的$h_\Theta(x^{(i)})$。

3. 通过代码计算出代价函数$J(\Theta)$。

4. 执行反向传播算法(**Backprop**)来算出这些偏导数：$\frac{d}{d\Theta_{j,i}^{(l)}}J(\Theta) $。

5. 使用梯度检查来校验结果。用梯度检查来比较这些已经用反向传播算法得到的偏导数值$\frac{d}{d\Theta_{j,i}^{(l)}}J(\Theta) $与用数值方法得到的估计值进行比较，来检查确保这两种方法得到值是基本相近的。

   通过梯度检查，我们能确保我们的反向传播算法得到的结果是正确的，但必须要说明的一点是，<mark>检查结束后需要去掉梯度检查的代码，因为梯度检查计算非常慢</mark>。

6. 使用一个最优化算法（比如说梯度下降算法或者其他更加高级的优化方法，比如说BFGS算法，共轭梯度法，或者其他一些已经内置到`fminunc`函数中的方法），将所有这些优化方法和反向传播算法相结合，这样我们就能计算出这些偏导数项的值$\frac{d}{d\Theta_{j,i}^{(l)}}J(\Theta) $。

降维(dimensionality reduction)
---

用于数据压缩，加快学习算法，以及可视化的复杂数据集。

### 主成分分析PCA

PCA所做的就是**寻找一个低维的面使数据投射在上面，使得到达低维面的距离的平方和达到最小值**。数据到低维面的距离叫做**投影误差**。所以**PCA**所做的就是寻找一个投影平面，对数据进行投影，使得这个能够最小化。

#### PCA算法实现

- 数据预处理

  如果数据跨度比较大，需要<mark>进行均值归一化处理</mark>。

- 算法实现

  1. 想要把数据从$n$维降低到$k$维，首先要做的是计算出下面这个协方差矩阵(通常用$\sum$来表示)：
     $$
     \sum = \frac{1}{m}\sum_{i=1}^{n}(x^{(i)})(x^{(i)})^T
     $$
     计算出这个协方差矩阵后，假如把它存为Octave中的一个名为`Sigma`的变量，需要做的是计算出`Sigma`矩阵的**特征向量(eigenvectors)**。

     在Octave中，可以使用如下命令来实现这一功能：

     ```
     [U,S,V] = svd(Sigma);
     ```

     svd将输出三个矩阵，真正需要的是$U$矩阵。$U$矩阵也是一个$n×n$矩阵：
     $$
     U = 
     \begin{bmatrix}
        | & | & | & \cdots & |  \\
        u^{(1)} & u^{(2)} & u^{(3)} & \cdots & u^{(n)}  \\
        | & | & | & \cdots & | 
     \end{bmatrix}
     \in R^{n×n}
     $$

  2. 如果想将数据的维度从$n$降低到$k$的话，只需要提取前$k$列向量。这样就得到了$u^{(1)}$到$u^{(k)}$，也就是用来投影数据的$k$个方向，组成的$n×k$的矩阵$U_{reduce}$：
     $$
     U_{reduce} = 
     \begin{bmatrix}
        | & | & | & \cdots & |  \\
        u^{(1)} & u^{(2)} & u^{(3)} & \cdots & u^{(k)}  \\
        | & | & | & \cdots & | 
     \end{bmatrix}
     \in R^{n×k}
     $$

     ```
     Ureduce = U(:,1:k);
     ```

  3. 然后使用$U_{reduce}$来对数据降维：
     $$
     z = 
     \begin{bmatrix}
        | & | & | & \cdots & |  \\
        u^{(1)} & u^{(2)} & u^{(3)} & \cdots & u^{(k)}  \\
        | & | & | & \cdots & | 
     \end{bmatrix}^Tx
     = 
     \begin{bmatrix}
        - & u^{(1)} & -  \\
        - & u^{(2)} & -  \\
        - & u^{(3)} & -  \\
       \vdots & \vdots & \vdots \\
        - & u^{(k)} & - 
     \end{bmatrix}x
     $$

     ```
     z = Ureduce'*x;
     ```

     $z$是$k×1$的矩阵，这里的$x$可以是训练集中的样本，也可以是交叉验证集中的样本，也可以是测试集样本。

#### 选则主成分的数量$k$

$k$是PCA算法的一个参数，称作主成分数量。调用`svd`来计算PCA时，会得到三个矩阵`[U,S,V]`，除了之前提到的`U`矩阵之外，`S`矩阵是一个$n×n$的对角矩阵，它只有在对角线上的元素不为0，其余的元素都是0:
$$
S = 
\begin{bmatrix}
 S_{11}   & 0      & \cdots & 0      \\
 0  & S_{22}      & \cdots & 0     \\
 \vdots & \vdots & \ddots & \vdots \\
 0  & 0      & \cdots & S_{nn}      \\
\end{bmatrix}
$$
可以通过这个$S$矩阵方便的计算出差异性那一项的值：
$$
\frac{\frac{1}{m}\sum_{i=1}^m||x^{(i)}-x_{approx}^{(i)}||^2}{\frac{1}{m}\sum_{i=1}^m||x^{(i)}||^2} = 1 - \frac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}}\leq 0.01
$$
即：
$$
\frac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}}\geq 0.99
$$
可以从1开始，慢慢增大$k$的值，来计算上面这个不等式，直到满足为止即可。通过这种方式，只需要调用一次svd函数，通过`svd`给出的`S`矩阵就可以通过依次增加$k$值的方式来求解了。$\frac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}}$会告诉你百分之多少的差异性被保留了下来，这就是一个**平方投影误差的测量指标**。

### 对压缩数据还原

根据$z=U_{reduce}^Tx$，如果想得到相反的情形，方程应这样变化:
$$
x_{approx}=U_{reduce}z
$$
同时根据PCA的意图，投影的平方误差不能很大。也就是说$x_{approx}$将会与最开始用来导出$z$的原始$x$很接近。用低维度的特征数据$z$还原到未被压缩的特征数据的过程，找到一个与原始数据$x$近似的$x_{approx}$ ，称这一过程为**原始数据的重构(reconstruction)**。

### 关于PCA使用总结

<mark>为了解决过拟合问题而使用PCA是不适合的</mark>！如果担心过拟合问题，应该使用正则化方法，而不是使用PCA来对数据进行降维。

<mark>**一开始不要将PCA方法就直接放到算法里**</mark>，先使用原始数据$x^{(i)}$看看效果。只有一个原因让我们相信算法出现了问题，<mark>那就是学习算法收敛地非常缓慢，占用内存或者硬盘空间非常大，所以想压缩数据。只有当$x^{(i)}$效果不好的时候，那么就考虑用PCA来进行压缩数据</mark>。

无监督学习
---

### K-Means算法

K均值是一个迭代方法，它要做两件事情：

- 第一是**簇分配**(cluster assignment)
- 第二个是**移动聚类中心**(move cluster centroids)

K均值算法接受两个输入：

1. 参数$K$，表示想从数据中聚类出的簇的个数
2. 第二个输入参数是训练集$\{x^{(1)},x^{(2)},\ldots,x^{(m)}\}$

#### 簇数量$K$选择

选择聚类的数目可能不总是那么容易，大部分情况下，对于数据集中有多少个聚类中心通常是模棱两可的。这就是无监督学习的一部分。没有给我们标签，所以不会总有一个清晰的答案。这就是为什么，做一个能够自动选择聚类数目的算法，是非常困难的原因之一。

- 肘部法则(Elbow Method)

  <img src="http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E8%82%98%E9%83%A8%E6%B3%95%E5%88%99.png" width="400px"/>

- 下游决定

  由需求决定多少个分类更有意义，能更好的满足需求。

#### K-Means算法步骤

$\mu_{c^{(i)}}$表示$x^{(i)}$所属的簇的聚类中心，关于K-Means的代价函数表示为：
$$
J(c^{(1)},\ldots,c^{(m)},\mu_1,\ldots,u_K) = \frac{1}{m}\sum_{i=1}^{m}||x^{(i)} - u_{c^{(i)}}||^2
$$
代价函数要做的就是找到使$J$最小的$c^{(i)}$和$\mu_i$，在K-Means算法中，也叫失真代价函数(distortion cost function)。

1. 随机初始化$K$个**聚类中心**，记作$\mu_1,\mu_2$一直到$\mu_K$。

   为了避免局部最优的问题，需要**初始化K均值很多次，并运行K-Means方法很多次，通过多次尝试来<mark>选取$J$最小的情况</mark>，从而保证最终能得到一个足够好的结果。一个尽可能局部或全局最优的结果。**

2. 内部循环执行以下步骤：

   - 簇分配

     首先对于每个训练样本，用变量$c^{(i)}$表示$K$个聚类中心中最接近$x^{(i)}$的那个中心的下标，这就是簇分配。
     $$
     c^{(i)} = min_k = ||x^{(i)} - \mu_k||
     $$
     <mark>相当于给样本分别打上1~$k$的标记</mark>。

   - 移动聚类中心

     对于每个聚类中心：$k$从1循环到$K$，将$μ_k$赋值为这个簇的均值，之后重新开始簇分配。

异常检测
---

在遇到具体情况时，要<mark>选择异常检查还是监督学习的方式。其实关键区别就是**在异常检测算法中只有一小撮正样本**</mark>，因此监督学习算法不能从这些样本中学到太多东西。

### 异常检查算法

1. 从样本中选择一些能体现出**异常行为的特征**$x_i$。

2. 分别计算出每个特征的参数$\mu_1,\ldots,\mu_n,\sigma_1^2,\ldots,\sigma_n^2$。
   $$
   \begin{split}
   \mu_j  & = & \frac{1}{m}\sum_{i=1}^{m}x_j^{(i)} \\
   \sigma_j^2 & = & \frac{1}{m}\sum_{i=1}^{m}(x_j^{(i)} - \mu_j)^2
   \end{split}
   $$

   ```matlab
   mu = mean(X);

   % 将均值复制多行
   % mus = mu(ones(m,1),:);
   mus = repmat(mu,m,1);

   sigma2 = mean((X - mus) .* (X - mus));
   ```

3. 给定一个新的样本$x$，计算出它对应的$p(x)$:
   $$
   p(x)=\prod_{j=1}^np(x_j;\mu_j,\sigma_j^2) = \prod_{j=1}^n\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})
   $$

   ```matlab
   function p = multivariateGaussian(X, mu, Sigma2)

   k = length(mu);

   if (size(Sigma2, 2) == 1) || (size(Sigma2, 1) == 1)
       Sigma2 = diag(Sigma2);
   end

   X = bsxfun(@minus, X, mu(:)');
   p = (2 * pi) ^ (- k / 2) * det(Sigma2) ^ (-0.5) * ...
       exp(-0.5 * sum(bsxfun(@times, X * pinv(Sigma2), X), 2));

   end
   ```

通过判断$p(x) < \epsilon$，来判断是否有异常发生。

### 异常检测系统构建

我们要考虑的异常检测问题是一个非监督问题，使用的是无标签数据。但如果有一些带标签的数据，能够指明哪些是异常样本，哪些是非异常样本，这就是要找的能够评价异常检测算法的标准方法。

#### 数据集划分

1. 对于训练集，还是需要把数据看成是无标签的，通常来讲这些样本都是**正常**的，但可能有一些异常的也被分到训练集里，这也没关系（毕竟异常的是少数）

   总样本3/5的这些样本都对应$y=0$的情况，通过用这些训练样本来拟合$p(x)=\prod_{j=1}^np(x_j;\mu_j,\sigma_j^2) $，以此来计算参数$\mu_1,\ldots,\mu_n,\sigma_1^2,\ldots,\sigma_n^2$。

2. 接下来我们要定义交叉验证集和测试集。通过这两个集合我们将得到异常检测算法。

   将剩余2/5的样本一半放入**交叉验证集**，另一半放入**测试集**中。同时将有异常的样本，同样也把它们进行一个分割：一半异常样本放到验证集中，剩下一半异常样本放入测试集中。

#### 异常算法的评估

预设一个比较小的$\epsilon$，对于$p(x) \lt \epsilon$的样本视为异常样本，然后分别在测试集合和交叉验证集上进行测试和验证。我们知道在测试集合交叉验证集上是存在$y=1$的异常样本的，只不过量比较少而已。

这与监督学习有些类似，在对有标签的数据进行预测。所以可以通过**对标签预测正确的次数来评价算法的好坏**。

当然这些标签会比较偏斜，因为$y=0$(也就是正常的样本)肯定是比出现$y=1$(也就是异常样本)的情况更多，那么总是预测$y=0$它的分类准确度自然会很高。因此我们应该算出以下数据来更科学的衡量算法的好坏：

- 应该算出**真阳性**、**假阳性**、**假阴性**和**真阴性**的比率来作为评价度量值

  ```matlab
  cvPredictions = double(pval < epsilon);

  % 真阳性
  tp = sum((cvPredictions == 1) & (yval == 1)); % 预测值和真实值都为1
  % 假阳性
  fp = sum((cvPredictions == 1) & (yval == 0)); % 预测值为1，真实值为0
  % 假阴性
  fn = sum((cvPredictions == 0) & (yval == 1)); % 预测值为0，真实值为1
  ```

- 也可以算出**查准率**和**召回率**

  ```matlab
  % 查准率
  prec = tp / (tp + fp);
  % 召回率
  rec = tp / (tp + fn);
  ```

- 计算出$F1−score$，通过一个很简单的数字来总结出查准和召回的大小。

  ```matlab
  % F1Score
  F1 = (2 * prec * rec) / (prec + rec);

  % 最终取使F1Score最大的epsilon
  ```

通过这些方法，就可以评价异常检测算法在交叉验证和测试集样本中的表现。

### 特征选取

事实上应用异常检测时，对它的效率影响最大的因素之一，是使用什么特征变量。

- 特征变量获取

  对应异常样本，在指定特征$x_1$下的$p(x_1)$并不低，我们无法从这一特征下区分出这一异常样本，需要引入另一特征$x_2$。

  选择异常检测需要考虑的特征时，先找出异常样本，然后尝试通过引入新的特征来验证对异常样本的识别的准确性。如果有所提高，就可以考虑引入这个特征。

  其实，解决这类问题的思路就是尝试组合新的特征，从而能更好的检测异常情况。

- 对不服从高斯分布的数据进行转换

  在异常检测算法中，做的事情之一就是使用正态(高斯)分布来对特征向量建模。通常情况下，都需要用直方图来可视化这些数据，这么做的原因是为了在使用算法之前，确保数据看起来是服从高斯分布的（当然即使数据并不是高斯分布，它也基本上可以良好地运行，但最好转换成高斯分布的样式之后在带入计算）。

  对于一个不服从高斯分布的数据进行转换的过程：

|                   原始数据                   |                $x^{0.5}$                 |                $x^{0.2}$                 |                $x^{0.1}$                 |                $x^{0.05}$                |                $\log(x)$                 |
| :--------------------------------------: | :--------------------------------------: | :--------------------------------------: | :--------------------------------------: | :--------------------------------------: | :--------------------------------------: |
| ![](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%831.png) | ![数据调整为高斯分布2](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%832.png) | ![数据调整为高斯分布3](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%833.png) | ![数据调整为高斯分布4](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%834.png) | ![数据调整为高斯分布5](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%835.png) | ![数据调整为高斯分布6](http://gtw.oss-cn-shanghai.aliyuncs.com/machine-learning/Stanford/%E6%95%B0%E6%8D%AE%E8%B0%83%E6%95%B4%E4%B8%BA%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%836.png) |
|              ` hist(x,50)`               |            `hist(x.^0.5,50)`             |            `hist(x.^0.2,50)`             |            `hist(x.^0.1,50)`             |            `hist(x.^0.05,50)`            |            `hist(log(x),50)`             |

推荐系统
---

在实际情况中，我们并不知道每个产品具体的特征值是多少，我们可以着眼于用户，看看任意用户$j$对应的不同产品的喜欢程度$\theta^{(j)}$。有了这些参数值，理论上就能推测出每个产品的特征变量$x_1$和$x_2$的值。

在已知给定参数$\theta^{(1)},\dots,\theta^{(n_u)}$的情况下，对下面函数最小化，得到特征值$x^{(i)}$：
$$
min_{x^{(i)}} \frac{1}{2}\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2 + \frac{\lambda}{2}\sum_{k=1}^{n}{(x_k^{(i)})^2}
$$
计算所有的特征，我们通过最小化下面的函数可以得到：
$$
min_{x^{(1)},\dots,x^{(n_m)}}  \frac{1}{2}\sum_{i=1}^{n_m}\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2 + \frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}{(x_k^{(i)})^2}
$$
类似**先有鸡还是先有蛋**的问题。知道了$x$就能预测出$\theta$，反之，如果知道了$\theta$，就能预测出$x$。一直重复上述的计算过程，算法将会收敛到一组合理的特征值$x$，以及一组合理的对不同用户参数的估计值$\theta$。这就是基本的**协同过滤算法**，但这实际上不是我们最终使用的算法。

### 协同过滤(collaborative filtering)

有一个更有效率的算法，不必再这样不停地来回计算，而是能同时把$x$和$\theta$同时计算出来。要做的就是把上面两个式子合而为一：同时最小化$x^{(1)},\dots,x^{(n_m)}$和$\theta^{(1)},\dots,\theta^{(n_u)}$：
$$
J(x^{(1)},\dots,x^{(n_m)},\theta^{(1)},\dots,\theta^{(n_u)})=\frac{1}{2}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2 +\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}{(x_k^{(i)})^2} + \frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}
$$

#### 注意点

不需要不断地在$x$和$\theta$这两个参数之间不停折腾，所要做的是将这两组参数同时化简。

以这样的方法学习特征量时，<mark>必须要保证去掉$x_0$项，这样来保证学习到的特征量$x$是$n$维的</mark>，而不是$n+1$维的。

同样地，因为参数$\theta$与特征向量$x$是在同一个维度上，所以$\theta$也是$n$维的。因为如果没有$x_0$，那么$\theta_0$也不再需要。

#### 协同过滤算法的正式描述

1. 首先用较小的初始值来随机初始化参数$x^{(1)},\dots,x^{(n_m)}$和$\theta^{(1)},\dots,\theta^{(n_u)}$

2. 通过使用梯度下降算法（或者其他更高级的优化算法）来最小化代价函数$J(x^{(1)},\dots,x^{(n_m)},\theta^{(1)},\dots,\theta^{(n_u)})$。

   循环每一个$j=1,\dots,n_u;i=1,\dots,n_m$来执行对应的梯度下降：
   $$
   \begin{split}
   x_k^{(i)} &:=& x_k^{(i)} - \alpha \left ( \sum_{j:r(i,j)=1}((\theta^{(j)})^T-y^{(i,j)})^2\theta_k^{(j)} + \lambda x_k^{(i)} \right ) \\
   \theta_k^{(j)} &:=& \theta_k^{(j)} - \alpha \left ( \sum_{i:r(i,j)=1}((\theta^{(j)})^T-y^{(i,j)})^2x_k^{(i)} + \lambda\theta_k^{(j)} \right )
   \end{split}
   $$
   <mark>在这个公式中，不再用到$x_0=1$这一项，在做正则化的时候，也是对这$n$维的参数进行正则化，并不包括$x_0$和$\theta_0$</mark>。

3. 最终，通过用户对应的参数向量$\theta$和训练得出的特征向量$x$，来预测用户给出的评分$\theta^Tx$。

大数据处理
---

| 对比         | 批量梯度下降                                   | 随机梯度下降                                   | 小批量梯度下降                                  |
| ---------- | ---------------------------------------- | ---------------------------------------- | ---------------------------------------- |
| 梯度下降Repeat | $\theta_j := \theta_j - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$ | $\theta_j := \theta_j - \alpha(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$ | $\theta_j := \theta_j - \alpha\frac{1}{10}\sum_{k=1}^{i+9}(h_\theta(x^{(k)}) - y^{(k)})x_j^{(k)}$ |
| 描述         | 1.每次遍历是针对所有样本（需要加合所有样本，对所有数据扫描）<br />2.指定遍历次数，通常很大 | 1.每次循环针对一个样本，遍历整个样本<br />2.由于m非常大，外层循环通常一次就好，最多10次，具体取决于样本大小 | 每次迭代使用b个样本，b的标准取值是2~100之间的一个数            |

<mark>随机梯度下降最终会在靠近全局最小值的区域内徘徊，而不是直接逼近全局最小值并停留在那里</mark>。

小批量梯度下降算法**和**随机梯度下降算法**相比优势在于**向量化**。批量处理的数据可以用一种更向量化的方法来实现，允许部分并行计算10个样本的和，而**随机梯度下降算法**每次只去计算一个样本，没有太多的并行计算。

### 学习速率$\alpha$选则

- <mark>更小的学习速率，最终的振荡就会更小</mark>，有时候这一点小的区别可以忽略
- 把cost样本数从1000提高到5000组样本，<mark>样本数目提高可能会得到一条更平滑的曲线</mark>；当然增大它的缺点就是获取结果延迟。
- 如果出现下图蓝线这种情况，可能代价函数没有在减小。也有可能实际上代价函数是在下降的只不过蓝线用来平均的样本数量太小了，并且蓝线太嘈杂看不出来代价函数的趋势确实是下降的。所以可以用5000组样本来平均比用1000组样本来平均更能看出趋势。

### 在线学习

与以往的学习过程不同的是，在线学习中，<mark>每次梯度下降使用当前样本数据$(x,y)$来更新$\theta$，使用一次之后就丢弃了</mark>，之后永远都不会再次使用它。
$$
\theta_j := \theta_j - \alpha(h_\theta(x) - y)x_j \ \ \  (j = 0,\dots,n)
$$
因为数据本质上是自由的，而且数据本质上是无限的，那么或许就真的没必要重复处理一个样本。

上限分析
---

**在开发机器学习系统时，最宝贵的资源就是时间**，**上限分析(ceiling analysis)**这种方式通常能提供一种很有价值的信号，告诉你流水线中的哪个部分最值得你花时间。

### 主要思想

假设整个系统的估计准确率为72%（对测试集上的图像分别运行流水线上的每一个模块操作之后，整个测试集的准确率是72%）

1. 首先，模拟在**文字检测**准确率100%的情况下，得出当前系统的准确率。（可以通过人工的方式找出这种样本）
2. 然后以同样的方式，得出在**文字检测**，以及**字符切分**准确率100%的情况下，当前系统的准确率。
3. 我们也要写出在**文字检测**、**字符切分**以及**字符识别**准确率100%的情况下，当前系统的准确率（当然是100%）。

| 模块       | 准确率      |
| -------- | -------- |
| 整个系统     | 72%      |
| 文字检测     | 89%      |
| 字符切分     | 90%      |
| **字符识别** | **100%** |

有了这些数据，我们就知道了每一个模块进行改善它们各自的上升空间是多大。

可以看到，如果我们拥有完美的文字检测模块，那么整个系统的表现将会从准确率72%上升到89%，因此效果的增益是17%。这就意味着，如果在现有系统的基础上花费时间和精力改善文字检测模块的效果，那么系统的表现可能会提高17%。

而相对来讲，如果取得完美的字符分割模块，那么最终系统表现只提升了1%。这给我们提供了一个很重要的信息，那就是不管我们投入多大精力在字符分割上，系统效果的潜在上升空间也都是很小很小。所以就不会让一个比较大的工程师团队花时间忙于字符分割模块，因为通过上限分析我们知道了即使把字符分割模块做得再好，再怎么完美，系统表现最多也只能提升1%。

最后，如果取得完美的字符识别模块，那么整个系统的表现将提高10%。所以，同样你可以分析10%的效果提升值得投入多少工作量。