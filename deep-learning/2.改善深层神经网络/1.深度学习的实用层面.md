[TOC]

## 深度学习的实用层面

将学习如何有效运作神经网络，内容涉及**超参数调优**，**如何构建数据**，以及如何确保优化**算法快速运行**，从而使学习算法在合理时间内完成自我学习。

### 1. 训练，验证，测试集（Train / Dev / Test sets）

在配置训练集、验证集和测试数据集的过程中做出正确决策会在很大程度上帮助大家创建高效的神经网络。训练神经网络时，我们需要做出很多决策，例如：

1. 神经网络分多少层
2. 每层含有多少个隐藏单元
3. 学习速率是多少
4. 各层采用哪些激活函数

创建新应用的过程中，不可能从一开始就准确预测出这些信息和其他超参数。实际上，**应用型机器学习是一个高度迭代的过程**，通常在项目启动时，会先有一个初步想法，比如构建一个含有特定层数，隐藏单元数量或数据集个数等等的神经网络，然后编码，并尝试运行这些代码，通过运行和测试得到该神经网络或这些配置信息的运行结果。可能会根据输出结果重新完善自己的想法，改变策略，或者为了找到更好的神经网络不断迭代更新自己的方案。

创建高质量的训练数据集，验证集和测试集也有助于提高循环效率。

在机器学习发展的小数据量时代，常见做法是将所有数据三七分，就是人们常说的70%验证集，30%测试集，如果没有明确设置验证集，也可以按照60%训练，20%验证和20%测试集来划分。如果只有1万条数据，那么上述比例划分是非常合理的。

但是在大数据时代，现在的==数据量可能是百万级别，那么验证集和测试集占数据总量的比例会趋向于变得更小==。因为验证集的目的就是验证不同的算法，检验哪种算法更有效。因此，需要验证集足够大才能评估，比如我们有100万条数据，那么取1万条数据便足以进行评估，所以不需要拿出20%的数据作为验证集。

假设有100万条数据，其中1万条作为验证集，1万条作为测试集，100万里取1万，比例是1%，即：训练集占98%，验证集和测试集各占1%。对于数据量过百万的应用，训练集可以占到99.5%，验证和测试集各占0.25%，或者验证集占0.4%，测试集占0.1%。

总结一下，在机器学习中，通常将样本分成训练集，验证集和测试集三部分，数据集规模相对较小，适用传统的划分比例，数据集规模较大的，验证集和测试集要小于数据总量的20%或10%。

由于深度学习算法需要大量的训练数据，为了获取更大规模的训练数据集，我们可以采用当前流行的各种创意策略，例如，网页抓取，代价就是训练集数据与验证集和测试集数据有可能不是来自同一分布。针对这种情况，==**要确保验证集和测试集的数据来自同一分布**==。因为要用验证集来评估不同的模型，尽可能地优化性能，所以验证集和测试集来自同一个分布就会很好。

最后一点，就算没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做出无偏差估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试集，要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估。

所以说，搭建训练验证集和测试集能够加速神经网络的集成，也可以更有效地衡量算法地偏差和方差，从而帮助我们更高效地选择合适方法来优化算法。

### 2. 偏差，方差（Bias /Variance）

深度学习的误差很少权衡二者，总是分别考虑偏差和方差，却很少谈及偏差和方差的权衡问题。

![方差偏差](http://www.ai-start.com/dl2017/images/05ac08b96177b5d0aaae7b7bfea64f3a.png)

- 假设有如上图的数据集，如果给这个数据集拟合一条直线，可能得到一个逻辑回归拟合，但它并不能很好地拟合该数据，这是高偏差（**high bias**）的情况，称为“欠拟合”（**underfitting**）。
- 相反的如果拟合一个非常复杂的分类器，比如深度神经网络或含有隐藏单元的神经网络，可能就非常适用于这个数据集，但是这看起来也不是一种很好的拟合方式分类器方差较高（**high variance**），数据过度拟合（**overfitting**）。
- 在两者之间，可能还有一些像图中这样的，复杂程度适中，数据拟合适度的分类器，这个数据拟合看起来更加合理，称之为“适度拟合”（**just right**）是介于过度拟合和欠拟合中间的一类。

在这样一个只有和两个特征的二维数据集中，可以绘制数据，将偏差和方差可视化。在多维空间数据中，绘制数据和可视化分割边界无法实现，但可以通过几个指标，来研究偏差和方差。理解偏差和方差的两个关键数据是**训练集误差**（**Train set error**）和**验证集误差**（**Dev set error**）：

- 假定训练集误差是1%，为了方便论证，假定验证集误差是11%，可以看出训练集设置得非常好，而验证集设置相对较差，我们可能过度拟合了训练集，在某种程度上，验证集并没有充分利用交叉验证集的作用，像这种情况，我们称之为“高方差”。（**==高方差：可以很好拟合训练集，无法很好地拟合验证集==**）
- 假设训练集误差是15%，验证集误差是16%，假设案例中人的错误率几乎为0%。算法并没有在训练集中得到很好训练，如果训练数据的拟合度不高，就是数据欠拟合，就可以说这种算法偏差比较高。相反，它对于验证集产生的结果却是合理的，验证集中的错误率只比训练集的多了1%，所以这种算法偏差高，因为它甚至不能拟合训练集。（**==高偏差：训练集和验证集都无法很好拟合==**）

这些分析都是基于假设预测的，假设人的错误率接近0%，一般来说，最优误差也被称为贝叶斯误差，所以，最优误差接近0%。如果最优误差或贝叶斯误差非常高，比如15%。再看这个分类器（训练误差15%，验证误差16%），15%的错误率对训练集来说也是非常合理的，偏差不高，方差也非常低。

当所有分类器都不适用时，如何分析偏差和方差呢？比如，图片很模糊，即使是人眼，或者没有系统可以准确无误地识别图片。在这种情况下，最优误差会更高，那么分析过程就要做些改变了，通过查看训练集误差，可以判断数据拟合情况，至少对于训练数据是这样，可以判断是否有偏差问题，然后查看错误率有多高。当完成训练集训练，开始使用验证集验证时，可以判断方差是否过高。

### 3. 机器学习基础（Basic Recipe for Machine Learning）

初始模型训练完成后，首先要知道算法的偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，那么要做的就是选择一个新的网络。比如含有更多隐藏层或者隐藏单元的网络，或者花费更多时间来训练网络，或者尝试更先进的优化算法。也可以尝试其他方法，可能有用，也可能没用。不过采用规模更大的网络通常都会有所帮助，延长训练时间不一定有用，但也没什么坏处。

**训练学习算法时，会不断尝试这些方法，直到解决掉偏差问题，这是最低标准，反复尝试直到可以拟合数据为止，至少能够拟合训练集**。

如果网络足够大，通常可以很好的拟合训练集，只要能扩大网络规模，至少可以拟合或者过拟合训练集。一旦偏差降低到可以接受的数值，检查一下方差有没有问题。为了评估方差，我们要查看验证集性能，我们能从一个性能理想的训练集推断出验证集的性能是否也理想，**如果方差高，最好的解决办法就是采用更多数据**，如果你能做到，会有一定的帮助。但有时候，无法获得更多数据，**也可以尝试通过正则化来减少过拟合**，有时候不得不反复尝试。但是，如果能找到更合适的神经网络框架，有时它可能会一箭双雕，同时减少方差和偏差。如何实现呢？想系统地说出做法很难，总之就是不断重复尝试，直到找到一个低偏差，低方差的框架，这时你就成功了。

有两点需要注意：

1. 高偏差和高方差是两种不同的情况，后续要尝试的方法也可能完全不同，通常会用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。

   举个例子，如果算法存在高偏差问题，准备更多训练数据其实也没什么用处，至少这不是更有效的方法，所以大家要清楚存在的问题是偏差还是方差，还是两者都有问题，明确这一点有助于我们选择出最有效的方法。

2. 在机器学习的初期阶段，关于所谓的偏差方差权衡的讨论屡见不鲜，原因是我们能尝试的方法有很多，可以增加偏差，减少方差，也可以减少偏差，增加方差。在当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要准备了更多数据（也并非只有这两种情况），那么只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。

这两步实际要做的工作是：训练网络，选择网络或者准备更多数据，现在我们有工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。这就是深度学习对监督式学习大有裨益的一个重要原因，也是我们不用太过关注如何平衡偏差和方差的一个重要原因。比如通过正则化，训练一个更大的网络几乎没有任何负面影响，而训练一个大型神经网络的主要代价也只是计算时间，前提是网络是比较规范化的。

### 4. 正则化（Regularization）

对于高方差问题有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少网络误差。

正则化是一种非常实用的减少方差的方法，正则化时会出现偏差方差权衡问题，偏差可能略有增加，如果网络足够大，增幅通常不会太高。

**$L2$正则化:**
$$
\begin{split}
J\left( w,b \right) &=\frac{1}{m}\sum\limits_{i=1}^{m}{L\left( {{{\hat{y}}}^{(i)}},{{y}^{(i)}} \right)} + \frac{\lambda}{2m}\mid\mid W\mid\mid _2^2 \\
\mid\mid W\mid\mid _2^2 &= \sum\limits_{j=1}^{n_x} w_j^2 = W^T \cdot W
\end{split}
$$
$L2$正则化是最常见的正则化类型。用逻辑回归来实现这些设想，求成本函数的最小值，$J\left( w,b \right)$是定义的成本函数。在逻辑回归函数中加入正则化，只需添加$\frac{\lambda}{m}\mid\mid W\mid\mid _2^2$，此方法称为$L2$正则化。因为这里用了$\mid\mid W\mid\mid _2^2$欧几里德法线。

为什么只正则化参数？为什么不再加上参数$\frac{\lambda}{2m}b^2$呢？可以这么做，一般是习惯省略不写。因为$W$通常是一个高维参数矢量，已经可以表达高偏差问题，$W$可能包含有很多参数，我们不可能拟合所有参数。而$b$只是单个数字，$W$几乎涵盖所有参数，如果加了参数$b$，其实也没太大影响，因为$b$只是众多参数中的一个，通常省略不计，如果想加上这个参数，完全没问题。

**$L1$正则化:**
$$
\begin{split}
J\left( w,b \right) &=\frac{1}{m}\sum\limits_{i=1}^{m}{L\left( {{{\hat{y}}}^{(i)}},{{y}^{(i)}} \right)} + \frac{\lambda}{2m}\mid\mid W\mid\mid _1 \\
\mid\mid W\mid\mid _1 &= \sum\limits_{j=1}^{n_x} \mid w_j \mid
\end{split}
$$
如果用的是$L1$正则化，$W$最终会是稀疏的，也就是说$W$向量中有很多0，有人说这样有利于压缩模型，因为集合中参数均为0，存储模型所占用的内存更少。实际上，虽然$L1$正则化使模型变得稀疏，却没有降低太多存储内存，所以这并不是$L1$正则化的目的，至少不是为了压缩模型，人们在训练网络时，越来越倾向于使用$L2$正则化。

$\lambda$是正则化参数，是另外一个需要调整的超级参数。顺便说一下，在**Python**编程语言中，$\lambda$是一个保留字段，编写代码时，所以写成$lambd$，以免与**Python**中的保留字段冲突。

**$L2$正则化在神经网络中实现：**
$$
\begin{split}
J\left( W^{[1]},b^{[1]} \ldots \right) &=\frac{1}{m}\sum_{i=1}^{m}{L\left( {{{\hat{y}}}^{(i)}},{{y}^{(i)}} \right)} + \frac{\lambda}{2m} \sum_{l=1}^{L}\mid\mid W^{[l]}\mid\mid _F^2 \\
\mid\mid W^{[l]}\mid\mid _F^2 &= \sum_{i=1}^{n_{l-1}}\sum_{j=1}^{n_l} w_{ij}^2 
\end
{split}
$$
$\mid\mid W^{[l]}\mid\mid _F^2$矩阵范数被称作“弗罗贝尼乌斯范数”，用下标$F$标注”，鉴于线性代数中一些神秘晦涩的原因，不称之为“矩阵$L2$范数”，而称它为“弗罗贝尼乌斯范数”，表示一个矩阵中所有元素的平方和。

该如何使用该范数实现梯度下降呢？

既然已经增加了这个正则项，现在要做的就是使$dW^{[l]} = dW^{[l]} +\frac {\lambda}{m}W^{[l]} $，然后使用新定义的$dW^{[l]}$计算更新项。它的定义含有相关参数的代价函数导数和，以及最后添加的额外正则项，这也是$L2$正则化有时被称为“权重衰减”的原因。
$$
\begin{split}
W^{[l]} &:= W^{[l]} - \alpha \left( (from \  bp) +\frac {\lambda}{m}W^{[l]}\right) \\
&:= W^{[l]} - \frac{\alpha \lambda}{m}W^{[l]} - \alpha (from \  bp) \\
&:=(1 - \frac{\alpha \lambda}{m})W^{[l]} - \alpha (from \  bp) 
\end
{split}
$$
该正则项说明，不论$W^{[l]}$是什么，我们都试图让它变得更小。实际上，相当于未正则化之前的梯度下降，然后给矩阵$W$乘以$(1 -a\frac{\lambda}{m})$倍的权重，该系数小于1，因此$L2$范数正则化也被称为“权重衰减”。

### 5. 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?）

![拟合](http://www.ai-start.com/dl2017/images/2aafa244c3f184cc271b26d1d95d70c9.png)

为什么正则化有利于预防过拟合呢？为什么它可以减少方差问题？

左图是高偏差，右图是高方差，中间是Just Right。假设一个庞大的深度拟合神经网络。直观上理解就是如果正则化$\lambda$设置得足够大，权重矩阵$W$被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。

但是$\lambda$会存在一个中间值，于是会有一个接近“Just Right”的中间状态。

直观理解$\lambda$增加到足够大，$W$会接近于0，实际上是不会发生这种情况的。我们尝试消除或至少减少许多隐藏单元的影响，最终这个网络会变得更简单，这个神经网络越来越接近逻辑回归，我们直觉上认为大量隐藏单元被完全消除了，其实不然，实际上是该神经网络的所有隐藏单元依然存在，但是它们的影响变得更小了。神经网络变得更简单了，貌似这样更不容易发生过拟合。

![tanh](http://www.ai-start.com/dl2017/images/8248be8e83121535b73969a4599fbb08.png)

再来直观感受一下，正则化为什么可以预防过拟合，假设用的是双曲线激活函数。用$g(z)$表示$tanh(z)$，那么可以发现，利用双曲正切函数的线性状态，只要$z$可以扩展为更大值或者更小值，激活函数开始变得非线性，最终的非线性会容易产生过拟合。

如果正则化参数$\lambda$很大，$W$会变小，相对来说，$z$取值范围也会很小。这时曲线函数$tanh$会相对呈线性，整个神经网络会计算离线性函数近的值，这个线性函数非常简单，并不是一个极复杂的高度非线性函数，所以不会发生过拟合。

如果使用的是梯度下降函数，如果实施的是正则化函数，请牢记，$J$已经有一个全新的定义。如果继续用的是原来未正则化的函数$J$，可能看不到单调递减现象，为了调试梯度下降，请务必使用新定义的$J$函数，否则函数$J$可能不会在所有调幅范围内都单调递减。

### 6. dropout 正则化（Dropout Regularization）

除了$L2$正则化，还有一个非常实用的正则化方法——“**Dropout**（随机失活）”。

![Dropout1](http://www.ai-start.com/dl2017/images/e45f9a948989b365650ddf16f62b097e.png)

![Dropout2](http://www.ai-start.com/dl2017/images/9fa7196adeeaf88eb386fda2e9fa9909.png)

**Dropout**会遍历网络的每一层，并设置消除神经网络中节点的概率。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用**backprop**方法进行训练。

对于其它样本，照旧以抛硬币的方式设置概率，保留一类节点集合，删除其它类型的节点集合。对于每个训练样本，都将采用一个精简后神经网络来训练它，这种方法似乎有点怪，单纯遍历节点，编码也是随机的，可它真的有效。不过可想而知，针对每个训练样本，训练规模极小的网络，最后可能会认识到为什么要正则化网络，因为我们在训练极小的网络。

**实施dropout步骤：**

方法有几种，最常用的方法是**inverted dropout**（反向随机失活），以三层网络举例说明如何在某一层中实施**dropout**：

1. 首先要定义向量$d$，$d^{[3]}$表示一个三层的**dropout**向量：

   ```
   d3 = np.random.rand(a3.shape[0],a3.shape[1]) < keep-prob
   ```

   然后看它是否小于某数，该数称之为**keep-prob**，**keep-prob**是一个具体数字，上个示例中它是0.5，而本例中它是0.8。表示保留某个隐藏单元的概率，意味着消除任意一个隐藏单元的概率是0.2，它的作用就是生成随机矩阵。$d^{[3]}$是一个矩阵，每个样本和每个隐藏单元，其在$d^{[3]}$中的对应值为1的概率都是0.8，对应为0的概率是0.2。

2. 接下来要做的就是从第三层中获取激活函数，这里叫它$a^{[3]}$，$a^{[3]}$等于上面的$a^{[3]}$乘以$d^{[3]}$，`a3 =np.multiply(a3,d3)`，这里是元素相乘让$d^{[3]}$中0元素与$a^{[3]}$中相对元素归零。

3. 最后，==向外扩展$a^{[3]}$，即`a3 /= keep-prob`。==

   下面解释为什么要这么做，假设第三隐藏层上有50个神经元，在一维上$a^{[3]}$是50，通过因子分解将它拆分成$50×m$维的，保留和删除它们的概率分别为80%和20%，意味着最后被归零的单元有10（50×20%=10）个。现在看下$z^{\lbrack4]}$，$z^{[4]} = w^{[4]} a^{[3]} + b^{[4]}$，我们的预期是$a^{[3]}$减少20%，也就是说$a^{[3]}$中有20%的元素被归零，为了不影响$z^{\lbrack4]}$的期望值，我们需要用$w^{[4]} a^{[3]}/0.8$，它将会修正或弥补我们所需的那20%，$a^{[3]}$的期望值不会变。

`a3 /= keep-prob`就是所谓的**inverted dropout**方法。它的功能是，不论**keep-prop**的值是多少0.8，0.9甚至是1（如果**keep-prop**设置为1，那么就不存在**dropout**，因为它会保留所有节点），通过除以**keep-prob**，确保$a^{[3]}$的期望值不变。

**测试阶段训练算法：**

在测试阶段，我们要做的是不使用dropout函数。因为在测试阶段进行预测时，我们不期望输出结果是随机的，如果测试阶段应用dropout函数，预测会受到干扰。

如果在测试阶段使用dropout函数，理论上只需要多次运行预测处理过程，每一次不同的隐藏单元会被随机归零，预测处理遍历它们，但计算效率低，得出的结果也几乎相同，与不使用dropout函数的程序产生的结果极为相似。

**Inverted dropout**函数在除以**keep-prob**时可以记住上一步的操作，目的是确保即使在测试阶段不执行**dropout**来调整数值范围，激活函数的预期结果也不会发生变化，所以没必要在测试阶段额外添加尺度参数，这与训练阶段不同。

### 7. 理解 dropout（Understanding Dropout）

**Dropout**为什么可以通过正则化发挥如此大的作用呢？

直观上理解：不依赖于任何一个特征，因为该单元的输入可能随时被清除，也不会给任何一个输入加太多权重。通过这种形式传播下去，**dropout**将产生收缩权重的平方范数的效果，和之前讲的$L2$正则化类似。实施**dropout**的结果是它会压缩权重，并完成一些预防过拟合的外层正则化。事实证明，**dropout**被正式地作为一种正则化的替代形式，$L2$对不同权重的衰减是不同的，它取决于激活函数倍增的大小。与$L2$正则化不同的是，因为被应用方式的不同，dropout也会有所不同，甚至更适用于不同的输入范围。

==实施**dropout**的另一个细节是，超参数是**keep-prob**，它代表每一层上保留单元的概率==。所以不同层的**keep-prob**也可以变化。某一层为了预防矩阵的过拟合，它的**keep-prob**值应该相对较低。对于其它层，过拟合的程度可能没那么严重，它们的**keep-prob**值可能高一些。如果在某一层，不必担心其过拟合的问题，那么**keep-prob**可以为1。

有点像在处理$L2$正则化的正则化参数$\lambda$，我们尝试对某些层施行更多正则化，从技术上讲，也可以对输入层应用**dropout**，这样有机会删除一个或多个输入特征，虽然现实中通常不这么做。**keep-prob**的值为1，是非常常用的输入值，也可以用更大的值，或许是0.9，但是消除一半的输入特征是不太可能的。

实施**dropout**，在计算机视觉领域有很多成功的第一次。计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据，所以**dropout**在计算机视觉中应用得比较频繁。有些计算机视觉研究人员非常喜欢用它，几乎成了默认的选择。但要牢记一点，**dropout**是一种正则化方法，它有助于预防过拟合，因此除非算法过拟合，不然一般不会使用**dropout**的。它在其它领域应用得比较少，主要存在于计算机视觉领域，是因为通常没有足够的数据，所以一直存在过拟合，这就是有些计算机视觉研究人员如此钟情于**dropout**函数的原因。

**dropout**一大缺点就是代价函数$J$不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。原本定义明确的代价函数$J$每次迭代后都会下降，但引入dropout函数后的代价函数$J$实际上并没有明确定义，或者说在某种程度上很难计算，所以我们失去了调试工具来绘制这样的图片。

通常会关闭**dropout**函数，将**keep-prob**的值设为1，运行代码，确保$J$函数单调递减。然后打开**dropout**函数，希望在**dropout**过程中，代码并未引入**bug**。也可以尝试其它方法，虽然并没有关于这些方法性能的数据统计，但你可以把它们与**dropout**方法一起使用。

### 8. 其他正则化方法（Other regularization methods）

除了正则化和随机失活（**dropout**）正则化，还有几种方法可以减少神经网络中的过拟合:

**数据扩增:**

假设正在拟合猫咪图片分类器，如果想通过扩增训练数据来解决过拟合，但扩增数据代价高，而且有时候我们无法扩增数据，但我们可以通过添加这类图片来增加训练集。例如，水平翻转图片，并把它添加到训练集。所以现在训练集中有原图，还有翻转后的这张图片，所以通过水平翻转图片，训练集则可以增大一倍，因为训练集有冗余，这虽然不如我们额外收集一组新图片那么好，但这样做节省了获取更多猫咪图片的花费。除了水平翻转图片，也可以随意裁剪图片，这张图是把原图旋转并随意放大后裁剪的，仍能辨别出图片中的猫咪。

通过随意翻转和裁剪图片，可以增大数据集，额外生成假训练数据。和全新的独立的猫咪图片数据相比，这些额外的假的数据无法包含像全新数据那么多的信息，但这么做基本没有花费，代价几乎为零，除了一些对抗性代价。以这种方式扩增算法数据，进而正则化数据集，减少过拟合比较廉价。

所以，数据扩增可作为正则化方法使用，实际功能上也与正则化相似。

**early stopping:**

还有另外一种常用的方法叫作**early stopping**，运行梯度下降时，绘制代价函数的优化过程，呈单调下降趋势，如下图：

![early stopping](http://www.ai-start.com/dl2017/images/51ca931387ed9fb80313263113c56e8e.png)

因为在训练过程中，希望训练误差，代价函数都在下降，通过**early stopping**，不但可以绘制上面这些内容，还可以绘制验证集误差，它可以是验证集上的代价函数，逻辑损失和对数损失等。可以发现，验证集误差通常会先呈下降趋势，然后在某个节点处开始上升。

当还未在神经网络上运行太多迭代过程的时候，参数$w$接近0，因为随机初始化$w$值时，它的值可能都是较小的随机值。在长期训练神经网络之前$w$依然很小，在迭代过程和训练过程中$w$的值会变得越来越大，比如在中间位置时，神经网络中参数$w$的值已经非常大了，所以**early stopping**要做就是在中间点停止迭代过程。这时我们得到一个$w$值中等大小的弗罗贝尼乌斯范数，与$L2$正则化相似，选择参数$w$范数较小的神经网络，但愿神经网络过度拟合不严重。

**early stopping 缺点**:

机器学习过程包括几个步骤，其中一步是选择一个算法来优化代价函数$J$，我们有很多种工具来解决这个问题，如梯度下降，后面会介绍其它算法，例如**Momentum**，**RMSprop**和**Adam**等等，但是优化代价函数$J$之后，我们也不想发生过拟合，也有一些工具可以解决该问题，比如正则化，扩增数据等等。

在机器学习中，超参数激增，选出可行的算法也变得越来越复杂。如果我们用一组工具优化代价函数$J$，机器学习就会变得更简单。在重点优化代价函数$J$时，只需要留意$w$和$b$，$J(w,b)$的值越小越好，只需要想办法减小这个值，其它的不用关注。然后，减少方差，这一步我们用另外一套工具来实现，这个原理有时被称为“正交化”。思路是在一个时间做一个任务。

但**early stopping**的主要缺点就是不能独立地处理这两个问题，因为提早停止梯度下降，也就是停止了优化代价函数$J$。因为现在你不再尝试降低代价函数$J$，所以代价函数$J$的值可能不够小，同时你又希望不出现过拟合，你没有采取不同的方式来解决这两个问题，而是用一种方法同时解决两个问题，这样做的结果是我们要考虑的东西变得更复杂。

如果不用**early stopping**，另一种方法就是$L2$正则化，训练神经网络的时间就可能很长。这导致超级参数搜索空间更容易分解，也更容易搜索，但是缺点在于，必须尝试很多正则化参数$\lambda$的值，这也导致搜索大量$\lambda$值的计算代价太高。

**Early stopping**的优点是，只运行一次梯度下降，你可以找出$w$的较小值，中间值和较大值，而无需尝试$L2$正则化超级参数$\lambda$的很多值。

虽然$L2$正则化有缺点，可还是有很多人愿意用它。吴恩达老师个人更倾向于使用$L2$正则化，尝试许多不同的$\lambda$值，假设你可以负担大量计算的代价，而使用**early stopping**也能得到相似结果，还不用尝试这么多$\lambda$值。

### 9. 归一化输入（Normalizing inputs）

![均值归一化](http://www.ai-start.com/dl2017/images/5e49434607f22caf087f7730177931bf.png)

训练神经网络，其中一个加速训练的方法就是归一化输入。假设一个训练集有两个特征，输入特征为2维，归一化需要两个步骤：

1. 零均值化

   通过使用$\mu = \frac{1}{m}\sum_{i =1}^{m}x^{(i)}$，它是一个向量，之后令$x:=x-\mu$，表达的意思是移动训练集，直到它完成零均值化。即上图中图二表达的意思。

2. 归一化方差

   注意特征$x_{1}$的方差比特征$x_{2}$的方差要大得多，$\sigma^{2}= \frac{1}{m}\sum_{i =1}^{m}{({x^{(i)})}^{2}}$，$\sigma^{2}$是一个向量，它的每个特征都有方差，注意之前是已经完成了零均值化，最后把所有数据除以向量$\sigma^{2}$，最后变成上图图三形式。

==如果用它来调整训练数据，那么必须用相同的 $μ$ 和 $\sigma^{2}$来归一化测试集==。尤其是，你不希望训练集和测试集的归一化有所不同，不论$μ$的值是什么，也不论$\sigma^{2}$的值是什么，均值化和归一化公式中都会用到它们。所以==要用同样的方法调整测试集，而不是在训练集和测试集上分别预估$μ$ 和 $\sigma^{2}$==。

为什么要进行均值归一化输入特征，回想一下代价函数$J(w,b)=\frac{1}{m}\sum\limits_{i=1}^{m}{L({{{\hat{y}}}^{(i)}},{{y}^{(i)}})}$：

![均值归一化后梯度下降图](http://www.ai-start.com/dl2017/images/4d0c183882a140ecd205f1618243d7f8.png)

如果使用非归一化的输入特征，代价函数会像上图左图这样，是一个非常细长狭窄的代价函数。假设要找的最小值在椭圆中心，但如果特征值在不同范围，假如$x_{1}$取值范围从1到1000，特征$x_{2}$的取值范围从0到1，结果是参数$w_{1}$和$w_{2}$值的范围或比率将会非常不同，直观理解，标记为$w$和$b$，代价函数就有点像狭长的碗一样，如果你能画出该函数的部分轮廓，它会是一个狭长的函数。这时必须使用一个非常小的学习率，梯度下降法可能需要多次迭代过程，直到最后找到最小值。

如果归一化特征后，代价函数平均起来看更对称。如果函数是一个更圆的球形轮廓，那么不论从哪个位置开始，梯度下降法都能够更直接地找到最小值，而且可以在梯度下降法中使用较大步长，而不需要像在左图中那样反复执行。

==均值归一化总地直观理解是代价函数会更圆一些，而且更容易优化，前提是特征都在相似范围内，而不是1到1000，0到1的范围，而是在-1到1范围内或相似偏差，这使得代价函数$J$优化起来更简单快速。==

实际上如果假设特征$x_{1}$范围在0-1之间，$x_{2}$的范围在-1到1之间，$x_{3}$范围在1-2之间，它们是相似范围，所以会表现得很好。所以如果输入特征处于不同范围内，可能有些特征值从0到1，有些从1到1000，那么归一化特征值就非常重要了。如果特征值处于相似范围内，那么归一化就不是很重要了。执行这类归一化并不会产生什么危害，通常都会做归一化处理。

### 10. 梯度消失/梯度爆炸（Vanishing / Exploding gradients）

训练神经网络，尤其是深度神经所面临的一个问题就是梯度消失或梯度爆炸，也就是在训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变小，这加大了训练的难度。

![L层深度网络](http://www.ai-start.com/dl2017/images/fc03196f0b6d1c9f56fa39d0d462cfa4.png)

假设正在训练这样一个极深的神经网络，这个神经网络会有参数$W^{[1]}$，$W^{[2]}$，$W^{[3]}$等等，直到$W^{[l]}$，为了简单起见，假设使用激活函数$g(z)=z$，也就是线性激活函数，假设$b^{[l]}$=0，则输出$ y=W^{[l]}W^{[L -1]}W^{[L - 2]}\ldots W^{[3]}W^{[2]}W^{[1]}x$ 。

**梯度爆炸：**

所有这些矩阵数据传递的协议将给出$\hat y$而不是$y$的值。假设每个权重矩阵$W^{[l]} = \begin{bmatrix} 1.5 & 0 \\0 & 1.5 \\\end{bmatrix}$，从技术上来讲，最后一项有不同维度，可能它就是余下的权重矩阵，$\hat y= W^{[l]}\begin{bmatrix} 1.5 & 0 \\ 0 & 1.5 \\\end{bmatrix}^{(L -1)}x$ 。因为我们假设所有矩阵都等于1.5倍的单位矩阵，最后的计算结果就是$\hat{y}$，$\hat{y}$也就是等于${1.5}^{(L-1)}x$。如果对于一个深度神经网络来说$L$值较大，那么$\hat{y}$的值也会非常大，实际上它呈指数级增长的，它增长的比率是${1.5}^{L}$，因此对于一个深度神经网络，$y$的值将爆炸式增长。

**梯度消失：**

相反的，如果权重是0.5，$W^{[l]} = \begin{bmatrix} 0.5& 0 \\ 0 & 0.5 \\ \end{bmatrix}$，它比1小，这项也就变成了${0.5}^{L}$，矩阵$\hat y= W^{[l]}\begin{bmatrix} 0.5 & 0 \\ 0 & 0.5 \\\end{bmatrix}^{(L - 1)}x$ 。假设$x_{1}$和$x_{2}$都是1，激活函数将变成$\frac{1}{2}$，$\frac{1}{2}$，$\frac{1}{4}$，$\frac{1}{4}$，$\frac{1}{8}$，$\frac{1}{8}$等，直到最后一项变成$\frac{1}{2^{L}}$，所以作为自定义函数，激活函数的值将以指数级下降，它是与网络层数数量$L$相关的函数，在深度网络中，激活函数以指数级递减。

**总结：**

得到的直观理解是，权重$W$只比1略大一点，或者说只是比单位矩阵大一点，深度神经网络的激活函数将爆炸式增长，如果$W$比1略小一点，在深度神经网络中，激活函数将以指数级递减，虽然我只是讨论了激活函数以与$L$相关的指数级数增长或下降，它也适用于与层数$L$相关的导数或梯度函数，也是呈指数级增长或呈指数递减。

如果激活函数或梯度函数以与$L$相关的指数增长或递减，它们的值将会变得极大或极小，从而导致训练难度上升，尤其是梯度指数小于$L$时，梯度下降算法的步长会非常非常小，梯度下降算法将花费很长时间来学习。

实际上，在很长一段时间内，它曾是训练深度神经网络的阻力，虽然有一个不能彻底解决此问题的解决方案，但是已在如何选择初始化权重问题上提供了很多帮助。

### 11. 神经网络的权重初始化（Weight Initialization for Deep NetworksVanishing / Exploding gradients）

针对深度网络的梯度消失和梯度爆炸，有一个不完整的解决方案，虽然不能彻底解决问题，却很有用，有助于我们为神经网络更谨慎地选择随机初始化参数。

![单神经元](http://www.ai-start.com/dl2017/images/e4114d7dc1c6242bd96cdadb457b8959.png)

假设单个神经元有4个输入特征，$z = w_{1}x_{1} + w_{2}x_{2} + \ldots +w_{n}x_{n}$，暂时忽略$b$，为了预防$z$值过大或过小，可以看到$n$越大，我们希望$w_{i}$越小，因为$z$是$w_{i}x_{i}$的和，最合理的方法就是设置$w_{i}=\frac{1}{n}$，$n$表示神经元的输入特征数量。实际上，要做的就是设置某层权重矩阵$w^{[l]} = np.random.randn( \text{shape})*\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]}})$（$n^{[l - 1]}$即第$l-1$层神经元数量）。

如果用的是**Relu**激活函数，而不是$\frac{1}{n}$，方差设置为$\frac{2}{n}$，效果会更好。初始化时，尤其是使用**Relu**激活函数时，$g^{[l]}(z) =Relu(z)$,它取决于你对随机变量的熟悉程度，这是高斯随机变量，然后乘以它的平方根，也就是引用这个方差$\frac{2}{n}$。如果激活函数的输入特征被零均值和标准方差化，方差是1，$z$也会调整到相似范围，这就没解决问题（梯度消失和爆炸问题）。但它确实降低了梯度消失和爆炸问题，因为它给权重矩阵$w$设置了合理值，你也知道，它不能比1大很多，也不能比1小很多，所以梯度没有爆炸或消失过快。

**tanh**激活函数，有篇论文提到，常量1比常量2的效率更高，对于**tanh**函数来说，它是$\sqrt{\frac{1}{n^{[l-1]}}}$，这里平方根的作用与$\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]}})$公式作用相同，它适用于**tanh**激活函数，被称为**Xavier**初始化。**Yoshua Bengio**和他的同事还提出另一种方法，你可能在一些论文中看到过，它们使用的是公式$\sqrt{\frac{2}{n^{[l-1]} + n^{\left[l\right]}}}$ ，其它理论已对此证明。

如果想用**Relu**激活函数，也就是最常用的激活函数，一般会用这个公式$\text{np.}\text{sqrt}(\frac{2}{n^{[l-1]}})$，如果使用**tanh**函数，可以用公式$\sqrt{\frac{1}{n^{[l-1]}}}$。

实际上，所有这些公式只是给你一个起点，它们给出初始化权重矩阵的方差的默认值，如果想添加方差，方差参数则是另一个你需要调整的超级参数，可以给公式$\text{np.}\text{sqrt}(\frac{2}{n^{[l-1]}})$添加一个乘数参数，调优作为超级参数激增一份子的乘子参数。有时调优该超级参数效果一般，这并不是我想调优的首要超级参数，但我发现调优过程中产生的问题，虽然调优该参数能起到一定作用，但考虑到相比调优，其它超级参数的重要性，我通常把它的优先级放得比较低。

通过设置的权重矩阵使网络既不会增长过快，也不会太快下降到0，从而训练出一个权重或梯度不会增长或消失过快的深度网络。我们在训练深度网络时，这也是一个加快训练速度的技巧。

### 12. 梯度的数值逼近（Numerical approximation of gradients）

在实施**backprop**时，有一个测试叫做梯度检验，它的作用是确保**backprop**正确实施。因为有时候，虽然写下了这些方程式，却不能100%确定执行**backprop**的所有细节都是正确的。

![梯度数值逼近](http://www.ai-start.com/dl2017/images/91cde35a0fc9c11a98f16ad2797f20a7.png)

假设$f\left( \theta \right)=\theta^{3}$，$\theta=1$，在$\theta$ 右侧，设置一个$\theta +\varepsilon$，在$\theta$左侧，设置$\theta -\varepsilon$。跟以前一样，$\varepsilon$的值为0.01，图中绿色三角形上边的点的值是$f( \theta +\varepsilon )$，下边的点是$f( \theta-\varepsilon)$，这个三角形的高度是$f( \theta +\varepsilon)-f(\theta -\varepsilon)$，三角形的宽度是$2\varepsilon$，高宽比值为$\frac{f(\theta + \varepsilon ) - (\theta -\varepsilon)}{2\varepsilon}= \frac{{(1.01)}^{3} - {(0.99)}^{3}}{2 \times0.01}$，它的期望值更接近$g( \theta)$ ，逼近误差是0.0001。

如果只考虑了单边公差，即从$\theta $到$\theta +\varepsilon$之间的误差，$g( \theta)$的值为3.0301，逼近误差是0.03，不是0.0001，所以使用双边误差的方法更逼近导数，其结果接近于3，现在我们更加确信，$g( \theta)$可能是$f$导数的正确实现。所以在执行梯度检验时，使用双边误差，即$\frac{f\left(\theta + \varepsilon \right) - f(\theta -\varepsilon)}{2\varepsilon}$，而不使用单边公差，因为它不够准确。

### 13. 梯度检验（Gradient checking）

假设网络中含有下列参数，$W^{[1]}$和$b^{[1]}$……$W^{[l]}$和$b^{[l]}$，为了执行梯度检验，首先要做的就是，把所有参数转换成一个巨大的向量数据，把所有$W$矩阵和$b$转换成向量之后，做连接运算，得到一个巨型向量$\theta$ 。该向量表示为参数$\theta$，代价函数$J(W^{[1]},b^{[1]},\ldots,W^{[l]},b^{[l]})$就可以转变为关于$\theta$的代价函数$J(\theta)$。接着同样可以把$dW^{[1]}$和${db}^{[1]}$……${dW}^{[l]}$和${db}^{[l]}$转换成一个新的向量，用它们来初始化大向量$d\theta$，它与$\theta$具有相同维度。

首先，我们要清楚$J$是超参数$\theta$的一个函数，你也可以将$J$函数展开为$J(\theta_{1},\theta_{2},\theta_{3},\ldots\ldots)$，不论超级参数向量$\theta$的维度是多少，为了实施梯度检验，要做的就是循环执行$i$，从而对每个$i$也就是对每个$\theta$组成元素计算$d\theta_{\text{approx}}[i]$的值，即使用双边误差$d\theta_{\text{approx}}\left[i \right] = \frac{J\left( \theta_{1},\theta_{2},\ldots\theta_{i} + \varepsilon,\ldots \right) - J\left( \theta_{1},\theta_{2},\ldots\theta_{i} - \varepsilon,\ldots \right)}{2\varepsilon}$ ，==只对$\theta_{i}$增加$\varepsilon$，其它项保持不变==。

从上节课中，了解到$d\theta_{\text{approx}}\left[i \right]$应该逼近$d\theta\left[i \right]$=$\frac{\partial J}{\partial\theta_{i}}$，$d\theta\left[i \right]$是代价函数的偏导数，然后需要对$i$的每个值都执行这个运算，最后得到$d\theta$应该逼近$d\theta_{\text{approx}}$，它与$d\theta$具有相同维度，要做的就是验证这些向量是否彼此接近。

具体来说，如何定义两个向量是否真的接近彼此？
$$
\frac{{||d\theta_{\text{approx}} -d\theta||}_{2}}{||d\theta_{\text{approx}}||_2 + ||d\theta||_2}
$$
通过上面公式，分母只是用于预防这些向量太小或太大，分母使得这个方程式变成比率。实际执行这个方程式，$\varepsilon$可能为$10^{-7}$，使用这个范围内的$\varepsilon$，如果发现计算方程式得到的值为$10^{-7}$或更小，这就很好，这就意味着导数逼近很有可能是正确的，它的值非常小。

如果它的值在$10^{-5}$范围内，就要小心了，也许这个值没问题，但我会再次检查这个向量的所有项，确保没有一项误差过大，可能这里有bug。

如果左边这个方程式结果是$10^{-3}$，就需要担心是否存在bug，计算结果应该比$10^{- 3}$小很多，如果比$10^{-3}$大很多，担心是否存在bug。这时应该**仔细检查所有$\theta$项，看是否有一个具体的$i$值，使得$d\theta_{\text{approx}}\left[i \right]$与$ d\theta[i]$大不相同，并用它来追踪一些求导计算是否正确**，经过一些调试，最终结果会是这种非常小的值（$10^{-7}$），那么你的实施可能是正确的。

在实施神经网络时，经常需要执行**foreprop**和**backprop**，然后可能发现这个梯度检验有一个相对较大的值，需要怀疑存在bug，然后开始调试，调试，调试，调试一段时间后，得到一个很小的梯度检验值，现在可以很自信的说，神经网络实施是正确的。梯度检验帮助我们在神经网络实施中发现了很多bug。

### 14. 梯度检验应用的注意事项（Gradient Checking Implementation Notes）

分享一些关于如何在神经网络实施梯度检验的实用技巧和注意事项：

1. 首先，**==不要在训练中使用梯度检验，它只用于调试==**。我的意思是，计算所有$i$值的$d\theta_{\text{approx}}\left[i\right]$是一个非常漫长的计算过程，为了实施梯度下降，你必须使用$W$和$b$ **backprop**来计算$d\theta$，并使用**backprop**来计算导数，只有调试的时候，你会计算它，来确认数值是否接近$d\theta$。完成后，关闭梯度检验，梯度检验的每一个迭代过程都不执行它，因为它太慢了。

2. 第二点，如果算法的梯度检验失败，要检查所有项，检查每一项，并试着找出bug，也就是说，如果$d\theta_{\text{approx}}\left[i\right]$与$d\theta[i]$的值相差很大，我们要做的就是查找不同的$i$值，看看是哪个导致$d\theta_{\text{approx}}\left[i\right]$与$d\theta\left[i\right]$的值相差这么多。

   举个例子，如果发现，相对某些层或某层的$\theta$或$d\theta$的值相差很大，但是$\text{dw}^{[l]}$的各项非常接近，注意$\theta$的各项与$b$和$w$的各项都是一一对应的。这时，你可能会发现，在计算参数$b$的导数$db$的过程中存在bug。反过来也是一样，如果你发现它们的值相差很大，$d\theta_{\text{approx}}\left[i\right]$的值与$d\theta\left[i\right]$的值相差很大，你会发现所有这些项目都来自于$dw$或某层的$dw$，可能帮你定位bug的位置，虽然未必能够帮你准确定位bug的位置，但它可以帮助你估测需要在哪些地方追踪bug。

3. 第三点，在实施梯度检验时，如果使用正则化，请注意正则项。如果代价函数$J(\theta) = \frac{1}{m}\sum_{}^{}{L(\hat y^{(i)},y^{(i)})} + \frac{\lambda}{2m}\sum_{}^{}{||W^{[l]}||}^{2}$，$d\theta$等于与$\theta$相关的$J$函数的梯度，包括这个正则项，记住一定要包括这个正则项。

4. 第四点，**==梯度检验不能与dropout同时使用==**，因为每次迭代过程中，**dropout**会随机消除隐藏层单元的不同子集，难以计算**dropout**在梯度下降上的代价函数$J$。因此**dropout**可作为优化代价函数$J$的一种方法，但是代价函数$J$被定义为对所有指数极大的节点子集求和。而在任何迭代过程中，这些节点都有可能被消除，所以很难计算代价函数$J$。你只是对成本函数做抽样，用**dropout**，每次随机消除不同的子集，所以很难用梯度检验来双重检验**dropout**的计算，所以一般不同时使用梯度检验和**dropout**。

   如果想这样做，可以把**dropout**中的**keepprob**设置为1.0，然后打开**dropout**，并寄希望于**dropout**的实施是正确的，还可以做点别的，比如修改节点丢失模式确定梯度检验是正确的。实际上，一般不这么做，建议关闭**dropout**，用梯度检验进行双重检查，在没有**dropout**的情况下，你的算法至少是正确的，然后打开**dropout**。

5. 最后一点，也是比较微妙的一点，现实中几乎不会出现这种情况。当$w$和$b$接近0时，梯度下降的实施是正确的，在随机初始化过程中……，但是在运行梯度下降时，$w$和$b$变得更大。可能只有在$w$和$b$接近0时，**backprop**的实施才是正确的。但是当$W$和$b$变大时，它会变得越来越不准确。你需要做一件事，我不经常这么做，就是在随机初始化过程中，运行梯度检验，然后再训练网络，$w$和$b$会有一段时间远离0，如果随机初始化值比较小，反复训练网络之后，再重新运行梯度检验。

回顾这一周，讲了如何配置训练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化，如$L2$正则化和**dropout**，还有加快神经网络训练速度的技巧（均值归一化），最后是梯度检验。